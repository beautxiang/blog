/*
 Navicat Premium Data Transfer

 Source Server         : mysql
 Source Server Type    : MySQL
 Source Server Version : 80011
 Source Host           : localhost:3306
 Source Schema         : blog

 Target Server Type    : MySQL
 Target Server Version : 80011
 File Encoding         : 65001

 Date: 15/06/2021 11:31:03
*/

SET NAMES utf8mb4;
SET FOREIGN_KEY_CHECKS = 0;

-- ----------------------------
-- Table structure for about
-- ----------------------------
DROP TABLE IF EXISTS `about`;
CREATE TABLE `about`  (
  `about_id` int(11) NOT NULL,
  `about_title` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NULL DEFAULT NULL,
  `about_content` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NULL DEFAULT NULL,
  `about_subscript` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NULL DEFAULT NULL,
  PRIMARY KEY (`about_id`) USING BTREE
) ENGINE = InnoDB CHARACTER SET = utf8mb4 COLLATE = utf8mb4_0900_ai_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of about
-- ----------------------------
INSERT INTO `about` VALUES (1, '电子信息内容管理系统', '该系统前端采用vue.js、Element、axios等技术栈，后端采用Springboot、mysql数据库结合xml，致力于打造出一款方便用户使用的软件。', '为更好的建设互联网生态....');

-- ----------------------------
-- Table structure for admin
-- ----------------------------
DROP TABLE IF EXISTS `admin`;
CREATE TABLE `admin`  (
  `admin_id` int(11) NOT NULL AUTO_INCREMENT COMMENT '管理员id\r\n',
  `admin_name` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NULL DEFAULT NULL COMMENT '管理员名',
  `admin_password` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NULL DEFAULT NULL COMMENT '管理员密码',
  `admin_email` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NULL DEFAULT NULL COMMENT '管理员邮箱',
  `user_photo` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NULL DEFAULT NULL COMMENT '管理员头像',
  `admin_register_time` datetime(0) NULL DEFAULT NULL COMMENT '管理员注册时间',
  PRIMARY KEY (`admin_id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 2 CHARACTER SET = utf8mb4 COLLATE = utf8mb4_0900_ai_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of admin
-- ----------------------------
INSERT INTO `admin` VALUES (1, 'admin', '123456', '2494916623@qq.com', NULL, '2021-04-26 09:23:12');
INSERT INTO `admin` VALUES (2, 'wzw', '123456', '1119417667@qq.com', NULL, '2021-04-26 09:23:44');

-- ----------------------------
-- Table structure for article
-- ----------------------------
DROP TABLE IF EXISTS `article`;
CREATE TABLE `article`  (
  `article_id` int(11) NOT NULL AUTO_INCREMENT COMMENT '文章id',
  `article_title` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NOT NULL COMMENT '文章标题',
  `article_photo` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NULL DEFAULT NULL COMMENT '文章图片',
  `article_content` longtext CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NOT NULL COMMENT '文章内容',
  `article_view_count` int(11) NULL DEFAULT 0 COMMENT '文章浏览量',
  `article_comment_count` int(11) NULL DEFAULT 0 COMMENT '文章评论数',
  `article_like_count` int(11) NULL DEFAULT 0 COMMENT '文章点赞数',
  `article_status` int(1) NULL DEFAULT 1 COMMENT '文章状态（0为不可见，1为可见）',
  `article_creation_time` datetime(0) NULL DEFAULT NULL COMMENT '文章创建时间',
  `category_id` int(11) NULL DEFAULT NULL COMMENT '对应外键的category的id',
  `admin_id` int(11) NULL DEFAULT NULL COMMENT '管理员id',
  PRIMARY KEY (`article_id`) USING BTREE,
  INDEX `article_ibfk_1`(`category_id`) USING BTREE,
  INDEX `article_ibfk_2`(`admin_id`) USING BTREE,
  CONSTRAINT `article_ibfk_1` FOREIGN KEY (`category_id`) REFERENCES `category` (`category_id`) ON DELETE CASCADE ON UPDATE CASCADE,
  CONSTRAINT `article_ibfk_2` FOREIGN KEY (`admin_id`) REFERENCES `admin` (`admin_id`) ON DELETE CASCADE ON UPDATE CASCADE
) ENGINE = InnoDB AUTO_INCREMENT = 60 CHARACTER SET = utf8mb4 COLLATE = utf8mb4_0900_ai_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of article
-- ----------------------------
INSERT INTO `article` VALUES (1, '自动化专业就业情况报告', NULL, '回顾下本专栏的前文，介绍了自动化学科的基本定义与学习内容、创立与发展历史、发展动力、国内外现状、与其他专业的区别、与人工智能的关系、深造问题、目前的产业发展，以及专业前辈的介绍文章，涵盖了从高考后进入专业到走出校园的全程，想了想也就剩下最后一个问题了，就业。\r\n\r\n无论本科，硕士还是读博，总有一天都要面临工作，对于自动化出来能干什么这个问题，每个学生都需要面对，只不过不同的学历层次选择不同。\r\n\r\n一、写在前面\r\n打开知乎，搜索任何一个专业的就业，生化环材除外，多看几个帖子就会发现，同样一个专业有的说我们就业随便去，都是月薪10K以上，有的说专业垃圾，出去也就3K，而如果单纯的看一个或者少数帖子，就会产生误导。\r\n\r\n谁说的对呢，其实都对，关键学校不一样，就拿自动化来说，清华大学自动化出来不缺好工作，普通的学校自动化出来，差一点的去个机械厂车间，两个人自然对专业感觉就不一样。所以网上帖子再多，不如本校学长一张就业去向表有价值。\r\n\r\n为了提供大范围的参考，本报告不涉及具体公司，有兴趣者可以查阅招聘网站信息。\r\n\r\n二、机器人行业\r\n提起自动化专业的适合就业方向，不少人第一个就说，机器人，有些高考志愿书上甚至把新设立的机器人工程专业称为最高层次的自动化专业，但很多人往往并不知道机器人相关岗位有什么。\r\n\r\n首先，随着科技的发展，分工的不断精细，对于刚入行的从业者来说，不会说让你一个人负责机器人系统的设计生产全过程，上来就当总工。分出来了许多工作，从一开始说吧。\r\n\r\n1、机器人运动控制\r\n\r\n假设交给你一个任务，让你设计一个机器人，第一步干啥呢？看看人体结构，先把大的结构敲定，用到仿生学或者机械设计相关知识，然后研究利用电机怎么让他动起来。这一个方向被称为机器人运动控制方向。\r\n\r\n这个方向要求有力学与机械知识及必要的算法能力，在相关的招聘网站上对于运动控制岗位的条件例如：\r\n\r\n推荐标准：适合于电机学相关知识扎实，具有基本的嵌入式开发能力的学生。\r\n\r\n\r\n\r\n2、环境感知与路径规划\r\n\r\n拿到了一个能动的机器人，接下来问题是怎么动，即环境感知与路径规划，最近这个大方向很火，原因也是因为机器学习带动的视觉革命，在机器学习没火之前，环境感知主要依靠传统传感器，利用多传感器融合技术，而路径规划算法的历史更早。\r\n\r\n这个方向主要依靠算法，也是目前为止机器人领域最贴近于计算机的方向，或者说就是计算机，岗位也分两种，传统感知类与视觉感知类，视觉感知类待遇相对好一些。这类与模式识别比较类似。\r\n\r\n推荐标准：适合于算法相关知识扎实的学生。一些岗位对于学历有要求。\r\n\r\n\r\n\r\n3、集群机器人\r\n\r\n设计的机器人能动了，也知道怎么动了，看样子任务完成了，此时上面下了一个新要求，举个例子，物流行业，一用就是许多台机器人，它们怎么配合？或者无人机，一群无人机怎么联动。这就是集群机器人方向。\r\n\r\n这个方向更加依靠数学，依靠算法，随着应用的机器人数量越来越多，该方向的热度逐渐上升。\r\n\r\n推荐标准：适合于数学、算法相关知识扎实的学生。对于学历有要求。\r\n\r\n\r\n\r\n4、总结\r\n\r\n不少网站上对于机器人行业的岗位还会有ROS这一类，看了看工作职能，这类岗可以划入以上三个。\r\n\r\n综上，对于机器人行业，机械电子工程出身的大佬可以考虑从事运动控制方向，自动化本科出身的也可以，自动化出身的硕博的话建议第二或第三，因为考虑到机械相关的知识需要补充，不过也不是绝对不能做第一个方向的。\r\n\r\n三、嵌入式\r\n嵌入式，这个方向与其他方向有重合，是每年自动化专业本科生毕业就业去向最多的行业，比较考验硬件能力，对各型号的单片机掌握，对基本控制算法的掌握，以后发展的方向也是硬件工程师，社会上对于嵌入式有很多培训机构，、在大学期间也可以自主学习。\r\n\r\n推荐标准：适合于硬件、基本算法相关知识扎实的学生。尤其是硬件相关知识。\r\n\r\n四、工业现场\r\n提起工业现场，虽然说自动化专业来源于工业，但学生往往不会选择工业现场，一是因为环境差，二是因为待遇低，三是因为各种加班，比996有过之而无不及。\r\n\r\n但是由于各种原因，最后很多人还是去了工业现场，去了以后或者打算去的，可以记住这样一句话，越硬越穷，越软越富。什么意思呢，对于同一批进去的，比较工资待遇，一般算法岗或者管理岗要比纯硬件岗高。\r\n\r\n工业现场对于新招收的自动化学生有以下几种岗位：\r\n\r\n1、学徒工类\r\n\r\n第一年在车间锻炼，做一些装配工作，逐渐跟着厂里师傅学PLC,电气控制等活，这种一般是本科生。\r\n\r\n2、初级工程师\r\n\r\n如果PLC等相关器件掌握较好，有些企业会让新进的学生迅速参与设计与调试，常年出差，不过待遇比学徒工类要好一点。本科生居多。\r\n\r\n3、上位机类\r\n\r\n如果通信、上位机编程掌握较好，一般会负责一些现场的上位机软件设计，也可以去一些专门做这块的公司，同样需要常年蹲现场和出差。\r\n\r\n做了几年后，拥有了工作经验，才有资格参加许多公司的高级岗位招聘，拿最近比较热门的工业互联网来说，很多岗位都要求三年经验，这个行业非常看重经验。\r\n\r\n推荐标准：热爱这行、能沉下心锻炼自己、具有一定的不断学习能力的学生。\r\n\r\n五、军工\r\n【请咨询相关行业人士】\r\n\r\n六、纯软件\r\nJAVA 安卓都比较好，入行人工智能纯软件请做好神仙打架的准备。', 5, 2, 0, 1, '2021-05-05 10:56:33', 1, 1);
INSERT INTO `article` VALUES (2, '自动化专业的这二十年', NULL, '从1998年自动化专业这一名称正式进入高等教育体系，已经过去了二十多年，这二十多年的过程中自动化专业都经历了什么，无数学者和专家做了大量研究，作者注意到，这二十年也是互联网跨越式发展的二十年，因此有一个问题让人好奇，每一年当人们在网络上谈论自动化专业时，他们会说些什么呢。\r\n\r\n以下，本文将借用百度搜索引擎的限定网页时间功能，试图了解这二十年中网民口中的自动化专业都是什么样。\r\n\r\n2003-2004年\r\n2003年的一篇招生文章中，一位自动化学生这样形容专业：\r\n\r\n计算机课程开设得相当丰富，就其水平来说也不比计算机专业的学生差，我们比计算机专业的同学多了自动化这一专业背景的优势，也就是说，我们既具有专业理论知识，又能利用计算机这一重要资源，能在计算机上进行编程、模拟仿真，真是如虎添翼，我们学到的东西将受益终身。\r\n　　我们建立系统的原则是稳定，受干扰的波动要小，那么我们的社会，稳定也是极其重要的。因此我们自动化人中有很多从事经济、政治领域或继续深造攻读其他专业的都相当容易，并且取得了不俗的成绩。\r\n在同年的十二月份，出现了这样的一篇专业方向提问：\r\n\r\n我是一个自动化专业的学生，现在大二，但是我到现在都不明白我所学的专业具体是做什么的，不知道将来的方向，问过一个学长，他说你们自动化的就是学开机器，关机器的。。郁闷ing... 我们现在还没有开专业课，下学期就开，我现在想明确一下自己的未来，依次来确定自己的奋斗目标， 我现在只知道PLC与单片机是自动化发展的两个好方向，所以我现在迫切想知道请自动化的前辈们指点指点我这个迷途的人，给我示以明灯。谢谢。谢谢\r\n说实话，这个帖子要是没看时间，我觉得是现在的帖子。\r\n\r\n看看后面的回复\r\n\r\n我在年初参加的高级电工的“应会”考核中，题目就是一个PLC的简单的顺序控制（只用基本指令就可实现）。由此：我想PLC今后将是普通电工应该掌握的，所以，我建议你在学习PLC的同时，还是认真的学好单片机吧，本科生应该追求点难度高的东西。 我没有见过PLC，现在也是在自己学习。一家只言，说错了，别骂我。\r\n2003年12月31号，出现了一篇对于就业的吐槽贴，算了算，差不多就是第一批自动化专业毕业参加工作一年的时间，吐槽的点在于工厂，仪表和工控，但对单片机方向多多少少有些向往：\r\n\r\n我也是自动化，三流学校毕业。2年了，搞单片机。项目做过很多，usb,pc上vc,平时用汇编写固件。前途还是有的，自己要把握。现在买了个51仿真器，自己在家里搞些小玩意。曾经在数码相机厂做过软件，感觉工厂、仪表、工控都很没前途！还是单片机好啊。\r\n另外在2004年的回复当中，有位作者也说明了里面的基本矛盾\r\n\r\n现在自动化企业要的是专业型全面人才，你要是想做研发就要在专业课程上下功夫，没有基础，做研发那是天方夜谭，而且最好在学校有有几个搞过的课题有点成果。如果你不想做研发，也可以做系统集成，做系统集成也需要专业知识，而且知识面要广比如PLC、DCS、组态软件等自动化知识、计算机知识、计算机网路知识、通讯知识等等，最好精通1门计算机语言。如果你也不作那只能做做维护或售后服务或者去搞销售。\r\n2005年-2006年\r\n与上两年大体相同，但也有自身的特色，比如2005年的一篇询问就业的帖子里，已经呈现了万金油特色，从帖子里逐渐嗅到了自动化特有的迷茫气息\r\n\r\n呵呵 自动化就业面灰常广的~~只要是electronical engneering 就可以~~不过我现在做ERP~~跟学的专业一点关系都没有~~我们班同学有去电信的、移动、联通之类的运营商，也有去一些电子研究所的、电子制造业的（这个范围就多去了）...还有搞汽车电子的、钢铁军工的、软件研发的......不一而足~~~万金油啊~~\r\n值得注意的是，在同年一篇帖子里，楼主表示图简单考研报考了模式识别，没有报双控，就业前景黯淡，很多回复帖也表示赞同，今天反过来了。\r\n\r\n2006年6月份，同样是一篇吐槽就业贴，一位层主说出了一段至今看来也不错的话\r\n\r\n自动化的一个好处是，你可以调整自己的方向，社会需要什么，你就能够适应什么，而不象其他行业，容易隔行如隔山，它是一个不太容易失业，又不太容易赚钱的行业，一定要有很灵的鼻子，在社会需要以前，就学这种本事，如智能住宅的单片机部分，智能家电，DSP..\r\n13年后的2019年，这段话被简单的总结为自动化=自动向热门方向转化\r\n\r\n2007-2008年\r\n2007年的搜索结果中出现了转专业：\r\n\r\n自动化能否转计算机等专业\r\n请问：自动化专业的本科生，能否转专业转到计算机、通讯工程、电子信息工程专业？难度大么？谢谢\r\n同年的一篇博文中标明，那时别的专业对于自动化的了解已经是做机器人的专业了。\r\n\r\n说到自动化，我就有种奇怪的感觉。已经不知有多少个人问过我“自动化是学什么的”了。每次都是支支唔唔的不知如何回答，然后就人云亦云的说：搞机器人的。记得第三届校运会的时候，我们学院的同学拿到了一万米的冠军时，我们同学都说，不愧是搞机器人的，连跑步都是那样，居然匀速跑了一万米到了最后速度也不减！\r\n其他的帖子内容一如既往，值得注意的是，在08年的帖子里面，一些参与吐槽的毕业生向往的岗位是销售，他们所说的自动化也限定在电气维护上，单片机或者说嵌入式，已经很少被提到\r\n\r\n2009年-2010年\r\n这个时间段，从网民到自动化学会，几乎都在分析为什么自动化专业这么多吐槽\r\n\r\n网民：\r\n\r\n自动化这个专业由来已久。在上个世纪，大多数此专业毕业的学生的必杀技便是PLC。因为行业属于工业范畴，属于那种发展不瘟不火的行业。一套PLC设备的寿命一般会超过十年。很多大公司的PLC产品也已垄断市场，也就注定了这个行业的人才需求量不会太大。另外，因为中国并没有自己的PLC研发公司，而外企也不会把这部分放到中国，所以大学生进入这个行业的一半都是在第一线从事PLC的编程和维护工作，工作环境一般比较差。不过薪水颇丰，我认识一个自动化本科毕业的学生，毕业后进入西门子从事PLC相关工作。月薪超过1W8.不过要是去一般的工业型企业做应用维护的话，你的工资恐怕就只能糊口了。仪器仪表就好很多，随着各种创业公司的建立，小型仪表有了飞速的发展。不过利润率都偏低，仅仅依靠工资是很难混的很好的。不过如果有幸进入上海自动化仪表，国核自仪等国企，那就不在讨论范畴了。\r\n自动化学会调研：\r\n\r\n我国相当多的学校自动化专业不开设必修的信息学、化学、生态学，不利于对学生基础综合素质与能力的培养；专业基础与专业课程方面最缺乏的是有关自动化的职业教育，相对与社会需求脱节。\r\n也是在这个时间段里，一些高校自动化系主任在开会时汇总了材料，提出了废除自动化专业的提议，当然，他们并未成功。\r\n\r\n2011年-2012年\r\n这一时间段，由于经历过废除危机，加上计算机技术的一些突破，自动化的相关讨论中计算机的前景方面内容略有增加，但不多，提到较多的新岗位是智能楼宇。以下是2011年博文\r\n\r\n我对自动化专业的评价是这样的：知识面基本能涵盖计算机、电子、信号、机械和电机年这几大工科领域，同时具有一定的数学建模、系统分析能力。自动化专业同学的长处，在于软硬件结合能力。自动化的同学擅长确定系统中各个模块的各自功能、明确模块间相互作用的途径；而各个模块的具体实现，也许相关专业的同学可以完成而自动化的同学却非常吃力。\r\n因此，自动化专业本科直接就业的同学，在单片机开发、嵌入式系统应用、系统驱动开发这些行业都比较对口。而在网络、通信、电力方面，单从知识结构方面，就有些吃亏。而其中一个比较具有误区的就是工业控制方面的岗位了，我曾经作为跟班，跟着做设备维修的姨父去过许多工厂，觉得工厂里设备的控制原理都已经是厂家成熟的解决方案了，主要的任务就是设备维修，而需要自动化相关知识的设备改造基本上一年到头屈指可数：因此我觉得工业控制方面的岗位也不是特别对口。\r\n谈谈模式识别与智能系统这一个方向。很多近期非常热门的技术都是来自这个方向，计算机视觉、声音识别、指纹虹膜等生物特征识别、智能学习系统等等。而计算机视觉的应用层面，简单的从“花季护航”、相机防抖、扫描识别到比较复杂的医学图像处理、机器视觉检测。\r\n总觉得我即将从事的是一个由人类好奇心推动的新的领域，在能源、生物学发生革命之前，它一定是能让大众察觉的最科幻的一门学科。\r\n控制理论与控制工程、系统工程这两个方向偏向于理论。在本科学习阶段，对于各种电路的数学模型、各种电机传动系统的数学模型，我一直因为几乎没有构建过而对他们保持着敬畏的心态。总觉得这两个专业需要的数学功底非常深厚、同时需要对很多数学软件、建模方法、仿真模拟方法轻车熟路。这两门学科虽然看似比较枯燥，但是如果真的研究深了，必然是大牛：庸俗一点说尤其是涉及到金融、投资领域，被企业请为高参的时候；学术一点说是当在某些理论，如神经网络、模糊控制等让人听了就觉得深奥的学说上有所突破的时候。\r\n这个时间段里，在各个论坛讨论最多的是控制界评院士事件。\r\n\r\n2013-2018年\r\n经过搜索，这五年的帖子基本一致，虽然2009年已经从上到下讨论过自动化专业的缺点，但一直到现在，还是吐槽不断，另一方面，吐槽的声音随着对专业的认知深入和计算机、人工智能的逐渐升温而减少，这一时期的总体趋势就是实力院校的毕业生对于自动化的吐槽逐渐减少，但新设自动化专业的毕业生意见依旧保持常态，然而、对于电气维护、工控行业这一方向来说，意见与十几年前基本一致。\r\n\r\n下图是关键词趋势，可以明显看出，自动化专业热度在高考季逐年上升\r\n\r\n\r\n还有一张有意思的图，对比了自动化与计算机的搜索。\r\n\r\n\r\n2019年\r\n之所以把2019年单独拿出来，是因为华为，华为高调宣布了八位高薪博士，它的本意也许是吸引人才，奖励贤才，宣传实力，但两位拿到最高薪的、都带有自动化背景的博士，无疑使得这个幕后专业受到了前所未有的关注。\r\n\r\n期待未来十年。\r\n\r\n', 2, 0, 0, 1, '2021-05-06 10:57:18', 1, 1);
INSERT INTO `article` VALUES (3, '自动化专业介绍', NULL, '1.培养目标\r\n\r\n本专业培养具备电工技术、电子技术、检测技术、信息处理技术、嵌入式技术、控制理论及应用等较宽广领域的工程技术基础和专业知识，能从事有关运动控制、过程控制、嵌入式系统、工业控制网络等方面的系统分析、系统设计、系统运行管理与维护、科学研究等方面的复合型自动化工程技术人才。\r\n\r\n2.主要课程\r\n\r\n电路原理、模拟电子技术基础、数字电子技术基础、C语言程序设计、微机原理与接口技术、信号与系统、自动控制原理、现代控制理论、电机原理及拖动基础、电力电子技术、检测技术与仪表、电气控制技术、嵌入式系统原理与应用。\r\n\r\n3.就业方向\r\n\r\n自动化专业的毕业生主要从事与自动控制系统相关的应用设计及科学研究工作，具体包括：自动化仪表和设备、嵌入式处理器及顶层应用设计、测控应用软件、运动控制系统、过程控制系统、交通控制和智能建筑等综合自动化测控系统的研究、设计、开发、运行和维护等工作。\r\n\r\n4.基本学制\r\n\r\n修业年限：4年；学生可在3-6年内修完本专业规定学分。\r\n\r\n5.授予学位\r\n\r\n修满规定的167.5学分，按照《大连大学学士学位授予工作实施细则》，授予工学学士学位。工学学士学位\r\n\r\n6.自动化专业特色\r\n\r\n自动化专业突出嵌入式系统、工业控制两个未来发展方向，构建知识体系与能力体系并重，理论教学与实践教学并重的培养模式与实施策略。\r\n\r\n(1)  多层次实践体系：基础类、设计类与综合类三层次的实践体系满足人才培养的需要，增强系统分析与设计能力。\r\n\r\n(2)  两方向校企合作构建：针对专业两大发展主线，广泛联系社会培训力量，加强校企合作，向卓越自动化工程师计划靠近，构建了基于工控应用技术与嵌入式系统研发的校企合作项目。', 0, 0, 0, 0, '2021-05-06 11:01:03', 1, 1);
INSERT INTO `article` VALUES (4, '自动化学院培养计划', NULL, '电气工程及其自动化专业 2017 版本科培养方案\r\nUndergraduate Education Plan for Specialty in Electrical \r\nEngineering and Automation (2017) \r\n专业名称 电气工程及其自动化 主干学科 电气工程、控制科学与工程、计算机科\r\n学与技术\r\nMajor Electrical Engineering \r\nand Automation \r\nMajor Disciplines Electrical Engineering, Control Science \r\nand Engineering, Computer Science and \r\nTechnology \r\n计划学制 四年 授予学位 工学学士\r\nDuration 4 Years Degree Granted Bachelor of Engineering \r\n最低毕业学分规定\r\nGraduation Credit Criteria \r\n课程类别 Course \r\nClassification \r\n课程性质\r\nCourse Nature \r\n通识教育课程\r\nPublic Basic \r\nCourses \r\n专业教育课程\r\nSpecialized Courses\r\n个性课程\r\nPersonalized \r\nCourse\r\n集中性实践\r\nPractice \r\nCourses\r\n课外学分\r\nStudy \r\nCredit after \r\nClass\r\n总学分\r\nTotal \r\nCredits\r\n必修课\r\nRequired Courses 29 68 \\ 28 \\ \r\n选修课\r\nElective Courses 9 20 6 \\ 10 \r\n170 \r\n一、 培养目标与毕业要求\r\nⅠEducational Objectives &Requirement \r\n（一） 培养目标\r\n武汉理工大学电气工程及其自动化专业面向电气工程领域科学研究、技术开发、工程设计和技术\r\n服务等任务，培养基础扎实、适应能力强、具有创新能力和国际化视野的高素质专业技术人才与管理\r\n人才。 \r\n（1）能设计电气系统解决方案，并能设计基于电路原理的实际应用系统； \r\n（2）在团队中作为技术骨干或领导有效发挥作用； \r\n（3）具有良好的修养和道德品质，有意愿并有能力服务社会； \r\n（4）能够通过继续教育或其它学习渠道更新知识，实现能力和技术水平的提升。 \r\nEducational Objectives \r\nThe Electrical Engineering and its Automation major in Wuhan University of Technology is oriented to \r\nface the mission of scientific research, technology development, engineering design and technology service, \r\netc in the field of electrical engineering. It is expected to train high-quality professional and technical \r\npersonnel and management personnel with a solid professional foundation, strong adaptability, \r\ninnovation capability as well as global perspective view. \r\n1. Capable of design electrical system solutions, as well as design the practical application system based \r\non circuit principle. \r\n2. Work effectively as a technical backbone or leader in the team. \r\n3. Have good self-cultivation and ethical standards, have willingness and ability to serve the society. \r\n4. The ability and the skills level can be improved and the knowledge can be updated by continuing \r\neducation or other learning channels. \r\n11-1（二） 毕业要求\r\n(1) 工程知识：能够将数学、自然科学、工程基础和专业知识用于解决电气工程及其自动化专业领域\r\n的复杂工程问题。\r\n(2) 问题分析：能够应用数学、自然科学和工程科学的基本原理，识别、表达、并通过文献研究分析\r\n电气工程及其自动化专业领域的复杂工程问题，以获得有效结论。\r\n(3) 设计/开发解决方案：能够设计针对电气工程及其自动化专业领域的复杂工程问题的解决方案，并\r\n能够在设计环节中体现创新意识，考虑社会、健康、安全、法律、文化以及环境等因素。\r\n(4) 研究：能够基于科学原理并采用科学方法对电气工程及其自动化专业领域的复杂工程问题进行研\r\n究，包括设计实验、分析与解释数据、并通过信息综合得到合理有效的结论。\r\n(5) 使用现代工具：能够针对电气工程及其自动化专业领域的复杂工程问题，开发、选择与使用恰当\r\n的技术、资源、现代工程工具和信息技术工具，包括对电气工程及其自动化专业领域的复杂工程\r\n问题的预测与模拟，并能够发现其局限性。\r\n(6) 工程与社会：能够利用工程相关背景知识进行合理分析，评价电气工程及其自动化专业领域的工\r\n程实践和复杂工程问题解决方案对社会、健康、安全、法律以及文化的影响，并理解应承担的责\r\n任。\r\n(7) 环境和可持续发展：能够理解和评价针对电气工程及其自动化专业领域的复杂工程问题的具体工\r\n程实践对环境、社会可持续发展的影响。\r\n(8) 职业规范：具有人文社会科学素养、社会责任感，能够在电气工程及其自动化工程领域的实践中\r\n理解并遵守工程职业道德和规范，履行责任。\r\n(9) 个人和团队：能够在多学科背景下的团队中承担个体、团队成员以及负责人的角色。\r\n(10) 沟通：能够就电气工程及其自动化专业领域的复杂工程问题与业界同行及社会公众进行有效沟通\r\n和交流，包括撰写报告和设计文稿、陈述发言、清晰表达或回应指令。并具备一定的国际视野，\r\n能够在跨文化背景下进行沟通和交流。\r\n(11) 项目管理：理解并掌握工程管理原理与经济决策方法，并能在多学科环境中应用。\r\n(12) 终身学习：具有自主学习和终身学习的意识，有不断学习和适应发展的能力。\r\nEducational Requirement\r\n1. Engineering knowledge: have the ability to solve complex engineering problems in the field of \r\nelectrical engineering using mathematics, natural science, engineering foundation and professional \r\nknowledge. \r\n2. Problem solving: have the ability to identify, express, and analyze through the literature research the \r\ncomplex engineering problems in the field of electrical engineering using fundamental principles in \r\nmathematics, natural science and engineering to get valid conclusions. \r\n3. Design/develop solution: have the ability to design solutions for the complex engineering problems in \r\nthe field of electrical engineering. In the mean time be able to reflect innovation consciousness in the \r\ndesign process, as well as considering the factors in society, health, safety, law, culture and environment. \r\n4. Research: be able to research the complex engineering problems in the field of electrical engineering \r\nbased on science principles and science methods, including developing experiment, analyze and explain \r\ndata, and drawing reasonable and effective conclusions through integrative information. \r\n5. Using modern tools: be able to develop, choose and use appropriate technology, resources, modern \r\nengineering tools and information technical tools to predict and simulate the complex engineering \r\nproblems in the field of electrical engineering and be capable of finding the limitations in it. \r\n6. Engineering and society: be able to use relevant background and knowledge in engineering to analyze \r\nand evaluate the influence of society, health, safety, law, culture and environment to the complex \r\nengineering problems in the field of electrical engineering and understand the responsibilities. \r\n11-27. Environment and sustainable development: be able to understand and evaluate the influence of \r\nengineering practice on the complex engineering problems in the field of electrical engineering to \r\nenvironment and sustainable development. \r\n8. Professional norm: Have humanistic quality and social responsibility. Be able to understand and comply \r\nwith the engineering ethics and norms in the field of electrical engineering practice and carry out the \r\nresponsibilities. \r\n9. Individual and team: be able to carry out the role of individual, team member as well as team leader in a \r\nmultidisciplinary team. \r\n10. Communication: be able to communicate effectively with industry peers and public citizens in the \r\ncomplex engineering problems in the field of electrical engineering. This includes writing reports and \r\ndesign documents, making statement, expressing ideas or respond instructions clearly. Having a sense of \r\ninternational perspective. Being capable of communication in multi-culture background. \r\n11. Project management: be able to comprehend and master the project management principals and \r\neconomic decision method. And be capable of apply it in multidisciplinary environment. \r\n12. Lifelong learning: Consciousness of independent learning and lifelong learning. Have the ability of \r\nconstant learning and adoption to development. \r\n附：培养目标实现矩阵\r\n培养目标 1 培养目标 2 培养目标 3 培养目标 4 \r\n毕业要求 1 √ \r\n毕业要求 2 √ \r\n毕业要求 3 √ \r\n毕业要求 4 √ \r\n毕业要求 5 √ \r\n毕业要求 6 √\r\n毕业要求 7 √\r\n毕业要求 8 √ √\r\n毕业要求 9 √ √ √\r\n毕业要求 10 √ √ √\r\n毕业要求 11 √ √\r\n毕业要求 12 √\r\n二、 专业核心课程与专业特色课程\r\nII Core Courses and Characteristic Courses \r\n（一） 专业核心课程\r\n电路原理，模拟电子技术基础,数字电子技术基础，微机原理及接口技术，电机学，自动控\r\n制原理，电力电子技术，电气工程基础，电磁场与电磁波。\r\nCore Courses: Circuit Theory, Analog Electronic Technology, Digital Electronic Technology, \r\nMicrocomputer Principles and Interfacing Technique, Electric Machinery, Automatic Control Principle, \r\nPower Electronics, Basic Principle of Power System Engineering, Electromagnetic Field and \r\nElectromagnetic Wave. \r\n（二） 专业特色课程\r\n电力系统分析，电力系统继电保护，高电压技术，电力电子装置及控制，电力拖动与控制系统，可\r\n再生能源发电技术，电力市场与电力经济，智能电网新技术，电力系统自动化\r\n11-3Characteristic Courses: Power System Analysis, Protective Relaying in Power Systems, , \r\nHigh-voltage Technology, Power Electronic System and Control, Electric Drive and Control System, \r\nRenewable Energy Technologies, Power Market and Power Economy, Smart Grid Novel Technology, \r\nPower System Automation. \r\n附：毕业要求实现矩阵：\r\n专业核 电气工程及其自动化专业毕业要求\r\n心课程\r\n专业特\r\n色课程 课程名称\r\n（1） （2） （3） （4） （5） （6） （7） （8） （9） （10） （11） (12)\r\n 思想道德修养与法律基础 √ √ √ √ \r\n 中国近现代史纲要 √ √ √ \r\n 毛泽东思想和中国特色社会\r\n主义理论体系概论 √ √ √ √ √ \r\n 马克思主义基本原理 √ √ √ √ √ \r\n 军事理论 √ √ √ √\r\n 体育 √ √ √\r\n 大学英语 √ √\r\n C 程序设计基础 √ √ √ \r\n 计算机基础与 C 程序设计综\r\n合实验 √ √ √ \r\n 专业导论 √ √ √ √ √ √ √ √ √ √\r\n 工程图学 √ √ √ \r\n 高等数学上 √ √ \r\n 高等数学下 √ √ \r\n 概率论与数理统计 √ √ \r\n 线性代数 √ √ \r\n 复变函数与积分变换 √ √ \r\n 大学物理上 √ √ \r\n 大学物理下 √ √ \r\n 物理实验上 √ √ \r\n 物理实验下 √ √ \r\n√ 电路原理上 √ √ \r\n√ 电路原理下 √ √ \r\n 电路原理实验上 √ √ \r\n 电路原理实验下 √ √ \r\n√ 模拟电子技术基础 √ √ \r\n11-4专业核 电气工程及其自动化专业毕业要求\r\n心课程\r\n专业特\r\n色课程 课程名称\r\n（1） （2） （3） （4） （5） （6） （7） （8） （9） （10） （11） (12)\r\n 模拟电子技术基础实验 √ √ \r\n√ 数字电子技术基础 √ √ \r\n 数字电子技术基础实验 √ √ \r\n√ 微机原理及接口技术 √ √ \r\n√ 电机学 1 √ √ \r\n√ 电机学 2 √ √ \r\n√ 自动控制原理 √ √ \r\n√ 电力电子技术 √ √ \r\n√ 电气工程基础 √ √ \r\n√ 电力系统分析 √ √ √ √ \r\n√ 电力电子装置及控制 √ √ √ √ \r\n√ 电力系统继电保护 √ √ √ \r\n√ 电力拖动与控制系统 √ √ √ \r\n 计算机技术基础 √ √ √ \r\n 电气 CAD √ √ √ \r\n√ 电磁场与电磁波 √ √ \r\n 数据库技术 √ √ √ \r\n√ 高电压技术 √ √ \r\n 电机控制技术 √ √ \r\n√ 电力系统自动化 √ √ \r\n√ 可再生能源发电技术 √ √ √ √ \r\n 电气工程综合实验 √ √ √ \r\n√ 电力市场与电力经济 √ √ √ √ √\r\n 现代控制理论 √ √ \r\n 信号与系统 √ √ \r\n 电气仿真技术 √ √ √ \r\n 电能转换与控制技术 √ √ \r\n 电力电子技术在电力系统中的\r\n应用 √ √ √ √ \r\n√ 智能电网新技术 √ √ √ √ \r\n11-5专业核 电气工程及其自动化专业毕业要求\r\n心课程\r\n专业特\r\n色课程 课程名称\r\n（1） （2） （3） （4） （5） （6） （7） （8） （9） （10） （11） (12)\r\n 电力电子装置中的典型传感器\r\n技术 √ √ √ \r\n 电源技术 √ √ \r\n 电气大数据 √ √ √ √ \r\n 电气人工智能 √ √ √ √ \r\n 计算机控制技术 √ √ √ \r\n 配电系统及其自动化 √ √ \r\n DSP 技术与应用 √ √ √ √ √ \r\n 控制系统仿真技术 √ √ √ \r\n 电力系统分析课程设计 √ √ √ √ √ \r\n 电力拖动与控制系统课程设\r\n计 √ √ √ √ √ \r\n 电力系统继电保护课程设计 √ √ √ √ √ \r\n 高电压技术课程设计 √ √ √ √ √ \r\n 电气工程基础课程设计 √ √ √ √ √ \r\n 电力电子技术课程设计 √ √ √ √ √ \r\n 军事训练 √ √ √ \r\n 电工电子实习 √ √ √ √ \r\n 机械制造工程实训 √ √ √ √ \r\n 电工电子基础强化训练 √ √ √ √ \r\n 生产实习 √ √ √ √ \r\n 毕业设计 √ √ √ √ √ √ √ √ √ √\r\n 电气工程综合创新创业 √ √ √ √ √ √\r\n 电气工程综合创新创业实践 √ √ √ √ √ √ √\r\n11-6三、 课程教学进程图\r\nⅢ Teaching Process Map \r\n第三学年 第四学年\r\n第一学期 第二学期 第一学期 第二学期\r\n毕业\r\n设计\r\n论文\r\n电机学2\r\n自动控制原理\r\n电力电子技术\r\n电气工程基础\r\n可再生能源\r\n发电技术\r\n智能电网新技术\r\n电力系统继电保护\r\n电力系统自动化\r\n电力市场与电力经济 高电压技术\r\n配电系统自动化\r\n电气工程综合实验\r\n电力电子装置及控制\r\n电力拖动与控制系统\r\n电力电子技术在电\r\n力系统中的应用\r\n现代控制理论\r\n电机控制技术\r\n电源技术\r\n第一学期\r\n大学英语1\r\n高等数学上\r\n第二学期\r\n大学英语2\r\n高等数学下\r\n线性代数\r\n大学物理上\r\n第一学年 第二学年\r\n第一学期\r\n大学英语3\r\n复变函数与积\r\n分变换B\r\n大学物理下\r\n物理实验上\r\n第二学期\r\n概率论与数理\r\n统计\r\n物理实验下\r\n电路原理下\r\n电路原理上\r\n电路原理实\r\n实验上 电路原理\r\n实验下\r\n模拟电子技术\r\n基础\r\n模拟电子技术\r\n基础实验\r\n数字电子技术\r\n基础\r\n数字电子技术\r\n基础实验\r\n电磁场与电磁波\r\n电机学1\r\n专业导论\r\n工程图学\r\n军事理论\r\n思想道德修养\r\n与法律基础\r\nC程序设计基础\r\n中国近现代史\r\n纲要\r\n计算机基础与C程序设\r\n计综合实验\r\n体育1\r\n通识类选修\r\n课程\r\n体育2\r\n通识类选修\r\n课程\r\n体育4\r\n毛泽东思想和\r\n中国特色社会\r\n主义体系概论\r\n个性选修课程\r\n通识类选修\r\n课程\r\n体育3\r\n马克思主义基\r\n本原理\r\n个性选修课程\r\n个性选修课程\r\n微机原理及接\r\n口技术\r\n通识类选修\r\n课程\r\n个性选修课程\r\n通识类选修\r\n课程\r\n通识类选修\r\n个性选修课程\r\n课程\r\n个性选修课程\r\n信号与系统\r\n发电厂电气部分\r\n电气工程综合创\r\n新创业\r\n军事训练\r\n电力系统分析\r\n电力电子装置中的典型传\r\n感器技术\r\n电机与电力\r\n电子模块\r\n电力系统\r\n模块\r\n电工电子实习 机械制造工程 实训\r\n电气工程基础课程\r\n设计\r\n电力电子技术课程\r\n设计\r\n生产实习\r\n电机与电力\r\n电子模块\r\n电力电子装置及\r\n控制课程设计\r\n电力拖动及控制系\r\n统课程设计\r\n电力系统\r\n模块\r\n电力系统分析课程\r\n设计\r\n电力系统继电保护\r\n课程设计\r\n电气仿真技术\r\n电能转换与控制技术\r\nDSP技术与应用\r\n电机控制系统半实\r\n物仿真课程设计\r\n高电压技术\r\n课程设计\r\n电气工程综合创\r\n新创业实践课程\r\n电气大数据\r\n电气人工智能\r\n大学英语4\r\n11-7四、 理论教学建议进程表\r\nⅣ Theory Course Schedule\r\n学时分配 Including 课程编号\r\nCourse \r\nNumber\r\n课 程 名 称\r\nCourse Title\r\n学分\r\nCrs 总学时\r\nTot hrs.\r\n实验\r\nExp.\r\n上机\r\nOperation\r\n实践\r\nPractice\r\n课外\r\nExtracur\r\n建议\r\n修读\r\n学期\r\nSuggested \r\nTerm\r\n先修课程\r\nPrerequisite \r\nCourse\r\n（一）通识教育必修课程\r\nGeneral Education Required Courses \r\n4220001110 思想道德修养与法律基础 3 48 8 1 \r\nMorals, Ethics and Fundamentals of Law \r\n4220002110 中国近现代史纲要 2 32 1 \r\nOutline of Contemporary and Modern \r\nChinese History \r\n4220003110 毛泽东思想和中国特色社会主义理论体\r\n系概论 4 96 32 3 \r\nIntroduction to Mao Zedong Thought and \r\nSocialism with Chinese Characteristics \r\n4220005110 马克思主义基本原理 3 48 8 4 \r\nMarxism Philosophy \r\n1060003130 军事理论 1 32 16 2 \r\nMilitary Theory \r\n4210001170 体育 1 1 26 1 \r\n Physical EducationⅠ \r\n4210002170 体育 2 1 34 2 \r\n Physical Education Ⅱ \r\n4210003170 体育 3 1 34 3 \r\n Physical Education Ⅲ \r\n4210004170 体育 4 1 34 4 \r\n Physical Education Ⅳ \r\n4030002180 大学英语 1 3 60 12 1 \r\n College English 1 \r\n4030003180 大学英语 2 2 44 12 2 大学英语 1\r\n College English Ⅱ \r\n4030004180 大学英语 3 2 44 12 3 大学英语 2\r\n College English Ⅲ \r\n4030004180 大学英语 4 2 44 12 4 大学英语 3\r\n College English IV \r\n4120335170 C 程序设计基础 2 32 2 \r\nFundamentals of Computer Program \r\nDesign(C) \r\n4120336170 计算机基础与 C 程序设计综合实验 1 32 32 2 \r\nComputer Foundation and C Programming \r\nComprehensive Experiment \r\n小 计 Subtotal 29 640 32 0 64 48 \r\n11-8学时分配 Including 课程编号\r\nCourse \r\nNumber\r\n课 程 名 称\r\nCourse Title\r\n学分\r\nCrs 总学时\r\nTot hrs.\r\n实验\r\nExp.\r\n上机\r\nOperation\r\n实践\r\nPractice\r\n课外\r\nExtracur\r\n建议\r\n修读\r\n学期\r\nSuggested \r\nTerm\r\n先修课程\r\nPrerequisite \r\nCourse\r\n（二）通识教育选修课程\r\nGeneral Education Elective Courses\r\n创新创业类\r\nInnovation and Entrepreneurship Courses\r\n人文社科类\r\nArts and Social Science Courses\r\n经济管理类\r\nEconomy and Management Courses\r\n科学技术类\r\nScience and Technology Courses\r\n艺术体育类\r\nArt and Physical Education Courses\r\n要求至少取得 9 个学分，且必须选修艺术体育类课程中的艺术类\r\n相关课程并取得至少 2 个学分，在创新创业类课程中至少选修一\r\n门课程，在人文社科类或经济管理类课程中至少选修一门。\r\nStudents are required to abtain at least 9 credits，which must cotain \r\nart courses of 2 credits from the category of Art and Physical \r\nEducation Courses,at least one course from the category of \r\nInnovation and Entrepreneurship Courses, and at least one course \r\nfrom the category of Arts and Social Science Courses or the \r\ncategory of Economy and Management Courses. \r\n（三）专业教育必修课程\r\nBasic Disciplinary RequiredCourses\r\n4100211170 电气专业导论 1 16 1 \r\nIntroduction to Electrical Engineering and \r\nAutomation \r\n4080373170 工程图学 B 3.5 72 16 1 \r\nEngineering Graphics \r\n4050063110 高等数学 A 上 5 80 1 \r\nAdvanced Mathematics Ⅰ\r\n4050064110 高等数学 A 下 5 80 2 高等数学上\r\nAdvanced Mathematics Ⅱ\r\n4050229110 线性代数 2.5 40 2 \r\nLinear Algebra \r\n4050021110 大学物理 A 上 3.5 56 2 \r\nPhysics AⅠ\r\n4050022110 大学物理 A 下 3.5 56 3 大学物理上\r\nPhysics Ⅱ\r\n4050466130 物理实验 A 上 1 32 32 3 \r\nPhysics Lab. Ⅰ\r\n4050467130 物理实验 A 下 1 32 32 4 物理实验上\r\nPhysics Lab. Ⅱ\r\n4100030110 电路原理 A 上 3 48 2 \r\nCircuit Theory Ⅰ\r\n4100032110 电路原理 A 实验上 0.5 16 16 2 \r\nCircuit Theory Exp Ⅰ\r\n4100031110 电路原理 A 下 3 48 3 电路原理上\r\nCircuit Theory Ⅱ\r\n4100033110 电路原理 A 实验下 0.5 16 16 3 电路原理实\r\n验上\r\nCircuit Theory Exp Ⅱ\r\n11-9学时分配 Including 课程编号\r\nCourse \r\nNumber\r\n课 程 名 称\r\nCourse Title\r\n学分\r\nCrs 总学时\r\nTot hrs.\r\n实验\r\nExp.\r\n上机\r\nOperation\r\n实践\r\nPractice\r\n课外\r\nExtracur\r\n建议\r\n修读\r\n学期\r\nSuggested \r\nTerm\r\n先修课程\r\nPrerequisite \r\nCourse\r\n4050052110 复变函数与积分变换 B 3 48 3 \r\nComplex Function and Integral Transform \r\n4110049110 模拟电子技术基础 B 3.5 56 3 \r\nAnalog Electronic Technology \r\n4110051110 模拟电子技术基础实验 0.5 16 16 3 \r\nAnalog Electronic Exp \r\n4050058110 概率论与数理统计 B 3 48 4 \r\nProbability and Mathematical Statistics \r\n4110067110 数字电子技术基础 B 3.5 56 4 \r\nDigital Electronic Technology \r\n4110068110 数字电子技术基础实验 0.5 16 16 4 \r\nDigital Electronic Experiment \r\n4100241170 电磁场与电磁波 D 1.5 24 4 \r\nElectromagnetic Field and Electromagnetic \r\nWave \r\n4100242170 电机学 A1 3 48 8 4 \r\nElectric Machinery I \r\n4100243170 电机学 A2 3 48 8 5 电机学 1 \r\nElectric Machinery Ⅱ\r\n4100244170 自动控制原理 A 3 48 8 5 \r\nAutomatic Control Principle \r\n4100245170 微机原理及接口技术 C 3 48 8 5 \r\nMicrocomputer Principles and Interfacing \r\nTechnique \r\n4100246170 电力电子技术 D 3.5 56 12 5 \r\nPower Electronics \r\n4100247170 电气工程基础 B 3 48 8 5 \r\nBasic Principle of Power System \r\nEngineering \r\n4100248170 电气工程综合创新创业 1 16 7 \r\nInnovation and Entrepreneurship Course \r\non Electrical Engineering \r\n小 计 Subtotal 68 1168 180 0 0 16 \r\n（四）专业教育选修课程\r\nSpecialized Elective Courses\r\n电机与电力电子模块\r\nPower Electronic System and Control\r\n4100141130 电力电子装置及控制 C 2.5 40 8 6 \r\nPower Electronic System and Control \r\n4100023110 电力拖动与控制系统 A 3.5 56 8 6 \r\nElectric Drive and Control System \r\n11-10学时分配 Including 课程编号\r\nCourse \r\nNumber\r\n课 程 名 称\r\nCourse Title\r\n学分\r\nCrs 总学时\r\nTot hrs.\r\n实验\r\nExp.\r\n上机\r\nOperation\r\n实践\r\nPractice\r\n课外\r\nExtracur\r\n建议\r\n修读\r\n学期\r\nSuggested \r\nTerm\r\n先修课程\r\nPrerequisite \r\nCourse\r\n4100013110 电机控制技术 2 32 6 \r\nMotor Control Technique \r\n4100249170 电能转换与控制技术 A 2.5 40 6 \r\nPower Conversion and Control Technique\r\n电力系统模块\r\nElectric Power System\r\n4100250170 高电压技术 A 3 48 6 \r\nHigh-voltage Technology \r\n4100025110 电力系统分析 B 4.5 72 12 6 \r\nPower System Analysis \r\n4100026110 电力系统继电保护 B 3 48 8 6 \r\nProtective Relaying in Power Systems \r\n公共选修部分 \r\n4110094110 信号与系统 B 3 48 8 4 \r\nSignal and System \r\n4100266170 电气大数据 1 16 5 \r\nElectrical Big Data \r\n4100027110 电力系统自动化 A 3.5 56 8 6 \r\nAutomatic Techniques in Power System \r\n4100131130 发电厂电气部分 2 32 6 \r\nElectrical Systems of Power Plants \r\n4100251170 电力电子装置中的典型传感器技术 2.5 40 7 \r\nTypical sensor technology applied in \r\npower \r\n4100252170 电力电子在电力系统中的应用 2.5 40 7 \r\nPower Electronics in Power Systems \r\n4100253170 电源技术 A 3 48 7 \r\nPower Supply Technologies \r\n4100037110 电气工程综合实验 1 32 32 7 \r\nAutomation Experiment \r\n4100022110 电力市场与电力经济 2 32 7 \r\nPower Market and Power Economy \r\n4100267170 电气人工智能 1 16 7 \r\nElectrical Artificial Intelligence \r\n4100051110 配电系统及其自动化 2 32 7 \r\nDistribution Systems and Automation \r\n小 计 Subtotal 44.5 728 84 0 0 0 \r\n11-11学时分配 Including 课程编号\r\nCourse \r\nNumber\r\n课 程 名 称\r\nCourse Title\r\n学分\r\nCrs 总学时\r\nTot hrs.\r\n实验\r\nExp.\r\n上机\r\nOperation\r\n实践\r\nPractice\r\n课外\r\nExtracur\r\n建议\r\n修读\r\n学期\r\nSuggested \r\nTerm\r\n先修课程\r\nPrerequisite \r\nCourse\r\n修读说明：专业选修课程要求至少选修 20 学分，电机与电力电子模块和电力系统模块并行上课，学生必须选择其一进\r\n行选修。学分不满 20 的通过其余选修课补齐总学分，选修另一模块课程等同选修课学分。\r\nNOTE: Minimum subtotal credits: 17. The students are required to take at least 20 credits from Specialized Elective \r\nCourses , the modules of Power Electronic System and the modules Control and Electric Power System are taught in in \r\nparallel. Students must choose one of them for elective courses. The students whose credits are less than 20 will be filled by the \r\nremaining elective courses, and the other modules will be equivalent to elective credits.\r\n（五）个性课程\r\nPersonalized Electice Courses\r\n4100183160 电气仿真技术 2 32 16 5 \r\nElectrical Simulation \r\n4100048110 可再生能源发电技术 A 2.5 40 8 5 \r\nRenewable Energy Technologies \r\n4100158160 智能电网新技术 2 32 6 \r\nSmart Grid Novel Technology \r\n4100001110 DSP 技术与应用 2 32 4 7 \r\nDSP Technology & Application \r\n4100058110 现代控制理论 2 32 6 7 \r\nModern Control Theory \r\n小 计 Subtotal 10.5 168 18 16 0 0 \r\n修读说明：学生从以上个性课程和学校发布的其它个性课程目录中选课，要求至少选修 6 学分。\r\nNOTE: Sudents can select courses from above and the other personalized courses in catalog, and are required to obtain\r\nat least 6 credits.\r\n五、 集中性实践教学环节\r\nⅤ Practice Schedule\r\n课程编号\r\nCourse \r\nNumber \r\n实践环节名称\r\nPractice Courses Name \r\n学分\r\nCrs \r\n周数\r\nWeeks \r\n建议修读学期\r\nSuggested Term \r\n1060002110 军事训练 1.5 3 1 \r\nMilitary Training \r\n4100068110 电工电子实习 A 2 2 3 \r\nPractice of Electrical Engineering & Electronics \r\n4080151110 机械制造工程实训 C 2 2 4 \r\nTraining on Mechanical Manufacturing Engineering \r\n4100127120 电工电子基础强化训练 1 1 4(暑期) \r\nFoundation Strengthening Training on Electronic & \r\nElectrics \r\n4100254170 电力电子技术课程设计 1.5 1.5 5 \r\nCourse Design of Power Electronic Technology \r\n4100255170 电气工程基础课程设计 1.5 1.5 5 \r\nCourse Design of Electrical Engineering Basic \r\n11-12课程编号\r\nCourse \r\nNumber \r\n实践环节名称\r\nPractice Courses Name \r\n学分\r\nCrs \r\n周数\r\nWeeks \r\n建议修读学期\r\nSuggested Term \r\n4100081110 生产实习 3 3 6(暑期) \r\nPractice of Manufacture \r\n4100256170 电气工程创新创业实践 1 1 7 \r\nInnovation and Entrepreneurship Practice \r\n4100257170 毕业论文 10 17 8 \r\n Graduation Thesis \r\n电机与电力电子模块\r\nPower Electronic System and Control \r\n4100072110 电力电子装置及控制课程设计 1.5 1.5 6 \r\nCourse Design on Power Electronic System and \r\nControl A \r\n4100258170 电机控制系统半实物仿真课程设计 1.5 1.5 6 \r\nCourse Design on Motor control system semi-material\r\n4100073110 电力拖动与控制系统课程设计 1.5 1.5 6 \r\nCourse Design on Electric Drive and Control System\r\n电力系统模块\r\nElectric Power System\r\n4100259170 高电压技术课程设计 1.5 1.5 6 \r\nCourse Design on High Voltage Technology \r\n4100260170 电力系统分析课程设计 1.5 1.5 6 \r\nCourse Design on Power System Analysis \r\n4100075110 电力系统继电保护课程设计 1.5 1.5 6 \r\nCourse Design on Protective Relaying in Power \r\nSystems \r\n小 计 Subtotal 28 41 \r\n六、其它要求\r\nⅥ Recommendations on Course Studies \r\n1、《形势与政策》和《心理健康教育》课程为课外必修课程，分别计 2 个和 1 个课外学分。 \r\n2、学生选修的通识选修课程和从学校发布的个性课程目录中选修的个性课程，要求与本专业培\r\n养方案内设置的课程内容不重复。 \r\n1.Situation & Policy (2 credits) and Mental Health Education (1 credit) are the required extracurricular \r\ncourses. \r\n2.The selected General Education Elective Courses and Personalized Elective Courses from the courses \r\nprogram by university must be different from the major undergraduate education plan in content. \r\n 学院教学责任人：周新民\r\n 专业培养方案责任人：夏泽中，侯慧，朱国荣\r\n11-13自动化专业 2017 版本科培养方案\r\nUndergraduate Education Plan for Specialty in Automation(2017) \r\n专业名称 自动化 主干学科 控制科学与工程、电气工程、计算机科\r\n学与技术\r\nMajor Automation Major Disciplines Control Science and Engineering, \r\nElectrical Engineering, Computer Science \r\nand Technology\r\n计划学制 四年 授予学位 工学学士\r\nDuration 4 Years Degree Granted Bachelor of Engineering\r\n最低毕业学分规定\r\nGraduation Credit Criteria \r\n课程类别\r\nCourse \r\nClassification\r\n课程性质\r\nCourse Nature \r\n通识教育课程\r\nPublic Basic \r\nCourses\r\n专业教育课程\r\nSpecialized \r\nCourses\r\n个性课程\r\nPersonalized \r\nCourse\r\n集中性实践\r\nPractice \r\nCourses\r\n课外学分\r\nStudy Credit \r\nafter Class\r\n总学分\r\nTotal\r\nCredits\r\n必修课\r\nRequired Courses 29 68.5 \\ 26.5 \\ \r\n选修课\r\nElective Courses 9 21 6 \\ 10 \r\n170 \r\n一、 培养目标与毕业要求\r\nⅠEducational Objectives&Requirement \r\n（一） 培养目标\r\n武汉理工大学自动化专业面向自动化领域的科学研究、技术开发、工程设计和技术服务需求，培养\r\n赋有健全人格、人文社会科学素养、自然科学基础和专业知识扎实、具有快速适应能力、创新创业意识、\r\n实干精神和国际化视野的高素质专业技术人才和管理人才。\r\n毕业 5 年内预期达到的目标如下：\r\n(1) 能根据具体问题设计自动化系统解决方案，并能有效地运用专业知识来保障其实施和达成；\r\n(2) 能在团队中开展有效的工作和交流，并成为技术骨干或部门负责人，且有效发挥作用；\r\n(3) 具有良好的修养和职业道德；\r\n(4) 在与自动化及相关专业领域成功就业/创业并具有竞争优势，或有能力完成研究生学业；\r\n(5) 有意愿并有能力为本地、本国乃至全球的公众服务。\r\nIeducational objectives \r\nThe automation major in Wuhan University of Technology is oriented to the requirements of scientific \r\nresearch, technology development, engineering design and technology service, etc. in the field of automation. \r\nIt is expected to cultivate the high-qualified professionals and management talents with a health personality, \r\nhumanities and social science literacy, solid professional foundation and skill, strong adaptability, a sense of \r\ninnovation and entrepreneurship, a spirit of work hard as well as a global perspective view. \r\n1. Capable of designing automation system solutions for specific task, as well as guarantee the \r\nimplementation and achievement by means of professional knowledge. \r\n11-142. Worked effectively and efficiently via cooperation and communication as a key technician or department \r\nhead. \r\n3. Have good self-cultivation and ethical standards. \r\n4. Succeed in being employed in the field of automation or related/ having own business, and show a \r\ncompetitive advantage. Graduates have outstanding abilityin engineering practice. \r\n5. Committed and able to provide public services in local, national and global society. \r\n（二） 毕业要求\r\n(1) 工程知识：能够将数学、自然科学、工程基础和专业知识用于解决自动化专业领域的复杂工程问题。\r\n(2) 问题分析：能够应用数学、自然科学和工程科学的基本原理，识别、表达、并通过文献研究分析自\r\n动化专业领域的复杂工程问题，以获得有效结论。\r\n(3) 设计/开发解决方案：能够设计针对自动化专业领域的复杂工程问题的解决方案，设计/开发满足特\r\n定需求的控制算法、控制策略、自动化装置、自动化系统和信息处理方案或技术，并能够在设计环\r\n节中体现创新意识，考虑社会、健康、安全、法律、文化以及环境等因素。\r\n(4) 研究：能够基于科学原理并采用科学方法对自动化专业领域的复杂工程问题进行研究，包括设计实\r\n验、分析与解释数据、并通过信息综合得到合理有效的结论。\r\n(5) 使用现代工具：能够针对自动化专业领域的复杂工程问题，开发、选择与使用恰当的技术、资源、\r\n现代工程工具和信息技术工具，包括对自动化专业领域的复杂工程问题的预测与模拟，并能够理解\r\n其局限性。\r\n(6) 工程与社会：能够基于工程相关背景知识进行合理分析，评价自动化专业工程实践和复杂工程问题\r\n解决方案对社会、健康、安全、法律以及文化的影响，并理解应承担的责任。掌握工业控制系统的\r\n设计方法、技术及相关开发平台，能理解工业控制系统的设计方法和步骤。并能在工程设计中能综\r\n合考虑经济、环境、法律、安全和伦理等制约因素。\r\n(7) 环境和可持续发展：能够理解和评价针对自动化专业领域的复杂工程问题的具体工程实践对环境、\r\n社会可持续发展的影响。\r\n(8) 职业规范：具有人文社会科学素养、社会责任感，能够在自动化工程实践中理解并遵守工程职业道\r\n德和规范，履行责任。\r\n(9) 个人和团队：能够在多学科背景下的团队中承担个体、团队成员以及负责人的角色。\r\n(10) 沟通：能够就自动化专业领域的复杂工程问题与业界同行及社会公众进行有效沟通和交流，包括撰\r\n写报告和设计文稿、陈述发言、清晰表达或回应指令。并具备一定的国际视野，能够在跨文化背景\r\n下进行沟通和交流。\r\n(11) 项目管理：理解并掌握工程管理原理与经济决策方法，并能在多学科环境中应用。\r\n(12) 终身学习：具有自主学习和终身学习的意识，有不断学习和适应发展的能力。\r\nIIGraduation Requirements：\r\n1. Engineering knowledge: with the ability to solve complex engineering problems in the field of \r\nautomation by applying mathematics, natural science, engineering foundation and professional \r\nknowledge. \r\n2. Problem solving: with the ability to identify, express, and analyze the complex engineering problems in \r\nthe field of automation through the literature review methods by applying fundamental principles in \r\n11-15mathematics, natural science and engineering to get valid conclusions. \r\n3. Design/develop solution: with the ability to design solutions for the complex engineering problems in the \r\nfield of automation.The ability to design /develop control algorithm/strategy, automation equipment, \r\nsolution and related technology of automation system and information system to meet the specific \r\nrequirements. Meanwhile, graduates are supposed to design with innovative inspiration, as well as \r\nconsidering the relationship with society, health, safety, law, culture and environment. \r\n4. Research: with the ability to research the complex engineering problems in the field of automation based \r\non science principles and science methods, including developing experiment, analyzing and explaining \r\ndata, and drawing reasonable and effective conclusions through integrative information. \r\n5. Using modern tools: with the ability to develop, choose and use appropriate technology, resources, \r\nmodern engineering tools and information technical tools to predict and simulate the complex engineering \r\nproblems in the field of automation and be capable of finding the associative limitations. \r\n6. Engineering and society: with the ability to analyze and evaluate the influence on society, health, safety, \r\nlaw, culture and environment from the complex engineering practice/solution in the field of automation \r\nby applying the project background and relevant knowledge. Also, responsibility should be understood. \r\n7. Environment and sustainable development: with the ability to understand and evaluate the influence on \r\nenvironment and sustainable development, which is caused by engineering practice of the complex \r\nengineering projects in the field of automation. \r\n8. Professional norm: be with humanistic quality and social responsibility. With the ability to understand \r\nand comply with the engineering ethics and norms in the field of automatic engineering practice and take \r\nthe responsibilities. \r\n9. Individual and team: with the ability to competently play the role of individual, team member as well as \r\nteam leader in a multidisciplinary team. \r\n10. Communication: with the ability to communicate effectively with industry peers and public citizens \r\nabout the complex engineering problems in the field of automation. It includes writing reports and \r\ndesigning documents, making statement, expressing ideas or respond instructions clearly. Graduates are \r\nsupposed to be with international perspective and be capable of communicating in a multi-culture \r\nbackground. \r\n11. Project management: with the ability to comprehend and master the project management principals and \r\neconomic decision method, which can be applied in a multidisciplinary environment. \r\n12. Lifelong learning: be aware of independent learning and lifelong learning. With the ability to keep \r\nlearning and adapt to the development. \r\n附：培养目标实现矩阵\r\n培养目标 1 培养目标 2 培养目标 3 培养目标 4 培养目标 5 \r\n毕业要求 1 √     \r\n毕业要求 2 √       \r\n毕业要求 3 √      √ √\r\n毕业要求 4 √  √   \r\n毕业要求 5 √     \r\n毕业要求 6 √ √ √\r\n毕业要求 7 √    √\r\n毕业要求 8 √    √\r\n毕业要求 9 √    \r\n11-16培养目标 1 培养目标 2 培养目标 3 培养目标 4 培养目标 5 \r\n毕业要求 10 √ √ √\r\n毕业要求 11 √    \r\n毕业要求 12 √ √\r\n二、 专业核心课程与专业特色课程\r\nIICore Courses and Characteristic Courses \r\n（一） 培养特色：\r\n采用宽口径、厚基础、重实践、聚前沿的人才培养模式，突出“嵌入式计算、自动化执行、智\r\n能化决策”的专业核心，与计算机、信息技术深度融合的特色。凝练“信息与物联网”和“工控与\r\n智能机器人”两个子方向、强调综合知识运用。\r\nIn the program, college students are supposed to with broad extension and solid foundation of \r\nprofessional knowledge, endowed with high practical ability, acquaint themselves with the knowledge on \r\nthe cutting edge. It highlights the professional core as “embedded computing, automated execution, \r\nintelligent decision making”. The specialty is deeply integrated with computer science and information \r\ntechnology.The plan focus on two sub-direction“information and Internet of Thing”, “industrial \r\ncontroland intelligent robot”, emphasizing the application of comprehensive knowledge. \r\n（二） 专业核心课程：\r\n电路原理，电子技术，自动控制原理，微处理器与微控制器，电力电子技术与运动控制系统，\r\n计算机过程控制系统，智能机器人、数据通讯与计算机网络、传感与检测技术、程序设计方法、电\r\n机与拖动基础、电器控制与可编程序控制器、物联网技术与工程。\r\nCore Courses: Circuit Theory, Electronics, Automatic Control Principle,Micro-computer processor \r\nand Microcomputer controller，Power Electronics & Motion Control System，Computer Process Control \r\nSystem，Introduction to intelligent robotics, Data communication and computer network, Sensor and \r\nDetecting Technique, Introduction to programming design, Basic of Electric Machines and Electric, \r\ncontrol apparatus and PLC, Technology and engineering of internet of Things. \r\n（三） 专业特色课程：\r\n控制工程实践与系统仿真、图像处理与机器视觉、工业机器人编程与实践、嵌入式系统与应用\r\n（I）、射频识别（RFID）原理与应用、、自动化综合实验\r\nCharacteristic Courses: Control Engineering Practice and System Simulation, Image Processing and \r\nMachine Vision, Programming and Practice of Industrial robot, embedded system and application（I）, \r\nPrinciple and Application of RFID, , Automation Experiment \r\n附：毕业要求实现矩阵：\r\n专业 自动化专业毕业要求\r\n核心\r\n课程\r\n专业\r\n特色\r\n课程\r\n课程名称\r\n（1） （2） （3） （4） （5） （6） （7） （8） （9） （10） （11） （12）\r\n 思想道德修养与法律基础 √ √ \r\n 中国近现代史纲要 √ \r\n 毛泽东思想和中国特色社会主\r\n义理论体系概论 √ √ \r\n11-17专业 自动化专业毕业要求\r\n核心\r\n课程\r\n专业\r\n特色\r\n课程\r\n课程名称\r\n（1） （2） （3） （4） （5） （6） （7） （8） （9） （10） （11） （12）\r\n 马克思主义基本原理 √ √ \r\n 军事理论 √ \r\n 体育 1 √ \r\n 体育 2 √\r\n 体育 3 √\r\n 体育 4 √\r\n 大学英语 1 √ √\r\n 大学英语 2 √ √\r\n 大学英语 3 √ √\r\n 大学英语 4 √ √\r\n C 程序设计基础 √ √ √ \r\n 计算机基础与 C 程序设计综合\r\n实验 √ √ √ √ \r\n 专业导论 √ √ √       √\r\n 工程图学 √ √ \r\n 高等数学上 √ \r\n 高等数学下 √ \r\n 概率论与数理统计 √ \r\n 线性代数 √ \r\n 复变函数与积分变换 √ \r\n 大学物理上 √ \r\n 大学物理下 √ \r\n 物理实验上 √ √ \r\n 物理实验下 √ √ \r\n√ 电路原理上 √ √ √ √ \r\n√ 电路原理下 √ √ √ √ \r\n 电路原理实验上 √ √ √ \r\n 电路原理实验下 √ √ √ \r\n√ 模拟电子技术基础 √ √ √ √ \r\n 模拟电子技术基础实验 √ √ \r\n11-18专业 自动化专业毕业要求\r\n核心\r\n课程\r\n专业\r\n特色\r\n课程\r\n课程名称\r\n（1） （2） （3） （4） （5） （6） （7） （8） （9） （10） （11） （12）\r\n√ 数字电子技术基础 √ √ √ √ \r\n 数字电子技术基础实验 √ √ \r\n 面向对象程序设计（C++） √ √ √ √\r\n 电气 CAD √ √ √ \r\n 信号处理与数据分析 √ √ √ √ √ √\r\n 数据库与信息系统 √ √ √ √ √ √ √\r\n√ 程序设计方法 √ √ √ √\r\n√ 数据通讯与计算机网络 √ √ √ √ √ √ √\r\n√ 电力电子技术 √ √ √ √ √ √ \r\n√ 微处理器与微控制器 √ √ √ √ √\r\n√ 电机与拖动基础 √ √ √ √ \r\n√ 传感与检测技术 √ √ √ √ √ √ √\r\n√ 智能机器人 √ √ √ √ √\r\n√ 计算机过程控制系统 √ √ √ √     √ √\r\n√ 运动控制系统 √ √ √ √ √     √ √\r\n√ 电力电子与电气拖动实验 √ √ √ √     √ \r\n√ 微处理器与微控制器实验 √ √ √     √ √\r\n 自动化专业工业 4.0 认知实验 √ √     √ √ √\r\n 现代控制理论 √ √ √ √ √ √\r\n√ 控制工程实践与系统仿真 √ √ √ √ √ √ √\r\n√ 图像处理与机器视觉 √ √ √ √ √ √ √\r\n 电子设计自动化 √ √ √ √ √ √ \r\n√ 嵌入式系统与应用 √ √ √ √ √ √ √\r\n DSP 技术与应用 √ √ √ √ √ √\r\n 人工智能与机器学习 √ √ √ √ √\r\n 项目管理 √ √ √ √\r\n 模式识别概论 √ √ \r\n 电器控制与可编程序控制器 √ √ √ √ √\r\n 工厂供电与节能技术 √ √ √ √ √\r\n11-19专业 自动化专业毕业要求\r\n核心\r\n课程\r\n专业\r\n特色\r\n课程\r\n课程名称\r\n（1） （2） （3） （4） （5） （6） （7） （8） （9） （10） （11） （12）\r\n√ 工业机器人编程与实践 √ √ √ √ √ √ √\r\n√ 自动化综合实验 √ √ √ √\r\n√ 物联网技术与工程 √ √ √\r\n 智能仪器仪表 √√ √ √\r\n√ 射频识别（RFID）原理与应用 √ √ √ √ √ √\r\n 军事训练 √ \r\n 电工电子实习 √ √ √ √ √ √ \r\n 机械制造工程实训 √ \r\n 电工电子基础强化训练 √ √ √ √ √ √ \r\n 控制工程综合实践 \r\n 物联网综合实践\r\n 智能机器人综合实践\r\n 生产实习 √ √ √ √ \r\n 毕业设计 √ √ √ √ √ √ √ √\r\n√ 自动控制原理 √ √ √ √ √ √ √\r\n 手机与 web 系统编程 √ √ √ √ √\r\n 科学研究方法与学术论文写作 √ √ √ √ \r\n 创新创业实践 \r\n 创新创业与自动化前沿 √ √ √ √ √ √\r\n三、 课程教学进程图\r\nⅢTeaching Process Map \r\n11-20第三学年 第四学年\r\n第一学期 第二学期 第一学期 第二学期\r\n毕业\r\n设计\r\n自动化综合实验\r\n第一学期\r\n大学英语1\r\n高等数学上\r\n第二学期\r\n大学英语2\r\n高等数学下\r\n线性代数\r\n大学物理1\r\n第一学年 第二学年\r\n第一学期\r\n大学英语3\r\n复变函数与积\r\n分变换\r\n大学物理2\r\n物理实验1\r\n第二学期\r\n概率论与数理\r\n统计\r\n物理实验2\r\n电路原理2\r\n电路原理1\r\n电路原理实\r\n验1 电路原理\r\n实验2\r\n模拟电子技术\r\n基础\r\n模拟电子技术\r\n基础实验\r\n数字电子技术\r\n基础B\r\n数字电子技术\r\n基础实验\r\n专业导论\r\nC程序设计基础\r\n工程图学\r\n计算机基础与\r\n思想道德修养\r\n与法律基础\r\nC\r\n程序设计实验\r\n中国近现代史\r\n纲要\r\n体育1\r\n通识类选修\r\n课程\r\n体育2\r\n电气CAD 数据库 与信息系统\r\n通识类选修\r\n课程\r\n体育4\r\n毛泽东思想和\r\n中国特色社会\r\n主义体系概论\r\n个性选修课程\r\n通识类选修\r\n课程\r\n体育3\r\n马克思主义基\r\n本原理\r\n个性选修课程 个性选修课程\r\n通识类选修\r\n课程\r\n个性选修课程\r\n通识类选修\r\n课程\r\n个性选修课程\r\n通识类选修\r\n课程\r\n个性选修课程\r\n军事理论 电工电子实习 机械制造工程实训 电工电子基础 强化训练\r\n物联网综合实\r\n践\r\n生产实习\r\n数据通讯与计\r\n算机网络\r\n面向对象程序设\r\n计（C++语言）\r\n电机与拖动基础\r\n自动控制原理 传感与检测技\r\n术\r\n工业机器人编\r\n程与实践\r\n控制工程实践\r\n现代控制理论\r\n与系统仿真\r\n智能机器人\r\n物联网技术与\r\n工程\r\n嵌入式系统与应\r\n用(I)\r\n运动控制系统\r\n计算机过程控制\r\n系统\r\nDSP技术与应用\r\n智能仪器仪表\r\n模式识别概论\r\n程序设计方法C\r\n信号处理与数\r\n据分析\r\n电气控制与可编\r\n程控制器\r\n电力电子技术\r\n电力电子与电气\r\n拖动实验\r\n微处理器与微控\r\n制器B实验\r\n射频识别原理应\r\n用\r\n手机与web系统\r\n编程\r\n自动化专业工业\r\n4.0认知性实验\r\n军事训练\r\n工厂供电与节能\r\n技术\r\n控制工程综合\r\n实践\r\n创新创业与自动\r\n化前沿\r\n过程控制系统\r\n创新创业实践\r\n综合实验\r\n微处理器与微控\r\n制器\r\n电子设计自动化\r\n图像处理与机器\r\n视觉\r\n智能机器人综\r\n合实践\r\n人工智能与机器\r\n学习\r\n科学研究方法与\r\n学术论文写作\r\n项目管理\r\n大学英语4\r\n11-21四、 理论教学建议进程表\r\nⅣ    Theory Course Schedule\r\n学时分配 Including 课程编号\r\nCourse\r\nNumber\r\n课 程 名 称\r\nCourse Title\r\n学分\r\nCrs 总学时\r\nTot hrs.\r\n实验\r\nExp.\r\n上机\r\nOpe‐\r\nration\r\n实践\r\nPrac‐\r\ntice\r\n课外\r\nExtra‐ \r\ncur\r\n建议\r\n修读\r\n学期\r\nSuggested\r\nTerm\r\n先修课程\r\nPrerequisite\r\nCourse\r\n（一）通识必修课程\r\nGeneral Education Required Courses\r\n4220001110 思想道德修养与法律基础 3 48 8 1 \r\n Morals, Ethics and Fundamentals of Law \r\n4220002110 中国近现代史纲要 2 32 1 \r\nOutline of Contemporary and Modern \r\nChinese History \r\n4220003110 毛泽东思想和中国特色社会主义理论体\r\n系概论 4 96 32 3 \r\nIntroduction to Mao Zedong Thought and \r\nSocialism with Chinese Characteristics \r\n4220005110 马克思主义基本原理 3 48 8 4 \r\n Marxism Philosophy \r\n1060003130 军事理论 1 32 16 2 \r\n Military Theory \r\n4210001170 体育 1 1 26 1 \r\n Physical EducationⅠ \r\n4210002170 体育 2 1 34 2 \r\n Physical Education Ⅱ \r\n4210003170 体育 3 1 34 3 \r\n Physical Education Ⅲ \r\n4210004170 体育 4 1 34 4 \r\n Physical Education Ⅳ \r\n4030002180 大学英语 1 3 60 12 1 \r\n College English 1 \r\n4030003180 大学英语 2 2 44 12 2 大学英语 1\r\n College English Ⅱ \r\n4030004180 大学英语 3 2 44 12 3 大学英语 2\r\n College English Ⅲ \r\n4030004180 大学英语 4 2 44 12 4 大学英语 3\r\n College English IV \r\n4120335170 C 程序设计基础 2 32 2 \r\nFundamentals of Computer Program \r\nDesign(C) \r\n4120336170 计算机基础与 C 程序设计综合实验 1 32 32 2 \r\nComputer foundation and C Programming \r\nComprehensive Experiment \r\n小 计 Subtotal 29 640 32 0 48 64 \r\n11-22学时分配 Including 课程编号\r\nCourse\r\nNumber\r\n课 程 名 称\r\nCourse Title\r\n学分\r\nCrs 总学时\r\nTot hrs.\r\n实验\r\nExp.\r\n上机\r\nOpe‐\r\nration\r\n实践\r\nPrac‐\r\ntice\r\n课外\r\nExtra‐ \r\ncur\r\n建议\r\n修读\r\n学期\r\nSuggested\r\nTerm\r\n先修课程\r\nPrerequisite\r\nCourse\r\n（二）通识选修课程\r\nGeneral Education Elective Courses\r\n创新创业类\r\nInnovation and Entrepreneurship Courses\r\n人文社科类\r\nArts and Social Science Courses\r\n经济管理类\r\nEconomy and Management Courses\r\n科学技术类\r\nScience and Technology Courses\r\n艺术体育类\r\nArt and Physical Education Courses\r\n要求至少取得 9 个学分，且必须选修艺术体育类课程中的艺术类相\r\n关课程并取得至少 2 个学分，在创新创业类课程中至少选修一门课\r\n程，在人文社科类或经济管理类课程中至少选修一门。\r\nStudents are required to abtain at least 9 credits，which must cotain art \r\ncourses of 2 credits from the category of Art and Physical Education \r\nCourses,at least one course from the category of Innovation and \r\nEntrepreneurship Courses, and at least one course from the category of \r\nArts and Social Science Courses or the category of Economy and \r\nManagement Courses. \r\n（三）专业教育必修课程\r\nBasic Disciplinary RequiredCourses\r\n4100212170 自动化专业导论 1 16 1 \r\n Introduction to Materials Physics \r\n4080373170 工程图学 B 3.5 72 16 1 \r\n Engineering Graphics \r\n4050063110 高等数学 A 上 5 80 1 \r\n Advanced Mathematics Ⅰ \r\n4050064110 高等数学 A 下 5 80 2 高等数学上\r\n Advanced Mathematics Ⅱ \r\n4050229110 线性代数 2.5 40 2 \r\n Linear Algebra \r\n4050021110 大学物理 A 上 3.5 56 2 大学物理上\r\n Physics Ⅰ \r\n4050022110 大学物理 A 下 3.5 56 3 \r\n Physics Ⅱ \r\n4050466130 物理实验 A 上 1 32 32 3 物理实验上\r\n Physics Lab. Ⅰ \r\n4050467130 物理实验 A 下 1 32 32 4 \r\n Physics Lab. Ⅱ \r\n4100030110 电路原理 A 上 3 48 2 \r\n Circuit Theory Ⅰ \r\n4100031110 电路原理 A 下 3 48 3 电路原理上\r\n Circuit Theory Ⅱ \r\n4100032110 电路原理 A 实验上 0.5 16 16 2 \r\n Circuit Theory Exp \r\n4100033110 电路原理 A 实验下 0.5 16 16 3 电路原理实\r\n验上 \r\n Circuit Theory Exp \r\n11-23学时分配 Including 课程编号\r\nCourse\r\nNumber\r\n课 程 名 称\r\nCourse Title\r\n学分\r\nCrs 总学时\r\nTot hrs.\r\n实验\r\nExp.\r\n上机\r\nOpe‐\r\nration\r\n实践\r\nPrac‐\r\ntice\r\n课外\r\nExtra‐ \r\ncur\r\n建议\r\n修读\r\n学期\r\nSuggested\r\nTerm\r\n先修课程\r\nPrerequisite\r\nCourse\r\n4050052110 复变函数与积分变换 B 3 48 3 \r\n Complex Function and Integral Transform \r\n4110049110 模拟电子技术基础 B 3.5 56 3 \r\n Analog Electronic Technology \r\n4110051110 模拟电子技术基础实验 0.5 16 16 3 \r\n Analog Electronic Exp \r\n4110067110 数字电子技术基础 B 3.5 56 4 \r\n Digital Electronic Technology \r\n4110068110 数字电子技术基础实验 0.5 16 16 4 \r\n Digital Electronic Exp. \r\n4050058110 概率论与数理统计 B 3 48 4 \r\n Probability and Mathematical Statistics \r\n4100172160 电力电子技术 F 2 32 5 \r\n Power Electronic \r\n4100169160 电机与拖动基础 B 2.5 40 5 \r\nBasic of ElectricMachineds and Electric \r\nDrive \r\n4100218170 电力电子与电气拖动实验 0.5 16 16 5 \r\nExperiment of Power Eectronics and \r\nMotor Drive \r\n4100166160 微处理器与微控制器 B 3.5 56 5 \r\n Micro Process and Micro Controller \r\n4100167160 微处理器与微控制器实验 0.5 16 16 5 \r\n Micro Process and Micro Controller Exp. \r\n4100064110 自动控制原理 H 4.5 72 8 5 \r\n Automatical Control principle \r\n4100219170 计算机过程控制系统 D 3.5 56 8 7 \r\n Instrument and Process Control System \r\n4100176160 运动控制系统 C 3.5 56 8 7 \r\n Motion Control System \r\n4100220170 创新创业与自动化前沿 1 16 7 \r\nInnovation/Entrepreneurship and \r\nautomation frontier \r\n小 计 Subtotal 68.5 1192 184 0 0 16 \r\n（四）专业教育选修课程\r\nSpecialized Elective Courses\r\n信息与物联网方向\r\nInformation and Internet of Things\r\n4100208160 数据通讯与计算机网络 A 3 48 8 4 \r\nData Dommuncation and Domputer \r\nNetwork \r\n11-24学时分配 Including 课程编号\r\nCourse\r\nNumber\r\n课 程 名 称\r\nCourse Title\r\n学分\r\nCrs 总学时\r\nTot hrs.\r\n实验\r\nExp.\r\n上机\r\nOpe‐\r\nration\r\n实践\r\nPrac‐\r\ntice\r\n课外\r\nExtra‐ \r\ncur\r\n建议\r\n修读\r\n学期\r\nSuggested\r\nTerm\r\n先修课程\r\nPrerequisite\r\nCourse\r\n4100221170 传感与检测技术 E 2.5 40 8 6 数 字 / 模拟电\r\n子技基础 \r\nPhotoelectron Materials and its \r\nApplications \r\n4100222170 物联网技术与工程 2.5 40 8 6 \r\n Introduction to Internet of Things \r\n工控与智能机器人方向\r\n Industrial control and Intelligent robot \r\n4100223170 程序设计方法 C 2.5 40 8 3 \r\n Programming Method \r\n4100192160 图像处理与机器视觉 A 2.5 40 8 5 \r\nPhotoelectron Materials and its \r\nApplications \r\n4100178160 智能机器人 3 48 8 6 \r\n Introduction to Intelligent Robotics \r\n选修模块 1 \r\n4100179160 自动化专业与工业 4.0 认知实验 0.5 16 16 2 \r\nCongnition Experiment of Automation \r\nand Industry 4.0 \r\n4100189160 信号处理与数据分析 2 32 4 \r\n Signal Processing and Data Analysisi \r\n4100058110 现代控制理论 2 32 6 6 \r\n Modern Control Theory \r\n4100224170 控制工程实践与系统仿真 3 48 16 6 \r\nControl Engineering Practice and System \r\nSimulation \r\n选修模块 2 \r\n4100182160 数据库与信息系统 2 32 12 2 \r\n Database and Infromation System \r\n4100186150 面向对象程序设计（C++） 2 32 12 2 \r\n Object-oriented Programming (c++) \r\n4100050110 模式识别概论 2 32 5 \r\n Introduction to Pattern Recognition \r\n4100225170 手机与 web 系统编程 3 48 16 6 \r\nProgramming for Smart Phone and Web \r\nSystem \r\n选修模块 3 \r\n4100034110 电气 CAD(A) 3 48 20 4 \r\n Electrical CAD \r\n4100226170 电子设计自动化 C 2.5 40 12 5 \r\n Eelectronic Design Automation \r\n11-25学时分配 Including 课程编号\r\nCourse\r\nNumber\r\n课 程 名 称\r\nCourse Title\r\n学分\r\nCrs 总学时\r\nTot hrs.\r\n实验\r\nExp.\r\n上机\r\nOpe‐\r\nration\r\n实践\r\nPrac‐\r\ntice\r\n课外\r\nExtra‐ \r\ncur\r\n建议\r\n修读\r\n学期\r\nSuggested\r\nTerm\r\n先修课程\r\nPrerequisite\r\nCourse\r\n4100227170 嵌入式系统与应用 2.5 40 8 6 \r\n Embeded System and Application \r\n选修模块 4 \r\n4100228170 电器控制与可编程序控制器 3.5 56 16 5 \r\n Introduction to Pattern Recognition \r\n4100195160 工业机器人编程与实践 2 32 16 6 \r\nProgramming and Practice of Industrial \r\nRobot \r\n4100043110 工厂供电与节能技术 3 48 6 7 \r\nPlant Power Supply & Sower Saving \r\nTechnology \r\n4100229170 自动化综合实验 C 1.5 48 48 7 \r\n Integrated Exp of Automatic \r\n小 计 Subtotal 50.5 840 208 44 0 0 \r\n修读说明：专业选修课程要求至少选修 21 学分，信息与物联网方向和工控与智能机器人方向并行上课，学生必须选择其\r\n一选修全部课程。学分不满 21 的通过其余选修课补齐总学分，选修另一方向课程等同选修其它模块学分。若选择信息与\r\n物联网方向，则组合（工控与智能机器人方向和选修模块 1~4）中每个模块内的课程至少选一门。若选择工控与智能机\r\n器人方向，则组合（信息与物联网方向和选修模块 1~4）中每个模块内的课程至少选一门。\r\nNOTE：Minimum subtotal credits: 21. The students are required to take at least 21 credits from Specialized    Elective Courses ,\r\nthe modules    A and the modules B    are taught in in parallel. Students must choose one of them for elective courses. The\r\nstudents whose credits less than 21 will be filled by the remaining optional courses, and the other modules will be equivalent to\r\nelective credits.    At least one in each module within the group (module B and module 1~4 ) should be chosen if module A is\r\nchosen. At least one in each module within the group (module A and module 1~4 ) should be chosen if module B is chosen.\r\n（五）个性课程\r\nPersonalized Electice Courses\r\n4100230170 科学研究方法与学术论文写作 2 32 4 \r\nScientific Research Methods and \r\nAcademic Paper Writing \r\n4100103110 智能仪器仪表 2 32 7 \r\n Intelligent Instrument \r\n4100210160 射频识别（RFID）原理与应用 2 32 7 \r\n Pricipale and Application of RFID \r\n4100203160 人工智能与机器学习 2.5 40 8 7 \r\nArtifical Intelligence and Machine \r\nLearning \r\n4100001110 DSP 技术与应用 2 32 4 7 \r\n DSP Technology & Application \r\n4170149110 项目管理 A 2 32 7 \r\n Project Management \r\n小 计 Subtotal 12.5 200 12 0 0 0 \r\n修读说明：学生从以上个性课程和学校发布的其它个性课程目录中选课，要求至少选修 6 学分。\r\nNOTE: Sudents can select courses from above and the other personalized courses in catalog, and are required to obtain at\r\nleast 6 credits.\r\n11-26五、 集中性实践教学环节\r\nⅤ Practice Schedule\r\n课程编号\r\nCourse\r\nNumber\r\n实践环节名称\r\nPractice Courses Name\r\n学分\r\nCrs\r\n周数\r\nWeeks\r\n建议修读学期\r\nSuggested Term\r\n1060002110 军事训练 1.5 3 1 \r\n Military Training \r\n4100068110 电工电子实习 A 2 2 3 \r\n Practice of Electrical Engineering & Electronics \r\n4080151110 机械制造工程实训 C 2 2 4 \r\n Training on Mechanical Manufacturing Engineering \r\n4100127120 电工电子基础强化训练 1 1 4（暑假）\r\nFundation Strengthening Training on Electronic & \r\nElectrics \r\n4100231170 控制工程综合实践 1.5 1.5 5 \r\nComprehensive Practice of Automatic Control \r\npriciple \r\n4100082110 生产实习 3 3 6（暑期）\r\n Practice of Manufacture \r\n4100232170 过程控制系统综合实践 1.5 1.5 7 \r\n Integrated Practice of Process Control System \r\n4100233170 自动化专业创新创业实践 1 1 7 \r\n Training Programs for Innovation and Entrepreneurship \r\n4100234170 毕业设计 10 17 8 \r\n Graduation Thesis \r\n信息与物联网方向 \r\n4100235170 物联网综合实践 3 3 6 \r\n Training on Mechanical Manufacturing Engineering \r\n工控与智能机器人方向 \r\n4100236170 智能机器人综合实践 3 3 6 \r\n Comprehensive Practice of Programming Design \r\n小 计 Subtotal 26.5 35 \r\n六、其它要求\r\nⅥ Recommendations on Course Studies \r\n1、《形势与政策》和《心理健康教育》课程为课外必修课程，分别计 2 个和 1 个课外学分。 \r\n2、学生选修的通识选修课程和从学校发布的个性课程目录中选修的个性课程，要求与本专业培养方案\r\n内设置的课程内容不重复。 \r\n1.Situation & Policy (2 credits) and Mental Health Education (1 credit) are the required extracurricular \r\ncourses. \r\n2.The selected General Education Elective Courses and Personalized Elective Courses from the courses \r\nprogram by university must be different from the major undergraduate education plan in content. \r\n学院教学责任人：周新民\r\n专业培养方案责任人：李志俊\r\n执笔人：傅    剑\r\n11-27电气工程及其自动化专业(卓越工程师班)2017 版本科培养方案\r\nUndergraduate Education Plan for Specialty in \r\nElectrical Engineering and Automation \r\n (Excellent Engineer Class)(2017) \r\n专业名称 电气工程及其自动化 主干学科 电气工程、控制科学与工程、计算\r\n机科学与技术\r\nMajor Electrical Engineering \r\nand Automation \r\nMajor Disciplines Electrical Engineering, Control \r\nScience and Engineering, Computer \r\nScience and Technology \r\n计划学制 四年 授予学位 工学学士\r\nDuration 4 Years Degree Granted Bachelor of Engineering \r\n最低毕业学分规定\r\nGraduation Credit Criteria \r\n课程类别 Course \r\nClassification \r\n课程性质\r\nCourse Nature \r\n通识教育课程\r\nPublic Basic \r\nCourses \r\n专业教育课程\r\nSpecialized \r\nCourses \r\n个性课程\r\nPersonalized \r\nCourse\r\n集中性实践\r\nPractice Courses\r\n课外学分\r\nStudy Credit \r\nafter Class\r\n总学分\r\nTotal \r\nCredits\r\n必修课\r\nRequired Courses 29 61.5 \\ 32.5 \\ \r\n选修课\r\nElective Courses 9 22 6 \\ 10 \r\n170 \r\n一、 培养目标与毕业要求\r\nⅠEducational Objectives &Requirement \r\n（一） 培养目标\r\n武汉理工大学电气工程及其自动化卓越工程师班面向电气工程领域科学研究、技术开发、工程设计\r\n和技术服务等任务，培养高素质、应用型、具有较强实践经验、适应能力、创新能力及国际化视野的“专\r\n业理论+工程实践+创新能力”的电力应用技术人才与管理人才。 \r\n（1） 能设计电气系统解决方案，能设计基于电路原理的实际应用系统, 并具有实际电气系统运行和维\r\n护能力； \r\n（2） 在团队中作为技术骨干或领导有效发挥作用； \r\n（3） 具有良好的修养和道德品质，有意愿并有能力服务社会； \r\n（4） 能够通过继续教育或其它学习渠道更新知识，实现能力和技术水平的提升。\r\nEducational Objectives\r\nThe electrical engineering and its automation major (Excellent Engineer Class) in Wuhan University of \r\nTechnology is oriented to face the mission of scientific research, technology development, engineering design \r\nand technology service, etc in the field of electrical engineering. It is expected to train high-quality \r\n“professional theory + engineering practice + innovation ability” technical personnel and management \r\npersonnel with application-oriented, strong practical ability, strong adaptability, innovation capability as well \r\nas global perspective. \r\n1. Capable of design electrical system solutions, as well as design practical application system based on \r\ncircuit principle. Also have the ability to operate and maintain practical electrical system. \r\n11-282. Work effectively as a technical backbone or leader in the team. \r\n3. Have good self-cultivation and ethical standards, have the willingness and the ability to serve the society. \r\n4. The ability and the skills level can be improved and the knowledge can be updated by continuing \r\neducation or other learning channels. \r\n（二）毕业要求\r\n（1） 工程知识：能够将数学、自然科学、工程基础和专业知识用于解决电气工程及其自动化专业领\r\n域的复杂工程问题。 \r\n（2） 问题分析：能够应用数学、自然科学和工程科学的基本原理，识别、表达、并通过文献研究分\r\n析电气工程及其自动化专业领域的复杂工程问题，以获得有效结论。 \r\n（3） 分析/设计解决方案及工程运行维护能力：具有分析、提出方案并解决电气工程及其自动化领域\r\n工程实际问题的能力，能够参与电气工程及其自动化领域生产及运作系统的设计，并具有运行\r\n和维护能力；具有较强的创新意识和进行产品开发和设计、技术改造与创新的初步能力，并能\r\n够考虑社会、健康、安全、法律、文化以及环境等因素。 \r\n（4） 研究：能够基于科学原理并采用科学方法对电气工程及其自动化专业领域的复杂工程问题进行\r\n研究，包括设计实验、分析与解释数据、并通过信息综合得到合理有效的结论。 \r\n（5） 使用现代工具：能够针对电气工程及其自动化专业领域的复杂工程问题，开发、选择与使用恰\r\n当的技术、资源、现代工程工具和信息技术工具，包括对电气工程及其自动化专业领域的复杂\r\n工程问题的预测与模拟，并能够发现其局限性。 \r\n（6） 工程与社会：能够利用工程相关背景知识进行合理分析，评价电气工程及其自动化专业领域的\r\n工程实践和复杂工程问题解决方案对社会、健康、安全、法律以及文化的影响，并理解应承担\r\n的责任。 \r\n（7） 环境和可持续发展：能够理解和评价针对电气工程及其自动化专业领域的复杂工程问题的具体\r\n工程实践对环境、社会可持续发展的影响。 \r\n（8） 职业规范：具有人文社会科学素养、社会责任感，能够在电气工程及其自动化工程领域的实践\r\n中理解并遵守工程职业道德和规范，履行责任。 \r\n（9） 个人和团队：能够在多学科背景下的团队中承担个体、团队成员以及负责人的角色。 \r\n（10） 沟通：能够就电气工程及其自动化专业领域的复杂工程问题与业界同行及社会公众进行有效沟\r\n通和交流，包括撰写报告和设计文稿、陈述发言、清晰表达或回应指令。并具备一定的国际视\r\n野，能够在跨文化背景下进行沟通和交流。 \r\n（11） 项目管理：理解并掌握工程管理原理与经济决策方法，并能在多学科环境中应用。 \r\n（12） 终身学习：具有自主学习和终身学习的意识，有不断学习和适应发展的能力。 \r\nEducational Requirement\r\n1. Engineering knowledge: have the ability to solve complex engineering problems in the field of electrical \r\nengineering using mathematics, natural science, engineering foundation and professional knowledge. \r\n2. Problem solving: have the ability to identify, express, and analyze through the literature research the \r\ncomplex engineering problems in the field of electrical engineering using fundamental principles in \r\nmathematics, natural science and engineering to get valid conclusions. \r\n3. Design/develop solution and engineering operation and maintenance ability: have the ability to design and \r\npropose solutions for the complex engineering problems in the field of electrical engineering. Be able to \r\nparticipate in the practical operation and maintenance of electrical engineering system. In the mean time \r\nbe able to reflect innovation consciousness in the design, development or technology upgrading process, \r\nas well as considering the factors in society, health, safety, law, culture and environment. \r\n4. Research: be able to research the complex engineering problems in the field of electrical engineering \r\nbased on science principles and science methods, including developing experiment, analyze and explain \r\n11-29data, and drawing reasonable and effective conclusions through integrative information. \r\n5. Using modern tools: be able to develop, choose and use appropriate technology, resources, modern \r\nengineering tools and information technical tools to predict and simulate the complex engineering \r\nproblems in the field of electrical engineering and be capable of finding the limitations in it. \r\n6. Engineering and society: be able to use relevant background and knowledge in engineering to analyze and \r\nevaluate the influence of society, health, safety, law, culture and environment to the complex engineering \r\nproblems in the field of electrical engineering. And understand the responsibilities. \r\n7. Environment and sustainable development: be able to understand and evaluate the influence of \r\nengineering practice on the complex engineering problems in the field of electrical engineering to \r\nenvironment and sustainable development. \r\n8. Professional norm: Have humanistic quality and social responsibility. Be able to understand and comply \r\nwith the engineering ethics and norms in the field of electrical engineering practice and carry out the \r\nresponsibilities. \r\n9. Individual and team: be able to carry out the role of individual, team member as well as team leader in a \r\nmultidisciplinary team. \r\n10. Communication: be able to communicate effectively with industry peers and public citizens in the \r\ncomplex engineering problems in the field of electrical engineering. This includes writing reports and \r\ndesign documents, making statement, expressing ideas or respond instructions clearly. Having a sense of \r\ninternational perspective. Being capable of communication in multi-culture background. \r\n11. Project management: be able to comprehend and master the project management principals and economic \r\ndecision method. And be capable of apply it in multidisciplinary environment. \r\n12. Lifelong learning: Consciousness of independent learning and lifelong learning. Have the ability of \r\nconstant learning and adoption to development. \r\n附：培养目标实现矩阵\r\n培养目标 1 培养目标 2 培养目标 3 培养目标 4 \r\n毕业要求 1 √ \r\n毕业要求 2 √ \r\n毕业要求 3 √ \r\n毕业要求 4 √ \r\n毕业要求 5 √ \r\n毕业要求 6 √\r\n毕业要求 7 √\r\n毕业要求 8 √ √\r\n毕业要求 9 √ √ √\r\n毕业要求 10 √ √ √\r\n毕业要求 11 √ √\r\n毕业要求 12 √\r\n二、 专业核心课程与专业特色课程\r\nII Core Courses and Characteristic Courses \r\n（一） 专业核心课程：\r\n电路原理，模拟电子技术基础,数字电子技术基础，微机原理及接口技术，电机学，自动控制原理，\r\n电力电子技术，电气工程基础。\r\n11-30Core Courses: Circuit Theory, Analog Electronic Technology, Digital Electronic Technology, \r\nMicrocomputer Principles & Interfacing Technique, Electric Machinery, Automatic Control Principles，Power \r\nElectronics, Basic Principle of Power Engineering \r\n（二） 专业特色课程：\r\n电力系统分析，电力系统继电保护，高电压技术，电力系统自动化，电力电子装置及控制，电力拖动与控\r\n制系统，发电厂电气部分，电磁场与电磁波，智能电网新技术，专业实践，岗位实习。\r\nCharacteristic Courses: Power System Analysis, Protective Relaying in Power Systems, , High-voltage \r\nTechnology, Power System Automation, Power Electronic System and Control, Electric Drive and Control \r\nSystem, Electric Elements of Power Plants, Electromagnetic Field and Electromagnetic Wave, Smart Grid \r\nNovel Technology, Professional Practice, Post Practice. \r\n附：毕业要求实现矩阵：\r\n电气工程及其自动化专业（卓越工程师班）毕业要求 专业核\r\n心课程\r\n专业特色\r\n课程 课程名称\r\n（1） （2） （3） （4） （5） （6） （7） （8） （9） （10） （11） (12)\r\n 思想道德修养与法律基础 √ √ √ √ \r\n 中国近现代史纲要 √ √ √ \r\n 毛泽东思想和中国特色社\r\n会主义理论体系概论 √ √ √ √ √ \r\n 马克思主义基本原理 √ √ √ √ √ \r\n 军事理论 √ √ √ √\r\n 体育 √ √ √ √\r\n 大学英语 √ √\r\n C 程序设计基础 √ √ √ \r\n 计算机基础与 C 程序设计\r\n综合实验 √ √ √ \r\n 专业导论 √ √ √ √ √ √ √ √ √ √\r\n 工程图学 √ √ √ \r\n 高等数学上 √ √ \r\n 高等数学下 √ √ \r\n 概率论与数理统计 √ √ \r\n 线性代数 √ √ \r\n 复变函数与积分变换 √ √ \r\n 大学物理上 √ √ \r\n 大学物理下 √ √ \r\n 物理实验上 √ √ \r\n 物理实验下 √ √ \r\n11-31电气工程及其自动化专业（卓越工程师班）毕业要求 专业核\r\n心课程\r\n专业特色\r\n课程 课程名称\r\n（1） （2） （3） （4） （5） （6） （7） （8） （9） （10） （11） (12)\r\n√ 电路原理上 √ √ \r\n√ 电路原理下 √ √ \r\n 电路原理实验上 √ √ \r\n 电路原理实验下 √ √ \r\n√ 模拟电子技术基础 √ √ \r\n 模拟电子技术基础实验 √ √ \r\n√ 数字电子技术基础 √ √ \r\n 数字电子技术基础实验 √ √ \r\n√ 微机原理及接口技术 √ √ \r\n√ 电机学 1 √ √ \r\n√ 电机学 2 √ √ \r\n√ 自动控制原理 √ √ \r\n√ 电力电子技术 √ √ \r\n√ 电气工程基础 √ √ \r\n√ 电力系统分析 √ √ √ √ \r\n√ 电力电子装置及控制 √ √ √ √ \r\n√ 电力系统继电保护 √ √ √ \r\n√ 电力拖动与控制系统 √ √ √ \r\n 电气 CAD √ √ √ \r\n√ 电磁场与电磁波 √ √ \r\n 数据库技术 √ √ √ \r\n√ 高电压技术 √ √ \r\n 电机控制技术 √ √ \r\n 电力系统自动化 √ √ \r\n 可再生能源发电技术 √ √ √ √ \r\n 传感与检测技术 √ √ \r\n 电气工程综合实验 √ √ √ \r\n 电力市场与电力经济 √ √ √ √ √\r\n√ 发电厂电气部分 √ √ \r\n 电力电子技术在电力系统中\r\n的应用 √ √ √ √ \r\n11-32电气工程及其自动化专业（卓越工程师班）毕业要求 专业核\r\n心课程\r\n专业特色\r\n课程 课程名称\r\n（1） （2） （3） （4） （5） （6） （7） （8） （9） （10） （11） (12)\r\n 电能转换与控制技术 √ √ \r\n 配电系统及其自动化 √ √ \r\n√ 智能电网新技术 √ √ √ √ \r\n 电力电子装置中的典型传感\r\n器技术 √ √ √ \r\n 电气大数据 √ √ √ √ \r\n 电气人工智能 √ √ √ √ \r\n 电气仿真技术 √ √ √ \r\n 军事训练 √ √ √ \r\n 电工电子实习 √ √ √ √ \r\n 机械制造工程实训 √ √ √ √ \r\n 电工电子基础强化训练 √ √ √ √ \r\n 工程设计训练(电气工程) √ √ √ √ \r\n 生产实习 √ √ √ √ \r\n√ 专业实践 √ √ √ √ √ √ √ √ √\r\n√ 岗位实习 √ √ √ √ √ √ √ √ √\r\n 毕业设计 √ √ √ √ √ √ √ √ √ √\r\n 电气工程综合创新创业课\r\n程 √ √ √ √ √ √\r\n 电气工程综合创新创业实\r\n践课程 √ √ √ √ √ √ √\r\n11-33三、 课程教学进程图\r\nⅢ Teaching Process Map \r\n第三学年 第四学年\r\n第一学期 第二学期 第一学期 第二学期\r\n毕业\r\n设计\r\n电机学2\r\n电力电子技术\r\n电气工程基础\r\n自动控制原理\r\n电力系统分析\r\n可再生能源\r\n发电技术\r\n电力系统继电保护\r\n电力系统自动化\r\n电力市场与电力经济 高电压技术\r\n电气工程综合实验\r\n配电系统及其自动化\r\n电力电子装置及控制\r\n电力拖动与控制系统\r\n电力电子技术在电力\r\n系统中的应用\r\n电机控制技术\r\n第一学期\r\n大学英语1\r\n高等数学上\r\n第二学期\r\n大学英语2\r\n高等数学下\r\n线性代数\r\n大学物理上\r\n第一学年 第二学年\r\n第一学期\r\n大学英语3\r\n复变函数与积\r\n分变换\r\n大学物理下\r\n物理实验上\r\n第二学期\r\n概率论与数理\r\n统计\r\n物理实验下\r\n电路原理下\r\n电路原理上\r\n电路原理实\r\n实验上 电路原理\r\n实验下\r\n模拟电子技术\r\n基础B\r\n模拟电子技术\r\n基础实验\r\n数字电子技术\r\n基础\r\n数字电子技术\r\n基础实验\r\n电机学1\r\n专业导论\r\n工程图学\r\n军事理论\r\n思想道德修养\r\n与法律基础\r\nC程序设计基础\r\n中国近现代史\r\n纲要\r\n计算机基础与C程序设\r\n计综合实验\r\n体育1\r\n通识类选修\r\n课程\r\n体育2\r\n通识类选修\r\n课程\r\n体育4\r\n毛泽东思想和\r\n中国特色社会\r\n主义体系概论\r\n通识类选修\r\n课程\r\n体育3\r\n马克思主义基\r\n本原理\r\n微机原理及接口技术\r\n（含单片机）\r\n通识类选修\r\n课程\r\n通识类选修\r\n课程\r\n通识类选修\r\n课程\r\n现代控制理论\r\n军事训练 电工电子实习 机械制造工程实训 工程设计训练 生产实习 （暑期）\r\n专业实践\r\n岗位实习\r\n电磁场与电磁波 发电厂电气部分\r\n信号与系统B\r\n智能电网新技术\r\n电气工程综合创新创\r\n业课程 电气仿真技术\r\n电气工程综合\r\n创新创业实践\r\n电力电子装置中的\r\n典型传感器技术\r\n个性课程 个性课程 个性课程 个性课程 个性课程 个性课程\r\n电能转换与控制\r\n技术\r\n电源技术\r\nDSP技术与应用\r\n电气大数据\r\n电气人工智能\r\n大学英语4\r\n11-34四、 理论教学建议进程表\r\nⅣ Theory Course Schedule\r\n学时分配 Including 课程编号\r\nCourse \r\nNumber\r\n课 程 名 称\r\nCourse Title\r\n学分\r\nCrs 总学时\r\nTot hrs.\r\n实验\r\nExp.\r\n上机\r\nOperation\r\n实践\r\nPractice\r\n课外\r\nExtracur\r\n建议\r\n修读\r\n学期\r\nSuggested \r\nTerm\r\n先修课程\r\nPrerequisite \r\nCourse\r\n（一）通识教育必修课程\r\nGeneral Education Required Courses \r\n4220001110 思想道德修养与法律基础 3 48 8 1 \r\nMorals, Ethics and Fundamentals of Law\r\n4220002110 中国近现代史纲要 2 32 1 \r\nOutline of Contemporary and Modern \r\nChinese History \r\n4220003110 毛泽东思想和中国特色社会主义理论体\r\n系概论 4 96 32 3 \r\nIntroduction to Mao Zedong Thought and \r\nSocialism with Chinese Characteristics \r\n4220005110 马克思主义基本原理 3 48 8 4 \r\nMarxism Philosophy \r\n1060003130 军事理论 1 32 16 1 \r\nMilitary Theory \r\n4210001170 体育 1 1 26 1 \r\nPhysical EducationⅠ\r\n4210002170 体育 2 1 34 2 \r\nPhysical Education Ⅱ\r\n4210003170 体育 3 1 34 3 \r\nPhysical Education Ⅲ\r\n4210004170 体育 4 1 34 4 \r\nPhysical Education Ⅳ\r\n4030002180 大学英语 1 3 60 12 1 \r\nCollege English 1 \r\n4030003180 大学英语 2 2 44 12 2 大学英语 1\r\nCollege English Ⅱ\r\n4030004180 大学英语 3 2 44 12 3 大学英语 2\r\nCollege English Ⅲ\r\n4030004180 大学英语 4 2 44 12 4 大学英语 3\r\nCollege English IV \r\n4120335170 C 程序设计基础 2 32 2 \r\nFundamentals of Computer Program \r\nDesign(C) \r\n4120336170 计算机基础与 C 程序设计综合实验 1 32 32 2 \r\nComputer Foundation and C \r\nProgramming Comprehensive Experiment\r\n小 计 Subtotal 29 640 32 0 64 48 \r\n11-35学时分配 Including 课程编号\r\nCourse \r\nNumber\r\n课 程 名 称\r\nCourse Title\r\n学分\r\nCrs 总学时\r\nTot hrs.\r\n实验\r\nExp.\r\n上机\r\nOperation\r\n实践\r\nPractice\r\n课外\r\nExtracur\r\n建议\r\n修读\r\n学期\r\nSuggested \r\nTerm\r\n先修课程\r\nPrerequisite \r\nCourse\r\n（二）通识教育选修课程\r\nGeneral Education Elective Courses\r\n创新创业类\r\nInnovation and Entrepreneurship Courses\r\n人文社科类\r\nArts and Social Science Courses\r\n经济管理类\r\nEconomy and Management Courses\r\n科学技术类\r\nScience and Technology Courses\r\n艺术体育类\r\nArt and Physical Education Courses\r\n要求至少取得 9 个学分，且必须选修艺术体育类课程中的艺术类相\r\n关课程并取得至少 2 个学分，在创新创业类课程中至少选修一门课\r\n程，在人文社科类或经济管理类课程中至少选修一门。\r\nStudents are required to abtain at least 9 credits，which must cotain art \r\ncourses of 2 credits from the category of Art and Physical Education \r\nCourses,at least one course from the category of Innovation and \r\nEntrepreneurship Courses, and at least one course from the category of \r\nArts and Social Science Courses or the category of Economy and \r\nManagement Courses. \r\n（三）专业教育必修课程\r\nBasic Disciplinary RequiredCourses\r\n4100211170 电气专业导论 1 16 1 \r\nIntroduction to Materials Physics \r\n4080373170 工程图学 B 3.5 72 16 1 \r\nEngineering Graphics \r\n4050063110 高等数学 A 上 5 80 1 \r\nAdvanced Mathematics Ⅰ\r\n4050064110 高等数学 A 下 5 80 2 高等数学\r\n上 \r\nAdvanced Mathematics Ⅱ\r\n4050229110 线性代数 2.5 40 2 \r\nLinear Algebra \r\n4050021110 大学物理 A 上 3.5 56 2 \r\nPhysics Ⅰ\r\n4050022110 大学物理 A 下 3.5 56 3 大学物理\r\n上 \r\nPhysics Ⅱ\r\n4050466130 物理实验 A 上 1 32 32 3 \r\nPhysics Lab. Ⅰ\r\n4050467130 物理实验 A 下 1 32 32 4 物理实验\r\n上 \r\nPhysics Lab. Ⅱ\r\n4100030110 电路原理 A 上 3 48 2 \r\nCircuit Theory Ⅰ\r\n4100032110 电路原理 A 实验上 0.5 16 16 2 \r\nCircuit Theory Exp Ⅰ\r\n4100031110 电路原理 A 下 3 48 3 电路原理\r\n上 \r\nCircuit Theory Ⅱ\r\n4100033110 电路原理 A 实验下 0.5 16 16 3 电路原理\r\n实验上 \r\nCircuit Theory Exp Ⅱ\r\n11-36学时分配 Including 课程编号\r\nCourse \r\nNumber\r\n课 程 名 称\r\nCourse Title\r\n学分\r\nCrs 总学时\r\nTot hrs.\r\n实验\r\nExp.\r\n上机\r\nOperation\r\n实践\r\nPractice\r\n课外\r\nExtracur\r\n建议\r\n修读\r\n学期\r\nSuggested \r\nTerm\r\n先修课程\r\nPrerequisite \r\nCourse\r\n4110049110 模拟电子技术基础 B 3.5 56 3 \r\nAnalog Electronic Technology \r\n4110051110 模拟电子技术基础实验 0.5 16 16 3 \r\nAnalog Electronic Exp \r\n4050052110 复变函数与积分变换 B 3 48 3 \r\nComplex Function and Integral Transform \r\n4050058110 概率论与数理统计 B 3 48 4 \r\nProbability and Mathematical Statistics \r\n4110067110 数字电子技术基础 B 3.5 56 4 \r\nDigital Electronic Technology \r\n4110068110 数字电子技术基础实验 0.5 16 16 4 \r\nDigital Electronic Experiment \r\n4100241170 电磁场与电磁波 D 1.5 24 4 \r\nElectromagnetic Field and \r\nElectromagnetic Wave \r\n4100242170 电机学 A1 3 48 8 4 \r\nElectric Machinery I \r\n4100243170 电机学 A2 3 48 8 5 电机学 1 \r\nElectric Machinery Ⅱ\r\n4100244170 自动控制原理 A 3 48 8 5 \r\nAutomatic Control Principle \r\n4100245170 微机原理及接口技术 C 3 48 8 5 \r\nMicrocomputer Principles and Interfacing \r\nTechnique \r\n4100248170 电气工程综合创新创业 1 16 7 \r\nInnovation and Entrepreneurship Course \r\n小 计 Subtotal 61.5 1064 160 0 0 16 \r\n（四）专业教育选修课程\r\nSpecialized Elective Courses\r\n4110094110 信号与系统 B 3 48 8 4 \r\nSignal and System \r\n4100246170 电力电子技术 D 3.5 56 12 5 \r\nPower Electronics \r\n4100141130 电力电子装置及控制 C 2.5 40 8 6 \r\nPower Electronic System and Control \r\n4100023110 电力拖动与控制系统 A 3.5 56 8 6 \r\nElectric Drive and Control System \r\n4100013110 电机控制技术 2 32 6 \r\nMotor Control Technique \r\n4100249170 电能转换与控制技术 A 2.5 40 6 \r\nPower Conversion and Control Technique\r\n11-37学时分配 Including 课程编号\r\nCourse \r\nNumber\r\n课 程 名 称\r\nCourse Title\r\n学分\r\nCrs 总学时\r\nTot hrs.\r\n实验\r\nExp.\r\n上机\r\nOperation\r\n实践\r\nPractice\r\n课外\r\nExtracur\r\n建议\r\n修读\r\n学期\r\nSuggested \r\nTerm\r\n先修课程\r\nPrerequisite \r\nCourse\r\n4100250170 高电压技术 A 3 48 6 \r\nHigh-voltage Technology \r\n4100025110 电力系统分析 B 4.5 72 12 6 \r\nPower System Analysis \r\n4100247170 电气工程基础 B 3 48 8 5 \r\nBasic Principle of Power System \r\n4100266170 电气大数据 1 16 5 \r\nElectrical Big Data \r\n4100026110 电力系统继电保护 B 3 48 8 6 \r\nProtective Relaying in Power Systems \r\n4100251170 电力电子装置中的典型传感器技术 2.5 40 7 \r\nTypical sensor technology applied in \r\npower \r\n4100027110 电力系统自动化 A 3.5 56 8 6 \r\nAutomatic Techniques in Power System \r\n4100131130 发电厂电气部分 2 32 6 \r\nElectrical Systems of Power Plants \r\n4100020110 电力电子技术在电力系统中的应用 2.5 40 7 \r\nPower Electronics in Power Systems \r\n4100253170 电源技术 A 3 48 7 \r\nPower Supply Technologies \r\n4100037110 电气工程综合实验 1 32 32 7 \r\nAutomation Experiment \r\n4100267170 电气人工智能 1 16 7 \r\nElectrical artificial intelligence \r\n4100022110 电力市场与电力经济 2 32 7 \r\nPower Market and Power Economy \r\n4100051110 配电系统及其自动化 2 32 7 \r\nDistribution Systems and Automation \r\n小 计 Subtotal 51 816 104 0 0 0 \r\n修读说明：专业选修课程要求至少选修 22 学分。\r\nNOTE: Minimum subtotal credits: 22. \r\n（五）个性课程\r\nPersonalized Electice Courses\r\n4100183160 电气仿真技术 2 32 16 5 \r\nElectrical Simulation \r\n4100048110 可再生能源发电技术 A 2.5 40 8 5 \r\nRenewable Energy Technologies \r\n4100158160 智能电网新技术 2 32 6 \r\nSmart Grid Novel Technology \r\n11-38学时分配 Including 课程编号\r\nCourse \r\nNumber\r\n课 程 名 称\r\nCourse Title\r\n学分\r\nCrs 总学时\r\nTot hrs.\r\n实验\r\nExp.\r\n上机\r\nOperation\r\n实践\r\nPractice\r\n课外\r\nExtracur\r\n建议\r\n修读\r\n学期\r\nSuggested \r\nTerm\r\n先修课程\r\nPrerequisite \r\nCourse\r\n4100001110 DSP 技术与应用 2 32 4 7 \r\nDSP Technology & Application \r\n4100058110 现代控制理论 2 32 6 7 \r\nModern Control Theory \r\n小 计 Subtotal 10.5 168 18 16 0 0 \r\n修读说明：学生从以上个性课程和学校发布的其它个性课程目录中选课，要求至少选修 6 学分。\r\nNOTE: Sudents can select courses from above and the other personalized courses in catalog, and are required to obtain at\r\nleast 6 credits.\r\n五、 集中性实践教学环节\r\nⅤ Practice Schedule \r\n课程编号\r\nCourse \r\nNumber \r\n实践环节名称\r\nPractice Courses Name \r\n学分\r\nCrs \r\n周数\r\nWeeks \r\n建议修读学期\r\nSuggested Term \r\n1060002110 军事训练 1.5 3 1 \r\nMilitary Training \r\n4100068110 电工电子实习 A 2 2 3 \r\nPractice of Electrical Engineering & \r\nElectronics \r\n4080151110 机械制造工程实训 C 2 2 4 \r\nTraining on Mechanical Manufacturing \r\nEngineering \r\n4100261170 工程设计训练(电气工程) 2 2 6（企业）\r\nEngineering design Training \r\n4100081110 生产实习 3 3 6(暑期) \r\nPractice of Manufacture \r\n4100109110 专业实践 3 3 7（企业）\r\nProfessional Practice \r\n4100110110 岗位实习 8 8 7（企业）\r\nJob Practice \r\n4100256170 电气工程创新创业实践 1 1 7 \r\nInnovation and Entrepreneurship Practice\r\n4100257170 毕业论文 10 17 8 \r\n Graduation Thesis \r\n小 计 Subtotal 32.5 41 \r\n \r\n11-39六、其它要求\r\nⅥ Recommendations on Course Studies \r\n1、《形势与政策》和《心理健康教育》课程为课外必修课程，分别计 2 个和 1 个课外学分。\r\n2、学生选修的通识选修课程和从学校发布的个性课程目录中选修的个性课程，要求与本专\r\n业培养方案内设置的课程内容不重复。 \r\n1.Situation & Policy (2 credits) and Mental Health Education (1 credit) are the required \r\nextracurricular courses. \r\n2.The selected General Education Elective Courses and Personalized Elective Courses from the \r\ncourses program by university must be different from the major undergraduate education plan in \r\ncontent. \r\n 学院教学责任人：周新民\r\n专业培养方案责任人：夏泽中，侯慧，朱国荣\r\n11-40自动化专业（卓越工程师班）2017 版本科培养方案\r\nUndergraduate Education Plan for Specialty in Automation \r\n(Excellent Engineer Class) (2017) \r\n专业名称 自动化 主干学科 控制科学与工程、电气工程、计算\r\n机科学与技术\r\nMajor Automation Major Disciplines Control Science and Engineering, \r\nElectrical Engineering, Computer \r\nScience and Technology\r\n计划学制 四年 授予学位 工学学士\r\nDuration 4 Years Degree Granted Bachelor of Engineering\r\n最低毕业学分规定\r\nGraduation Credit Criteria \r\n课程类别 Course \r\nClassification\r\n课程性质\r\nCourse Nature \r\n通识教育课程\r\nPublic Basic \r\nCourses\r\n专业教育课程\r\nSpecialized \r\nCourses\r\n个性课程\r\nPersonalized \r\nCourse\r\n集中性实践\r\nPractice \r\nCourses\r\n课外学分\r\nStudy Credit \r\nafter Class\r\n总学分\r\nTotal\r\nCredits\r\n必修课\r\nRequired Courses 29 63.5 \\ 32.5 \\ \r\n选修课\r\nElective Courses 9 20 6 \\ 10 \r\n170 \r\n一、 培养目标与毕业要求\r\nⅠ Educational Objectives &Requirement \r\n（一） 培养目标\r\n武汉理工大学自动化专业面向自动化领域科学研究、技术开发、工程设计和技术服务需\r\n求，培养赋有健全人格、人文社会科学素养、自然科学基础和专业知识扎实、工程实践能力\r\n强、具有快速适应能力、创新创业意识、实干精神和国际化视野的高素质专业技术人才和管\r\n理人才。\r\n（1） 能针对具体问题设计自动化系统解决方案，并能有效地运用专业知识来保障实施和\r\n达成；\r\n（2） 在团队中进行工作和交流，并成为技术骨干或部门负责人，且有效发挥作用；\r\n（3） 具有良好的修养和职业道德；\r\n（4） 在与自动化及相关专业领域成功/创业就业并体现出竞争优势，工程实践能力突出；、\r\n（5） 意愿并有能力为本地、本国乃至全球的公众服务。\r\nI.Ieducational objectives \r\nThe automation major in Wuhan University of Technology is oriented to the requirements of \r\nscientific research, technology development, engineering design and technology service, etc. in \r\nthe field of automation. It is expected to cultivate the high-qualified professionals and \r\nmanagement talents with a health personality, humanities and social science literacy, solid \r\nprofessional foundation and skill, strong practical ability in Engineering, strong adaptability, a \r\nsense of innovation and entrepreneurship, a spirit of work hard as well as a global perspective \r\nview. \r\n11-411. Capable of designing automation system solutions for specific task, as well as guarantee the \r\nimplementation and achievement by means of professional knowledge. \r\n2. Worked effectively and efficiently via cooperation and communication as a key technician or \r\nleader. \r\n3. Have good self-cultivation and ethical standards. \r\n4. Succeed in being employed in the field of automation or related, and show a competitive \r\nadvantage. Or, graduates have already completed postgraduate studies. \r\n5. Committed and ableto provide public services in local, national and global society. \r\n（二） 毕业要求\r\n（1） 工程知识：能够将数学、自然科学、工程基础和专业知识用于解决自动化专业领域\r\n的复杂工程问题；\r\n（2） 问题分析：能够应用数学、自然科学和工程科学的基本原理，识别、表达、并通过\r\n文献研究分析自动化专业领域的复杂工程问题，以获得有效结论；\r\n（3） 设计/开发解决方案：能够设计针对自动化专业领域的复杂工程问题的解决方案，设\r\n计/开发满足特定需求的控制算法、控制策略、自动化装置、自动化系统和信息处理\r\n方案或技术，具有较强产品开发和设计、技术改造等工程项目实践的初步能力，并\r\n能够在设计环节中体现创新意识，考虑社会、健康、安全、法律、文化以及环境等\r\n因素；\r\n（4） 研究：能够基于科学原理并采用科学方法对自动化专业领域的复杂工程问题进行研\r\n究，包括设计实验、分析与解释数据、并通过信息综合得到合理有效的结论；\r\n（5） 使用现代工具：能够针对自动化专业领域的复杂工程问题，开发、选择与使用恰当\r\n的技术、资源、现代工程工具和信息技术工具，包括对自动化专业领域的复杂工程\r\n问题的预测与模拟，并能够理解其局限性；\r\n（6） 工程与社会：能够基于工程相关背景知识进行合理分析，评价自动化专业工程实践\r\n和复杂工程问题解决方案对社会、健康、安全、法律以及文化的影响，并理解应承\r\n担的责任。掌握工业控制系统的设计方法、技术及相关开发平台，能理解工业控制\r\n系统的设计方法和步骤。并能在工程设计中能综合考虑经济、环境、法律、安全和\r\n伦理等制约因素；\r\n（7） 环境和可持续发展：能够理解和评价针对自动化专业领域的复杂工程问题的具体工\r\n程实践对环境、社会可持续发展的影响；\r\n（8） 职业规范：具有人文社会科学素养、社会责任感，能够在自动化工程实践中理解并\r\n遵守工程职业道德和规范，履行责任；\r\n（9） 个人和团队：能够在多学科背景下的团队中承担个体、团队成员以及负责人的角色；\r\n（10） 沟通：能够就自动化专业领域的复杂工程问题与业界同行及社会公众进行有效沟通\r\n和交流，包括撰写报告和设计文稿、陈述发言、清晰表达或回应指令。并具备一定\r\n的国际视野，能够在跨文化背景下进行沟通和交流；\r\n（11） 项目管理：理解并掌握工程管理原理与经济决策方法，并能在多学科环境中应用；\r\n（12） 终身学习：具有自主学习和终身学习的意识，有不断学习和适应发展的能力。\r\nIIGraduation Requirements：\r\n1. Engineering knowledge: with the ability to solve complex engineering problems in the field \r\nof automation by applying mathematics, natural science, engineering foundation and \r\nprofessional knowledge; \r\n2. Problem solving: with the ability to identify, express, and analyze the complex engineering \r\n11-42problems in the field of automation through the literature review methods by applying \r\nfundamental principles in mathematics, natural science and engineering to get valid \r\nconclusions; \r\n3. Design/develop solution: with the ability to design solutions for the complex engineering \r\nproblems in the field of automation. Graduates have the ability to design /develop control \r\nalgorithm/strategy, automation equipment, solution and related technology of automation \r\nsystem and information system to meet the specific requirements, especially with rather \r\nstrong capacity of practice for product development and design, technical reformation and so \r\non. Meanwhile, graduates are supposed to design with innovative inspiration, as well as \r\nconsidering the relationship with society, health, safety, law, culture and environment; \r\n4. Research: with the ability to research the complex engineering problems in the field of \r\nautomation based on science principles and science methods, including developing \r\nexperiment, analyzing and explaining data, and drawing reasonable and effective conclusions \r\nthrough integrative information; \r\n5. Using modern tools: with the ability to develop, choose and use appropriate technology, \r\nresources, modern engineering tools and information technical tools to predict and simulate \r\nthe complex engineering problems in the field of automation and be capable of finding the \r\nassociative limitations; \r\n6. Engineering and society: with the ability to analyze and evaluate the influence on society, \r\nhealth, safety, law, culture and environment from the complex engineering practice/solution \r\nin the field of automation by applying the project background and relevant knowledge. Also, \r\nresponsibility should be understood; \r\n7. Environment and sustainable development: with the ability to understand and evaluate the \r\ninfluence on environment and sustainable development, which is caused by engineering \r\npractice of the complex engineering projects in the field of automation; \r\n8. Professional norm: be with humanistic quality and social responsibility. With the ability to \r\nunderstand and comply with the engineering ethics and norms in the field of automatic \r\nengineering practice and take the responsibilities; \r\n9. Individual and team: with the ability to competently play the role of individual, team \r\nmember as well as team leader in a multidisciplinary team; \r\n10. Communication: with the ability to communicate effectively with industry peers and public \r\ncitizens about the complex engineering problems in the field of automation. It includes \r\nwriting reports and designing documents, making statement, expressing ideas or respond \r\ninstructions clearly. Graduates are supposed to be with international perspective and be \r\ncapable of communicating in a multi-culture background; \r\n11. Project management: with the ability to comprehend and master the project management \r\nprincipals and economic decision method, which can be applied in a multidisciplinary \r\nenvironment; \r\n12. Lifelong learning: be aware of independent learning and lifelong learning. With the ability to \r\nkeep learning and be adapt to the development. \r\n11-43附：培养目标实现矩阵\r\n培养目标 1 培养目标 2 培养目标 3 培养目标 4 培养目标 5 \r\n毕业要求 1 √     \r\n毕业要求 2 √       \r\n毕业要求 3 √      √ √\r\n毕业要求 4 √     \r\n毕业要求 5 √  √   \r\n毕业要求 6 √ √\r\n毕业要求 7 √    √\r\n毕业要求 8 √    √\r\n毕业要求 9 √ √    \r\n毕业要求 10 √ √ √\r\n毕业要求 11 √    \r\n毕业要求 12 √ √\r\n二、 专业核心课程与专业特色课程\r\nII Core Courses and Characteristic Courses \r\n（一） 培养特色：\r\n采用宽口径、厚基础、重实践、聚前沿的人才培养模式，突出“嵌入式计算、自动\r\n化执行、智能化决策”的专业核心，与计算机、信息技术深度融合的特色。凝练“信息\r\n与物联网”和“工控与智能机器人”两个子方向、强调综合知识运用和工程项目实践。\r\nIn the program, college students are supposed to with broad extension and solid \r\nfoundation of professional knowledge, endowed with high practical ability, acquaint \r\nthemselves with the knowledge on the cutting edge. It highlights the professional core as \r\n“embedded computing, automated execution, intelligent decision making”. The specialty is \r\ndeeply integrated with computer science and information technology. The plan focus on \r\ntwo sub-direction“information and Internet of Thing”,“industrial controland intelligent robot”, \r\nemphasizing the application and practice of comprehensive knowledge in engineering. \r\n（二） 专业核心课程：\r\n电路原理，电子技术，自动控制原理，微处理器与微控制器，电力电子技术与运动\r\n控制系统，计算机过程控制系统，智能机器人、数据通讯与计算机网络、传感与检测技\r\n术、程序设计方法导论、电机与拖动基础。\r\nCore Courses: Circuit Theory, Electronics, Automatic Control Principle,Microcomputer \r\nprocessor and Microcomputer controller，Power Electronics & Motion Control System，\r\nComputer Process Control System，Introduction to intelligent robotics, Data communication \r\nand computer network, Sensor and Detecting Technique, Introduction to programming design, \r\nBasic of Electric Machines and Electric \r\n（三） 专业特色课程：\r\n图像处理与机器视觉、智能机器人、工业机器人编程与实践、嵌入式系统与应用\r\nI、射频识别（RFID）原理与应用、物联网技术与工程、电子设计自动化、自动化综合\r\n实验\r\n11-44Characteristic Courses: Image Processing and Machine Vision, Introduction to \r\nIntelligent Robot, Programming and Practice of Industrial robot, embedded system and \r\napplication I, Principle and Application of RFID, Internet of things technology and \r\nengineering., Electronic Design Automation, Automation Experiment \r\n附：毕业要求实现矩阵：\r\n专业 自动化专业（卓越工程师班）毕业要求\r\n核心\r\n课程\r\n专业\r\n特色\r\n课程\r\n课程名称\r\n（1） （2） （3） （4） （5） （6） （7） （8） （9） （10） （11） （12）\r\n 思想道德修养与法律基础 √ √ \r\n 中国近现代史纲要 √ \r\n 毛泽东思想和中国特色社会主\r\n义理论体系概论 √ √ \r\n 马克思主义基本原理 √ √ \r\n 军事理论 √ \r\n 体育 1 √\r\n 体育 2 √\r\n 体育 3 √\r\n 体育 4 √\r\n 心理健康教育 √\r\n 大学英语 1 √ √\r\n 大学英语 2 √ √\r\n 大学英语 3 √ √\r\n 大学英语 4 √ √\r\n C 程序设计基础 √ √ √ \r\n 计算机基础与 C 程序设计综合\r\n实验 √ √ √ √ \r\n 专业导论 √ √√           √\r\n 工程图学 √ √ \r\n 高等数学上 √ \r\n 高等数学下 √ \r\n 概率论与数理统计 √ \r\n 线性代数 √ \r\n 复变函数与积分变换 √ \r\n 大学物理上 √ \r\n 大学物理下 √ \r\n11-45专业 自动化专业（卓越工程师班）毕业要求\r\n核心\r\n课程\r\n专业\r\n特色\r\n课程\r\n课程名称\r\n（1） （2） （3） （4） （5） （6） （7） （8） （9） （10） （11） （12）\r\n 物理实验上 √ √ \r\n 物理实验下 √ √ \r\n√ 电路原理上 √ √ √ √ \r\n√ 电路原理下 √ √ √ √ \r\n 电路原理实验上 √ √ √ \r\n 电路原理实验下 √ √ √ \r\n√ 模拟电子技术基础 √ √ √ √ \r\n 模拟电子技术基础实验 √ √ \r\n√ 数字电子技术基础 √ √ √ √ \r\n 数字电子技术基础实验 √ √ \r\n 面向对象程序设计（c++） √ √ √ √\r\n 电气 CAD √ √ √ \r\n 信号处理与数据分析 √ √ √ √ √ √\r\n 控制工程实践与系统仿真 √ √ √ √ √ √\r\n 数据库与信息系统 √ √ √ √ √ √ √\r\n 自动化专业工业 4.0 认知性实验 √ √ √ √ √\r\n 数据通讯与计算机网络 √ √ √ √ √ √\r\n√ 电力电子技术 \r\n√ 微处理器与微控制器 √ √ √ √ √\r\n 电机与拖动基础 \r\n√ 运动控制系统     \r\n 图像处理与机器视觉 √ √ √ √ √ √ √\r\n 电子设计自动化 √ √ √ √ √ √ \r\n 射频识别（RFID）原理与应用 √ √ √ √ √ √\r\n 嵌入式系统与应用 √ √ √ √ √ √ √\r\n 电器控制与可编程序控制器 √ √ √ √\r\n 智能机器人 √ √ √ √ √\r\n 现代控制理论 √ √ √ √ √ √\r\n 工厂供电与节能技术 √ √ √ √ √\r\n 工业机器人编程与实践 √ √ √ √ √ √ √\r\n11-46专业 自动化专业（卓越工程师班）毕业要求\r\n核心\r\n课程\r\n专业\r\n特色\r\n课程\r\n课程名称\r\n（1） （2） （3） （4） （5） （6） （7） （8） （9） （10） （11） （12）\r\n 物联网技术与工程 √ √ √\r\n DSP 技术与应用 √ √ √ √ √ √\r\n 模式识别概论 √ √ \r\n 智能仪器仪表 √ √ √     √\r\n 军事训练 √ \r\n 电工电子实习 √ √ √ √ √ √ \r\n 机械制造工程实训 √ \r\n 工程设计训练 √ √ √ √ \r\n 生产实习 √ √ √ √ \r\n 专业实践 √ √ √ √ √ √ √ √ √\r\n 岗位实习 √ √ √ √ √ √ \r\n 毕业设计 √ √ √ √ √ √ √ √ \r\n 传感与检测技术 √ √ √ √ √ √ √\r\n 微处理器与微控制器实验 √ √ √ √ √\r\n 自动控制原理 √ √ √ √ √\r\n 自动化综合实验 \r\n 计算机过程控制系统 √ √ √ √ √ √\r\n 程序设计方法 √ √ √ √\r\n 手机与 web 系统编程 √ √ √ √\r\n 科学研究方法与学术论文写作 √ √ √ √ √ \r\n 创新创业与自动化前沿 \r\n 人工智能与机器学习 √ √√√ √   √\r\n 项目管理 √ √    √   √\r\n三、 课程教学进程图\r\nⅢ Teaching Process Map \r\n11-47第三学年 第四学年\r\n第一学期 第二学期 第一学期 第二学期\r\n毕业\r\n设计\r\n第一学期\r\n大学英语1\r\n高等数学1\r\n第二学期\r\n大学英语2\r\n高等数学2\r\n线性代数\r\n大学物理A1\r\n第一学年 第二学年\r\n第一学期\r\n大学英语3\r\n复变函数与积\r\n分变换\r\n大学物理2\r\n物理实验1\r\n第二学期\r\n概率论与数理\r\n统计\r\n物理实验2\r\n电路原理2\r\n电路原理1\r\n电路原理\r\n实验1 电路原理\r\n实验A2\r\n模拟电子技术\r\n基础B\r\n模拟电子技术\r\n基础实验\r\n数字电子技术\r\n基础\r\n数字电子技术\r\n基础实验\r\n专业导论\r\n军事训练\r\n思想道德修养\r\n与法律基础\r\nC程序设计基础\r\n中国近代史\r\n纲要\r\n体育1\r\n通识类选修\r\n课程\r\n体育2\r\n电气CAD\r\n数据库\r\n与信息系统\r\n通识类选修\r\n课程\r\n体育4\r\n毛泽东思想和\r\n中国特色社会\r\n主义体系概论\r\n个性选修课程\r\n通识类选修\r\n课程\r\n体育3\r\n马克思主义基\r\n本原理\r\n微处理器与微控\r\n制器\r\n通识类选修\r\n课程\r\n个性选修课程\r\n通识类选修\r\n课程\r\n通识类选修\r\n个性选修课程\r\n课程\r\n军事理论\r\n电工电子实习 机械制造工程实训 工程设计训练\r\n（工控）\r\n生产实习\r\n数据通讯与计\r\n算机网络A\r\n面向对象程序设\r\n计（C++语言）\r\n电机与拖动基础\r\n自动控制原理\r\n电子设计自动化\r\n传感与检测技\r\n术\r\n工业机器人编程\r\n与实践\r\n嵌入式系统与用\r\n用\r\n智能机器人\r\n物联网技术与工\r\n现代控制理论\r\n程\r\n运动控制系统 控制工程实践与 系统仿真\r\nDSP技术与应用\r\n射频识别(RFID)\r\n原理应用\r\n模式识别概论\r\n程序设计方法\r\n图像处理与机器\r\n视觉\r\n项目管理\r\n电气控制与可编\r\n程控制器 自动化专业工业\r\n4.0认知性实验\r\n电力电子技术\r\n自动化综合实验\r\n智能仪器仪表\r\n岗位实习\r\n（工控）\r\n专业实践\r\n（信息）\r\n微处理器与微控\r\n制器实验\r\n创新创业与自动\r\n化前沿\r\n计算机基础与c\r\n程序设计综合实\r\n验\r\n计算机过程控制\r\n系统\r\n工厂供电与节能\r\n技术\r\n手机与web系统\r\n编程\r\n科学研究方法\r\n与学术论文写\r\n作 人工智能与机器\r\n学习\r\n创新创业\r\n实践\r\n工程设计训练\r\n（信息）\r\n岗位实习\r\n（信息）\r\n专业实践\r\n（工控）\r\n工程图学\r\n数据处理与信\r\n号分析\r\n大学英语4\r\n11-48四、 理论教学建议进程表\r\nⅣ    Theory Course Schedule\r\n学时分配 Including 课程编号\r\nCourse\r\nNumber\r\n课 程 名 称\r\nCourse Title\r\n学分\r\nCrs 总学时\r\nTot hrs.\r\n实验\r\nExp.\r\n上机\r\nOpe‐\r\nration\r\n实践\r\nPrac‐\r\ntice\r\n课外\r\nExtra‐ \r\ncur\r\n建议\r\n修读\r\n学期\r\nSuggested\r\nTerm\r\n先修课程\r\nPrerequisite\r\nCourse\r\n（一）通识必修课程\r\nGeneral Education Required Courses\r\n4220001110 思想道德修养与法律基础 3 48 8 1 \r\n Morals, Ethics and Fundamentals of Law \r\n4220002110 中国近现代史纲要 2 32 1 \r\nOutline of Contemporary and Modern \r\nChinese History \r\n4220003110 毛泽东思想和中国特色社会主义理论体\r\n系概论 4 96 32 3 \r\nIntroduction to Mao Zedong Thought and\r\nSocialism with Chinese Characteristics \r\n4220005110 马克思主义基本原理 3 48 8 4 \r\n Marxism Philosophy \r\n1060003130 军事理论 1 32 16 2 \r\n Military Theory \r\n4210001170 体育 1 1 26 1 \r\n Physical EducationⅠ \r\n4210002170 体育 2 1 34 2 \r\n Physical Education Ⅱ \r\n4210003170 体育 3 1 34 3 \r\n Physical Education Ⅲ \r\n4210004170 体育 4 1 34 4 \r\n Physical Education Ⅳ \r\n4030002180 大学英语 1 3 60 12 1 \r\n College English 1 \r\n4030003180 大学英语 2 2 44 12 2 大学英语 1\r\n College English Ⅱ \r\n4030004180 大学英语 3 2 44 12 3 大学英语 2\r\n College English Ⅲ \r\n4030004180 大学英语 4 2 44 12 4 大学英语 3\r\n College English IV \r\n4120335170 C 程序设计基础 2 32 1 \r\nFundamentals of Computer Program \r\nDesign(C) \r\n4120336170 计算机基础与 C 程序设计综合实验 1 32 32 1 \r\nComprehensive Experiments of Foundation \r\nof Computer and C Language Programming \r\n小 计 Subtotal 29 640 32 0 48 64 \r\n11-49学时分配 Including 课程编号\r\nCourse\r\nNumber\r\n课 程 名 称\r\nCourse Title\r\n学分\r\nCrs 总学时\r\nTot hrs.\r\n实验\r\nExp.\r\n上机\r\nOpe‐\r\nration\r\n实践\r\nPrac‐\r\ntice\r\n课外\r\nExtra‐ \r\ncur\r\n建议\r\n修读\r\n学期\r\nSuggested\r\nTerm\r\n先修课程\r\nPrerequisite\r\nCourse\r\n（二）通识选修课程\r\nGeneral Education Elective Courses\r\n创新创业类\r\nInnovation and Entrepreneurship Courses\r\n人文社科类\r\nArts and Social Science Courses\r\n经济管理类\r\nEconomy and Management Courses\r\n科学技术类\r\nScience and Technology Courses\r\n艺术体育类\r\nArt and Physical Education Courses\r\n要求至少取得 9 个学分，且必须选修艺术体育类课程中的艺术类相\r\n关课程并取得至少 2 个学分，在创新创业类课程中至少选修一门课\r\n程，在人文社科类或经济管理类课程中至少选修一门。\r\nStudents are required to abtain at least 9 credits，which must cotain art \r\ncourses of 2 credits from the category of Art and Physical Education \r\nCourses,at least one course from the category of Innovation and \r\nEntrepreneurship Courses, and at least one course from the category of \r\nArts and Social Science Courses or the category of Economy and \r\nManagement Courses. \r\n（三）专业教育必修课程\r\nBasic Disciplinary RequiredCourses\r\n4100212170 专业导论 1 16 1 \r\n Introduction to Materials Physics \r\n4080373170 工程图学 C 3.5 72 16 1 \r\n Engineering Graphics \r\n4050063110 高等数学 A 上 5 80 1 \r\n Advanced Mathematics Ⅰ \r\n4050064110 高等数学 A 下 5 80 2 高等数学上\r\n Advanced Mathematics Ⅱ \r\n4050229110 线性代数 2.5 40 2 \r\n Linear Algebra \r\n4050021110 大学物理 A 上 3.5 56 2 大学物理上\r\n Physics AⅠ \r\n4050022110 大学物理 A 下 3.5 56 3 \r\n Physics Ⅱ \r\n4050466130 物理实验 A 上 1 32 32 3 物理实验上\r\n Physics Lab. Ⅰ \r\n4050467130 物理实验 A 下 1 32 32 4 \r\n Physics Lab. Ⅱ \r\n4100030110 电路原理 A 上 3 48 2 \r\n Circuit Theory AⅠ \r\n4100032110 电路原理 A 实验上 0.5 16 16 2 \r\n Circuit Theory Exp \r\n4100031110 电路原理 A 下 3 48 3 电路原理上\r\n Circuit Theory Ⅱ \r\n4100033110 电路原理 A 实验下 0.5 16 16 3 电路原理实\r\n验上 \r\n Circuit Theory Exp \r\n4050052110 复变函数与积分变换 B 3 48 3 \r\n Complex Function and Integral Transform \r\n11-50学时分配 Including 课程编号\r\nCourse\r\nNumber\r\n课 程 名 称\r\nCourse Title\r\n学分\r\nCrs 总学时\r\nTot hrs.\r\n实验\r\nExp.\r\n上机\r\nOpe‐\r\nration\r\n实践\r\nPrac‐\r\ntice\r\n课外\r\nExtra‐ \r\ncur\r\n建议\r\n修读\r\n学期\r\nSuggested\r\nTerm\r\n先修课程\r\nPrerequisite\r\nCourse\r\n4110049110 模拟电子技术基础 B 3.5 56 3 \r\n Analog Electronic Technology \r\n4110051110 模拟电子技术基础实验 0.5 16 16 3 \r\n Analog Electronic Exp \r\n4110067110 数字电子技术基础 B 3.5 56 4 \r\n Digital Electronic Technology \r\n4110068110 数字电子技术基础实验 0.5 16 16 4 \r\n Digital Electronic Exp \r\n4050058110 概率论与数理统计 B 3 48 4 \r\n Probability and Mathematical Statistics \r\n4100172160 电力电子技术 F 2 32 5 \r\n power electronic \r\n4100169160 电机与拖动基础 B 2.5 40 5 \r\nBasic of ElectricMachineds and Electric \r\nDrive \r\n4100166160 微处理器与微控制器 B 3.5 56 5 数 字 / 模 拟\r\n电子技基础\r\n micro. process and micro.controller \r\n4100167160 微处理器与微控制器实验 0.5 16 16 5 \r\nExperiment of micro. process and \r\nmicro.controlle \r\n4100064110 自动控制原理 H 4.5 72 8 5 信号处理与\r\n数据分析\r\n Automatical Control principle \r\n4100221170 传感与检测技术 E 2.5 40 8 6 \r\n Sensor and Detecting Technology \r\n数 字 / 模 拟\r\n电子技基础\r\n4100220170 创新创业与自动化前沿 1 16 7 \r\nInnovation/Entrepreneurship and \r\nautomation frontier \r\n小 计 Subtotal 63.5 1104 160 0 0 16 \r\n（四）专业教育选修课程\r\nSpecialized Elective Courses\r\n信息与物联网方向\r\nInformation and Internet of things.\r\n4100208160 数据通讯与计算机网络 A 3 48 8 4 \r\nData Dommuncation and Domputer \r\nnetwork \r\n4100222170 物联网技术与工程 2.5 40 8 6 \r\n Introduction to Internet of Things \r\n4100219170 计算机过程控制系统 C 3.5 56 8 7 \r\n Instrument and Process Control System \r\n工控与智能机器人方向\r\nIndustrial control and intelligent robot \r\n11-51学时分配 Including 课程编号\r\nCourse\r\nNumber\r\n课 程 名 称\r\nCourse Title\r\n学分\r\nCrs 总学时\r\nTot hrs.\r\n实验\r\nExp.\r\n上机\r\nOpe‐\r\nration\r\n实践\r\nPrac‐\r\ntice\r\n课外\r\nExtra‐ \r\ncur\r\n建议\r\n修读\r\n学期\r\nSuggested\r\nTerm\r\n先修课程\r\nPrerequisite\r\nCourse\r\n4100223170 程序设计方法 C 2.5 40 8 3 \r\n Introduction to Programming Design \r\n4100178160 智能机器人 3 48 8 6 \r\n Introduction to Intelligent Robotics \r\n4100176160 运动控制系统 D 3.5 56 8 7 \r\n Motion Control System \r\n选修模块 1 \r\n4100179160 自动化专业与工业 4.0 认知实验 0.5 16 16 2 \r\nCongnition Experiment of Automation and \r\nIndustry 4.0 \r\n4070021110 信号处理与数据分析 2 32 4 \r\n Signal processing and data analysis \r\n4100058110 现代控制理论 2 32 6 6 \r\n Modern Control Theory \r\n4100224170 控制工程实践与系统仿真 3 48 16 6 \r\ncontrol engineering practice and system \r\nsimulation \r\n选修模块 2 \r\n4100182160 数据库与信息系统 2 32 12 2 \r\n database and infromation system \r\n4100186150 面向对象程序设计（C++） 2 32 12 2 \r\n object-oriented programming (c++) \r\n4100192160 图像处理与机器视觉 A 2.5 40 8 5 \r\n Photoelectron Materials and its Applications \r\n4100050110 模式识别概论 2 32 5 \r\n Introduction to Pattern Recognition \r\n4100225170 手机与 web 系统编程 3 48 16 6 \r\nprogramming for smart Phone and Web \r\nSystem \r\n选修模块 3 \r\n4100034110 电气 CAD 3 48 20 4 \r\n electrical CAD \r\n4100226170 电子设计自动化 C 2.5 40 12 5 \r\n Eelectronic Design Automation \r\n4100227170 嵌入式系统与应用 2.5 40 8 6 \r\n Embeded System and Application \r\n选修模块 4 \r\n4100228170 电器控制与可编程序控制器 3.5 56 16 5 \r\n Introduction to Pattern Recognition \r\n4100195160 工业机器人编程与实践 2 32 16 6 \r\nProgramming and Practice of Industrial \r\nRobot \r\n11-52学时分配 Including 课程编号\r\nCourse\r\nNumber\r\n课 程 名 称\r\nCourse Title\r\n学分\r\nCrs 总学时\r\nTot hrs.\r\n实验\r\nExp.\r\n上机\r\nOpe‐\r\nration\r\n实践\r\nPrac‐\r\ntice\r\n课外\r\nExtra‐ \r\ncur\r\n建议\r\n修读\r\n学期\r\nSuggested\r\nTerm\r\n先修课程\r\nPrerequisite\r\nCourse\r\n4100043110 工厂供电与节能技术 3 48 6 7 \r\nPlant Power Supply & Sower Saving \r\nTechnology \r\n4100229170 自动化综合实验 C 1.5 48 48 7 \r\n Automatic synthesis experiment \r\n小 计 Subtotal 46 768 192 44 0 0 \r\n修读说明：专业选修课程要求至少选修 20 学分，信息与物联网方向和工控与智能机器人方向并行上课，学生必须选择其\r\n一进行选修。学分不满 20 的通过其余选修课补齐总学分，选修另一模块课程等同选修课学分。若选择信息与物联网方向，\r\n则组合（工控与智能机器人方向和模块 1~4）中每个模块内的课程至少选一门。若选择工控与智能机器人方向，则组合（信\r\n息与物联网方向和模块 1~4）中每个模块内的课程至少选一门。\r\nNOTE：Minimum subtotal credits: 20. The students are required to take at least 20 credits from Specialized    Elective Courses ,\r\nInformation and Internet of things direction and industrial control and intelligent robot direction are taught in in parallel. Students\r\nmust choose one of them for elective courses. The students whose credits less than 20 will be filled by the remaining optional\r\ncourses, and the other modules will be equivalent to elective credits.    At least one in each module within the group (industrial\r\ncontrol and intelligent robot direction and module 1~4 ) should be chosen if Information and Internet of things direction.is\r\nchosen. At least one in each module within the group (Information and Internet of things direction and module 1~4 ) should be\r\nchosen if    industrial control and intelligent robot direction is chosen.\r\n（五）个性课程\r\nPersonalized Electice Courses\r\n4100230170 科学研究方法与学术论文写作 2 32 4 \r\nScientific research methods and academic \r\npaper writing \r\n4100103110 智能仪器仪表 2 32 5 \r\n intelligent instrument \r\n4100203160 人工智能与机器学习 2.5 40 8 5 \r\n Artifical Intelligence and Machine Learning \r\n4100001110 DSP 技术与应用 2 32 4 5 \r\n DSP Technology & Application \r\n4100210160 射频识别（RFID）原理与应用 2 32 7 \r\n pricipale and application of RFID \r\n4170149110 项目管理 A 2 32 7 \r\n project management \r\n小 计 Subtotal 12.5 200 12 0 0 0 \r\n修读说明：学生从以上个性课程和学校发布的其它个性课程目录中选课，要求至少选修 6 学分。\r\nNOTE: Sudents can select courses from above and the other personalized courses in catalog, and are required to obtain at\r\nleast 6 credits.\r\n五、 集中性实践教学环节\r\nⅤ Practice Schedule\r\n课程编号\r\nCourse\r\nNumber\r\n实践环节名称\r\nPractice Courses Name\r\n学分\r\nCrs\r\n周数\r\nWeeks\r\n建议修读学期\r\nSuggested Term\r\n1060002110 军事训练 1.5 3 1 \r\n Military Training \r\n11-53课程编号\r\nCourse\r\nNumber\r\n实践环节名称\r\nPractice Courses Name\r\n学分\r\nCrs\r\n周数\r\nWeeks\r\n建议修读学期\r\nSuggested Term\r\n4100068110 电工电子实习 A 2 2 3 \r\n Practice of Electrical Engineering & Electronics \r\n4080151110 机械制造工程实训 C 2 2 4 \r\n Training on Mechanical Manufacturing Engineering \r\n4100082110 生产实习 3 3 6（暑期）\r\n Practice of manufacture \r\n4100233170 自动化专业创新创业实践 1 1 7 \r\n Training Programs for Innovation and Entrepreneurship \r\n4100234170 毕业设计 10 17 8 \r\n Graduation Thesis \r\n信息与物联网工程方向 \r\n4100235170 工程设计训练（信息） 2 2 6（企业）\r\n engineering design training \r\n4100263170 专业实践（信息） 3 3 7（企业）\r\n profrssinal practice \r\n4100264170 岗位实习（信息） 8 8 7（企业）\r\n job practice \r\n工控与智能机器人方向 \r\n4100238170 工程设计训练(工控) 2 2 6（企业）\r\n engineering design training \r\n4100239170 专业实践（工控） 3 3 7（企业）\r\n profrssinal practice \r\n4100240170 岗位实习（工控） 8 8 7（企业）\r\n job practice \r\n小 计 Subtotal 32.5 41\r\n六、其它要求\r\nⅥ Recommendations on Course Studies \r\n1、《形势与政策》和《心理健康教育》课程为课外必修课程，分别计 2 个和 1 个课外学分。 \r\n2、学生选修的通识选修课程和从学校发布的个性课程目录中选修的个性课程，要求与本专业培养方案\r\n内设置的课程内容不重复。 \r\n1.Situation & Policy (2 credits) and Mental Health Education (1 credit) are the required extracurricular \r\ncourses. \r\n2.The selected General Education Elective Courses and Personalized Elective Courses from the courses \r\nprogram by university must be different from the major undergraduate education plan in content. \r\n \r\n学院教学责任人：周新民\r\n专业培养方案责任人：李志俊\r\n执笔人：傅    剑\r\n11-5', 0, 0, 0, 0, '2021-05-06 11:02:00', 1, 1);
INSERT INTO `article` VALUES (5, '自动化学院考试大纲', NULL, '硕士研究生入学考试\r\n—— 《自动控制原理》考试大纲\r\n\r\n第一部分 考试说明\r\n一．考试性质\r\n《自动控制原理》是为我校招收控制科学与工程等专业硕士研究生设置的考试科目。它的评价标准是高等学校优秀毕业生能达到及格或及格以上水平，以保证被录取者具有较扎实的专业基础。\r\n考试对象为符合全国硕士研究生报考条件的报考我校控制科学与工程（学硕）、控制工程（专硕）及工科其他相关专业的考生。\r\n\r\n二．考试形式与试卷结构\r\n（一）	答卷方式：闭卷，笔试；\r\n（二）	答题时间：180分钟。\r\n（三） 题型 ：计算题、分析题\r\n（四）参考书目：\r\n1. 自动控制原理(第六版) 胡寿松 主编 科学出版社\r\n2．	自动控制理论 王孝武 主编 机械工业出版社\r\n第二部分 考查要点\r\n（一）	自动控制的一般概念\r\n1．	自动控制和自动控制系统的基本概念，负反馈控制的原理；\r\n2．	控制系统的组成与分类；\r\n3．	根据实际系统的工作原理画控制系统的方块图。\r\n（二） 控制系统的数学模型\r\n1．	控制系统微分方程的建立，拉氏变换求解微分方程。\r\n2．	传递函数的概念、定义和性质。\r\n3．	控制系统的结构图，结构图的等效变换。\r\n4．	控制系统的信号流图，结构图与信号流图间的关系，由梅逊公式求系统的传递函数。\r\n（三）线性系统的时域分析\r\n1．	稳定性的概念，系统稳定的充要条件，Routh稳定判据。\r\n2．	稳态性能分析\r\n（1）	稳态误差的概念，根据定义求取误差传递函数，由终值定理计算稳态误差；\r\n（2）	静态误差系数和动态误差系数，系统型别与静态误差系数，影响稳态误差的因素。\r\n3．动态性能分析\r\n（1）	一阶系统特征参数与动态性能指标间的关系；\r\n（2）	典型二阶系统的特征参数与性能指标的关系；\r\n（3）	附加闭环零极点对系统动态性能的影响；\r\n（4）	主导极点的概念，用此概念分析高阶系统。\r\n（四）线性系统的根轨迹法\r\n1．	根轨迹的概念，根轨迹方程，幅值条件和相角条件。\r\n2．	绘制根轨迹的基本规则。\r\n3．	0o根轨迹。非最小相位系统的根轨迹及正反馈系统的根轨迹的画法。\r\n4．	等效开环传递函数的概念，参数根轨迹。\r\n5．	用根轨迹分析系统的性能。\r\n（五）线性系统的频域分析\r\n1．	频率特性的定义，幅频特性与相频特性。\r\n2．	用频率特性的概念分析系统的稳态响应。\r\n3．	频率特性的几何表示方法。\r\n（1）	典型环节及开环系统幅相频率特性曲线（又称奈氏曲线或极坐标图）的画法。\r\n（2）	典型环节及开环系统对数频率特性曲线（Bode图）的画法。\r\n（3）	由对数幅频特性求最小相位系统的开环传递函数。\r\n4．	Nquisty稳定性判据。\r\n（1）	根据奈氏曲线判断系统的稳定性，运用判断式 （ 从零到无穷大变化， ）或 （ 从 ～ ）；\r\n（2）	由对数频率特性判断系统的稳定性；\r\n5．	稳定裕量\r\n（1）	当系统稳定时，系统相对稳定性的概念。\r\n（2）	幅值裕量和相角裕量的定义及计算。\r\n（六）系统校正\r\n1．	校正的基本概念，校正的方式，常用校正装置的特性。\r\n2．	根据性能指标的要求，设计校正装置，用频率法确定串联超前校正、迟后校正和迟后-超前校正装置的参数。\r\n3．	将性能指标转换为期望开环对数幅频特性，根据期望特性设计最小相位系统的校正装置。\r\n4．	了解反馈校正和复合校正的基本思路与方法。\r\n\r\n（七）离散系统的分析与校正\r\n1．	离散系统的基本概念，脉冲传递函数及其特性，信号采样与恢复。\r\n2．	Z变换的定义，Z变换的方法。\r\n3．	离散系统的数学描述，差分方程与脉冲传递函数\r\n4．	离散系统的性能、和稳态误差分析。\r\n（1）稳定性分析。Z传递函数经W变换后，用劳斯判据分析其稳定性。\r\n（2）连续系统稳态性能分析方法在离散系统中的推广。\r\n（3）动态性能分析。离散系统的时间响应，采样器和保持器对动态性能的影响闭环极点与动态性能的关系。\r\n（八）非线性控制系统分析\r\n1．	非线性系统的特征，非线性系统与线性系统的区别与联系。\r\n2．	相平面作图法、奇点的确定，用极限环分析系统的稳定性和自振。\r\n3．	描述函数及其性质，用描述函数分析系统的稳定性、自振及有关参数。\r\n（九）线性系统的状态空间分析与综合\r\n1．	状态空间的概念，线性系统的状态空间描述，状态方程的解，状态转移矩阵及其性质。\r\n2．	线性系统的可控性与可观性，状态可控与输出可控的概念，可控与可观标准型。\r\n3．	线性定常系统的状态反馈\r\n\r\n', 1, 0, 0, 0, '2021-05-06 11:03:14', 1, 1);
INSERT INTO `article` VALUES (6, '工业互联网介绍', NULL, '工业互联网是全球工业系统与高级计算、分析、感应技术以及互联网连接融合的一种结果。\r\n工业互联网的本质是通过开放的、全球化的工业级网络平台把设备、生产线、工厂、供应商、产品和客户紧密地连接和融合起来，高效共享工业经济中的各种要素资源，从而通过自动化、智能化的生产方式降低成本、增加效率，帮助制造业延长产业链，推动制造业转型发展。\r\n工业互联网通过智能机器间的连接并最终将人机连接，结合软件和大数据分析，重构全球工业、激发生产力，让世界更美好、更快速、更安全、更清洁且更经济。中国工业互联网标识解析国家顶级节点落户在北京、上海、广州、武汉、重庆五大城市。 [1] \r\n2018年7月，工信部印发了《工业互联网平台建设及推广指南》和《工业互联网平台评价方法》。 [2]  2019年1月18日，工信部已印发《工业互联网网络建设及推广指南》。 [3]  3月，“工业互联网”成为“热词”并写入《2019年国务院政府工作报告》。', 0, 0, 0, 0, '2021-05-06 11:04:49', 2, 1);
INSERT INTO `article` VALUES (7, '工业互联网研究报告2021年', NULL, '工业革命是现代文明的起点，是人类生产方式\r\n的根本性变革。 １８ 世纪末的第一次工业革命创造\r\n了机器工厂的“蒸汽时代”，２０ 世纪初的第二次工\r\n业革命将人类带入大量生产的“电气时代”，这两\r\n个时代的划分已经是大家公认的。 ２０ 世纪中期计\r\n算机的发明、可编程控制器的应用使机器不仅延伸\r\n了人的体力，而且延伸了人的脑力，开创了数字控\r\n制机器的新时代，使人 －机在空间和时间上可以分\r\n离，人不再是机器的附属品，而真正成为机器的主\r\n人。 从制造业的角度，这是凭借电子和信息技术实\r\n现自动化的第三次工业革命。\r\n进入 ２１ 世纪，互联网、新能源、新材料和生物\r\n技术正在以极快的速度形成巨大产业能力和市场，\r\n将使整个工业生产体系提升到一个新的水平，推动\r\n一场新的工业革命，德国技术科学院（ＡＣＤＴＥＣＨ）\r\n等机构联合提出“第四代工业 －Ｉｎｄｕｓｔｒｙ ４．０”战略\r\n规划，旨在确保德国制造业的未来竞争力和引领世\r\n界工业发展潮流。 按照 ＡＣＤＴＥＣＨ 划分的四次工\r\n业革命的特征如图 １ 所示。 从图中可见，工业 ４．０\r\n与前三次工业革命有本质区别，其核心是信息物理\r\n系统的深度融合。\r\n2 信息物理融合系统\r\n处于人人可拥有多终端的互联网时代，任何由\r\n原子构成的实体产品都离不开比特，至少有条形\r\n图 １ 四次工业革命的不同特征\r\n码，或借助计算机来进行设计，或能够显示工作状\r\n态，或可进入物联网。 市场竞争已经充分表明，没\r\n有软件或软件含量低的实体产品，就是低附加值的\r\n产品，缺乏竞争力。 软件可以是“免费”的，但硬件\r\n身价翻番。 例如，在美国加州设计、中国装配的\r\nｉＰｈｏｎｅ 和 ｉＰａｄ 的售价里，１ ／３ 是原子，２／３ 是比特，\r\n比特的增值力使苹果成为最富有的公司，而富士康\r\n以工人健康和环境为代价仅获得微利。\r\n这一事实证明，任何产品的突破性创新和盈利\r\n能力都是原子和比特联姻的产物，是具有“人 －\r\n机”、“机 －机”相互通信能力的信息物理融合系统\r\n（Ｃｙｂｅｒ Ｐｈｙｓｉｃｓ Ｓｙｓｔｅｍ，ＣＰＳ），智能产品必将越来越\r\n普及。\r\n未来 １０ 年，由聪明机床、智能机器人和智能物\r\n流构成ＣＰＳ模式的工厂，分散的智能发电装置（如\r\n收稿日期：２０１４ －０７ －１５\r\n作者简介：张曙（１９３２—） ，男，江苏如皋人，同济大学现代制造技术研究所名誉所长，教授、博士生导师，主要研究方向为制造战略和机床设\r\n计。\r\n·１·\r\n２０１４ 年 ８ 月 机械设计与制造工程 Ａｇｕ．２０１４\r\n第 ４３ 卷 第 ８ 期 Ｍａｃｈｉｎｅ Ｄｅｓｉｇｎ ａｎｄ Ｍａｎｕｆａｃｔｕｒｉｎｇ Ｅｎｇｉｎｅｅｒｉｎｇ Ｖｏｌ．４３ Ｎｏ．８风电）构成 ＣＰＳ 模式的智能电网，以及各行各业和\r\n不同领域的 ＣＰＳ 构成的未来数字化智能城市如图\r\n２ 所示。\r\n图 ２ 基于互联网和物联网的智慧城市\r\n我国也已经开始在北京、上海、天津等地开展\r\n“智慧城市”的局部试点工作，将基础设施、资源环\r\n境、市政管理、医疗保障、经济和产业以及社会民生\r\n通过互联网和物联网连接在一起。 可以预计，不久\r\n的将来，新一代信息和通信技术将充分运用到各行\r\n各业，即把传感器、感应器等智能装置嵌入到电网、\r\n交通、建筑、工厂、货物等各种物体和环境中，并且\r\n通过有线和无线网络加以连接，形成物联网，再通\r\n过超级计算机和云计算将物联网和互联网整合起\r\n来，实现人类社会活动与物理系统的整合。 如图 ３\r\n所示。\r\n图 ３ 基于 ＣＰＳ 模式的社会架构\r\n3 明天的制造业：智能工厂\r\n工业 ４．０ 是一个产业的技术转型，是产业的变\r\n革。 工业 ４．０ 提出的智能制造是面向产品全生命\r\n周期，实现泛在感知条件下的信息化制造。 智能制\r\n造技术是在现代传感技术、网络技术、自动化技术\r\n以及人工智能的基础上，通过感知、人机交互、决\r\n策、执行和反馈，实现产品设计过程、制造过程和企\r\n业管理及服务的智能化，是信息技术与制造技术的\r\n深度融合与集成。\r\n智能化和自动化的最大区别在于知识的含量。\r\n智能制造是基于科学而非仅凭经验的制造，科学知\r\n识是智能化的基础。 因此，智能制造包含物质的和\r\n非物质的处理过程，不仅具有完善和快捷响应的物\r\n料供应链，还需要有稳定且强有力的知识供应链和\r\n产学研联盟，源源不断地提供高素质人才和工业需\r\n要的创新成果，发展高附加值的新产品，促进产业\r\n不断转型升级。\r\n智能制造是可持续发展的制造模式，它借助计\r\n算机建模仿真和信息通信技术的巨大潜力，优化产\r\n品的设计和制造过程，大幅度减少物质资源和能源\r\n的消耗以及各种废弃物的产生，同时实现循环再\r\n用，减少排放，保护环境。\r\n基于工业 ４．０ 构思的智能工厂将由物理系统\r\n和虚拟的信息系统组成，称之为信息物理生产系统\r\n（Ｃｙｂｅｒ Ｐｈｙｓｉｃｓ Ｐｒｏｄｕｃｔｉｏｎ Ｓｙｓｔｅｍ，ＣＰＰＳ），是为明天\r\n制造业勾画的蓝图，其框架结构如图 ４ 所示。\r\n图 ４ 信息物理生产系统 ＣＰＰＳ\r\n从图中可见，对应于进行物质生产的系统有一\r\n个虚拟的信息系统，它是物理系统的“灵魂”，控制\r\n和管理物理系统的生产和运作。 物理系统与信息\r\n系统通过移动互联网和物联网协同交互。 因此，这\r\n样的工厂不一定是在一个围墙里的实体车间。 它\r\n可以借助网络利用分散在各地的社会闲置设备，无\r\n需“关心”设备的确切所在地，只要关心设备可用\r\n与否，它是“全球本地化” 的工厂。 就好像在淘宝\r\n网上购物，并不需要知道实体商店在哪里，下了订\r\n单，宝贝就会快递到家。\r\n·２·\r\n２０１４ 年第 ４３ 卷 机械设计与制造工程这种新的生产模式，必将导致新的商业模式 、\r\n管理模式、企业组织模式以及人才需求的巨大变\r\n化。\r\n首先是产品设计与生产的分离。 今天，大到飞\r\n机、小到手机大多已经是异地设计和生产的。 关键\r\n是如何借助信息技术和网络将其进一步组织得更\r\n有效、更节约资源。 工业 ４．０ 提出以通信和服务为\r\n基础构建网络化智能工厂的设想，如图 ５ 所示。\r\n图 ５ 网络化的智能工厂\r\n从图中可见，智能工厂的生产环境由智能产\r\n品、智能设备、宜人的工作环境、高素质的劳动者和\r\n智能能源供应组成，他们相互之间进行企业内的通\r\n信，包括生产数据采集、工况分析、制造决策等。 若\r\n干智能工厂通过中间件、云计算和服务连接成庞大\r\n的制造网络，借助基于物流网的智能物流构建完整\r\n的制造体系。 因此，生产优势不仅是在特定生产条\r\n件下一次性体现，也以实现多家工厂、多个生产单\r\n元所形成的全球网络环境下的生产集合体的最优\r\n化为目标。\r\n智能工厂和物流之间的所有活动需要实时通\r\n信、交互和确认，即共同遵守规则环境，共同完成由\r\n顶层下达的任务。 建立这样分散的、网络化的智能\r\n工厂体系需要有一定的基础，应具有以下 ５ 个要素\r\n条件：（１）智能生产和产品，以先进的信息物理融\r\n合的设备生产高附加值的软硬结合的智能产品。\r\n（ ２）真实的企业环境，当前企业转型升级的途径和\r\n规划。 （３）宏观和微观经济环境，主要是产业政策\r\n和市场需求。 （４）人的因素，体现为新一代的管理\r\n人员、市场营销人员、技术人员和工人。 （５） 技术\r\n因素，主要体现为网络和通信基础设施的安全性和\r\n可靠性，智能生产技术等。 ', 1, 0, 0, 0, '2021-05-07 11:06:09', 2, 1);
INSERT INTO `article` VALUES (8, '工业4.0发展现状分析', NULL, '工业互联网是国家倡导的技术方向,是“新基建”的重点领域之一,也是企业和学术界普遍关注的热点话题。 工业互联网技\r\n术健康发展的关键在于能否为企业带来经济效益。 从经济性的角度,结合国内外众多实践案例的经验和教训,分析了该技术对企业\r\n业务的影响、价值创造的途径和难点,并对技术的发展趋势进行了总结和分析。 理论和实践都表明,工业互联网创造价值的能力与应\r\n用场景密切相关。 分别针对企业内部和企业之间两类场景,分析了各自的问题、技术特点和发展前景。 工业互联网平台技术是促进\r\n工业互联网发展的工具,会对我国制造业的产业生态产生重大和深远的影响。 促进工业互联网的发展,需要从战略和管理的角度着\r\n眼,而不能仅仅着眼于具体技术。', 1, 0, 0, 1, '2021-05-07 11:06:56', 2, 1);
INSERT INTO `article` VALUES (9, '神经网络入门', NULL, '残差网络\r\nResNet(Residual Neural Network)由微软研究院的Kaiming He等4名华人提出，通过Residual Unit(见图1)成功训练152层深的神经网络，在ILSVRC 2015比赛中获得了冠军，取得3.57%的top-5错误率，同时参数比VGGNet低，效果非常突出。\r\n\r\n\r\n**图1：ResNet的残差学习模块**\r\n理论上来说网络的深度越深，那么就可以很好的拟合任意的数据分布，实际上通过实验得知，当网络深度增加到一定的程度的时候，学习过程反而变的很差，训练的错误率不降反升。并且收敛的速度也会变的很慢，如下图所示：\r\n\r\n\r\n这就是所谓的Degradation的问题，即准确率先上升再达到饱和，再持续增加深度则会导致准确率的下降，这并不是过拟合的问题，因为不光在测试集上误差增加，训练集误差也会增加。假设有一个比较浅的网络达到饱和的准确率，那么后再加上几个y=x的映射层，起码误差不会增加，映射将前一层的输出传给后面的思想就是ResNet的灵感来源。\r\n残差网络的出现意在解决，网络训练的深度问题和训练的复杂度，其两个主要的特点是：\r\n\r\n收敛快，相比普通网络收敛快，容易训练；\r\n\r\n可以通过简单的堆叠这种结构以获得更高的正确率；\r\n\r\n1.什么是残差块\r\n\r\n直观认为学习一个非线性的结构要比学习一个恒等映射要难的多\r\n\r\n残差块之所以叫残差，相当于应层中学习的是残差，而非非线性的函数函数映射\r\n\r\n这种办法使得网络额复杂度并没有增加多少，但是他可以变的更深，残差的收敛速度更快，并且使得网络的层数更深\r\n\r\n2.残差网络的结构\r\n\r\n残差网络在各种图像识别和目标检测的任务重都获得了不错的成绩，详细的可以参考：Deep Residual Learning for Image Recognition\r\n\r\n3. ResNet V2\r\n分析了残差块背后的计算传播方式，表明了当shortcut以及附加激活项都使用恒等映射(identity mappings)时，前向和后向的信号能够直接的从一个block 传递到其他任意一个block。一系列的“消融”实验(ablation experiments)也验证了这些恒等映射的重要性。作者提出了一个新的残差单元，它使得训练变得更简单，同时也提高了网络的泛化能力。\r\n\r\nIntroduction\r\n深度残差网络(ResNets)由很多个“残差单元”组成。每一个单元(Fig.1 (a))可以表示为：\r\n\r\n\r\n其中 $x_l$ 和 $x_{l+1}$ 是第l个单元的输入和输出， F 表示一个残差函数。在He2016中， $h(x_l)=x_l$ 代表一个恒等映射，f 代表 ReLU, 这像极了Gradient Boosting.\r\n\r\n\r\nFig.1 (a) 原始残差单元；(b) 本文提出的残差单元；右：1001层ResNets 在CIFAR-10上的训练曲线。实线对应测试误差(右侧的y轴)，虚线对应训练损失(左侧的y轴)。本文提出的单元使得ResNet-1001的训练更简单。\r\n实验表明： 还是恒等映射好，网络的深度很重要 （为什么恒等映射好，理论上没有说明）\r\n\r\nAnalysis of Deep Residual Networks\r\n\r\n\r\n在mini-batch中，梯度(Eq.5)不可能出现梯度消失，因为在一个mini-batch上Eq.5后边的式子基本不会总为-1，也就是说即使很小的权重，也不会存在梯度消失，我想这也是ResNet之所以训练这多深的原因（实际上我们在训练深层网络结构时，是不害怕梯度爆炸的，但是非常害怕梯度消失）\r\n\r\nOn the Importance of Identity Skip Connections\r\n\r\n\r\n\r\nExperiments on Skip Connections\r\n\r\n\r\n\r\nDiscussions\r\n如Fig.2中灰色箭头所示，捷径连接是信息传递最直接的路径。 捷径连接中的操作 (缩放、门控、1×1 的卷积以及 dropout) 会阻碍信息的传递，以致于对优化造成困难。\r\n\r\n值得注意的是1×1的卷积捷径连接引入了更多的参数，本应该比恒等捷径连接具有更加强大的表达能力。事实上，shortcut-only gating 和1×1的卷积涵盖了恒等捷径连接的解空间(即，他们能够以恒等捷径连接的形式进行优化)。然而，它们的训练误差比恒等捷径连接的训练误差要高得多，这表明了这些模型退化问题的原因是优化问题，而不是表达能力的问题。\r\n\r\nOn the Usage of Activation Functions\r\n以上的实验内容验证了Eq.5和Eq.8中的分析，两个公式都是基于连接后的激活函数 f 为恒等连接的假设。但是在上述实验中f是以He2016中的ReLU设计的，因此，Eq.5和8只是以上实验的估计。接下来我们研究f的影响。\r\n\r\n我们希望通过重新安排激活函数(ReLU和/或BN)来使得 f 为一个恒等映射。He2016中的原始残差连接的形状如Fig.4(a) — BN在每一个权重层之后使用，之后再接一个ReLU，在最后的元素相加之后还有最后一个ReLU(即f= ReLU)。 Fig.4(b-e)展示了我们研究的其他形式，解释如下。\r\n\r\n\r\n\r\nExperiments on Activation\r\n\r\n\r\n\r\n\r\n\r\nhttps://blog.csdn.net/wspba/article/details/60750007\r\n\r\n4.Tensorflow实现ResNet\r\n以上主要是ResNet V1版本的理论知识，在ResNet作者的第二篇论文：Identity Mappings in Deep Residual Networks中， ResNet V2被提出，Residual V2和Residual V1的主要区别在于：\r\n\r\n作者通过研究ResNet残差学习单元的传播公式，发现前馈和反馈信号可以直接传输，因此skip connection的非线性激活函数（如ReLU）替代为Identity Mapping (y = x)。\r\n\r\nResNet V2在每一层都使用了Batch Normalization。这样处理之后，新的残差学习单元将比以前更容易训练且泛化性更强。\r\n\r\n下面我们就用Tensorflow实现一个ResNet V2网络。我们依然使用方便的contrib.slim库来辅助创建ResNet。\r\n\r\n# -*- coding: utf-8 -*-\r\nimport os\r\nos.environ[\'TF_CPP_MIN_LOG_LEVEL\'] = \'2\'\r\n \r\n# ResNet V2\r\n# 载入模块、TensorFlow\r\nimport collections\r\nimport tensorflow as tf\r\n \r\nslim = tf.contrib.slim\r\n# 注意tf.contrib类,很多和卷积相关的模块都在slim中，例如AlexNet,VGG\r\n \r\n# 定义Block,结构体,自动以的一种数据结构\r\nclass Block(collections.namedtuple(\'Block\', [\'scope\', \'unit_fn\', \'args\'])):\r\n    \'A named tuple describing a ResNet block\'\r\n\r\n# 说明： 见bottleneck这个函数\r\n# scope:\"block1\",\"block2\".....\r\n# unit_fn: bottleneck 残差学习单元\r\n# args: 参数 见resnet_v2_50\r\n\r\n \r\n# 定义降采样subsample方法\r\ndef subsample(inputs, factor, scope=None):\r\n    \'\'\'\r\n    factor: 1不做修改直接返回input,其他时使用最大池化1X1的尺寸，步长是factor\r\n    scope: 变量的命名空间\r\n    \'\'\'\r\n \r\n    if factor == 1:\r\n        return inputs\r\n    else:\r\n        return slim.max_pool2d(inputs, [1, 1], stride=factor, scope=scope)\r\n \r\n# 定义conv2d_same函数创建卷积层\r\ndef conv2d_same(inputs, num_outputs, kernel_size, stride, scope=None):\r\n    \'\'\'\r\n    如果factor=1直接“SAME\"填充\r\n    如果factor!=1,input做填充\r\n    \'\'\'\r\n    if stride == 1:\r\n        return slim.conv2d(inputs, num_outputs, kernel_size, stride=1,\r\n                           padding=\'SAME\', scope=scope)\r\n    else:\r\n        # kernel_size_effective = kernel_size + (kernel_size - 1) * (rate - 1)\r\n        pad_total = kernel_size - 1  #pad的总数\r\n        pad_beg = pad_total // 2\r\n        pad_end = pad_total - pad_beg\r\n        inputs = tf.pad(inputs,\r\n                        [[0, 0], [pad_beg, pad_end], [pad_beg, pad_end], [0, 0]])\r\n        # input,张量维度：在8个维度上的填充，填充模式，填充值默认为0\r\n        return slim.conv2d(inputs, num_outputs, kernel_size, stride=stride,\r\n                           padding=\'VALID\', scope=scope)\r\n \r\n \r\n@slim.add_arg_scope\r\n# 装饰目标函数，arg_scope为目标函数设置默认参数\r\n# 定义堆叠Blocks函数\r\ndef stack_blocks_dense(net, blocks,\r\n                       outputs_collections=None):\r\n \r\n    for block in blocks:\r\n        with tf.variable_scope(block.scope, \'block\', [net]) as sc:\r\n            #name_or_scope,default_name=None,values=None\r\n            for i, unit in enumerate(block.args):\r\n                with tf.variable_scope(\'unit_%d\' % (i + 1), values=[net]):\r\n                    unit_depth, unit_depth_bottleneck, unit_stride = unit\r\n                    net = block.unit_fn(net, # 残差学习的生成函数 bittleneck函数\r\n                                        depth=unit_depth,\r\n                                        depth_bottleneck=unit_depth_bottleneck,\r\n                                        stride=unit_stride)\r\n            net = slim.utils.collect_named_outputs(outputs_collections, sc.name, net)\r\n            # 将输出net添加到collection\r\n \r\n    return net\r\n \r\n# 创建ResNet通用arg_scope，定义函数默认参数值\r\n# arg_sope用来定义默写函数参数的默认值\r\ndef resnet_arg_scope(is_training=True,\r\n                     weight_decay=0.0001,\r\n                     batch_norm_decay=0.997,\r\n                     batch_norm_epsilon=1e-5,\r\n                     batch_norm_scale=True):\r\n \r\n    batch_norm_params = {\r\n        \'is_training\': is_training,\r\n        \'decay\': batch_norm_decay,\r\n        \'epsilon\': batch_norm_epsilon,\r\n        \'scale\': batch_norm_scale,\r\n        \'updates_collections\': tf.GraphKeys.UPDATE_OPS,\r\n    }\r\n \r\n    with slim.arg_scope(\r\n            [slim.conv2d],\r\n            weights_regularizer=slim.l2_regularizer(weight_decay),\r\n            weights_initializer=slim.variance_scaling_initializer(),\r\n            activation_fn=tf.nn.relu,\r\n            normalizer_fn=slim.batch_norm,\r\n            normalizer_params=batch_norm_params):\r\n        with slim.arg_scope([slim.batch_norm], **batch_norm_params):\r\n \r\n            with slim.arg_scope([slim.max_pool2d], padding=\'SAME\') as arg_sc:\r\n                return arg_sc\r\n \r\n \r\n@slim.add_arg_scope\r\n# 定义核心bottleneck残差学习单元\r\ndef bottleneck(inputs, depth, depth_bottleneck, stride,\r\n               outputs_collections=None, scope=None):\r\n \r\n    with tf.variable_scope(scope, \'bottleneck_v2\', [inputs]) as sc:\r\n        depth_in = slim.utils.last_dimension(inputs.get_shape(), min_rank=4)\r\n        # 获取输入的最后一个维度，即channel数，min_rank限定最少为4个维度\r\n        preact = slim.batch_norm(inputs, activation_fn=tf.nn.relu, scope=\'preact\')\r\n        # batch normalization,并进行Relu预激活\r\n        if depth == depth_in:\r\n            shortcut = subsample(inputs, stride, \'shortcut\')  # 降采样 使得输入通道数epth_in与depth一致\r\n        else: #用1X1的卷积改变通道数\r\n            shortcut = slim.conv2d(preact, depth, [1, 1], stride=stride,\r\n                                   normalizer_fn=None, activation_fn=None,\r\n                                   scope=\'shortcut\')\r\n \r\n        residual = slim.conv2d(preact, depth_bottleneck, [1, 1], stride=1,\r\n                               scope=\'conv1\')\r\n        residual = conv2d_same(residual, depth_bottleneck, 3, stride,\r\n                               scope=\'conv2\')\r\n        residual = slim.conv2d(residual, depth, [1, 1], stride=1,\r\n                               normalizer_fn=None, activation_fn=None,\r\n                               scope=\'conv3\')\r\n \r\n        output = shortcut + residual  # identity的\r\n        \r\n        # output加入到集合并返回output\r\n        return slim.utils.collect_named_outputs(outputs_collections,\r\n                                                sc.name,\r\n                                                output)\r\n \r\n# 定义生成ResNet V2的主函数\r\ndef resnet_v2(inputs, \r\n              blocks,  # 定义好的类的列表\r\n              num_classes=None, #最后输出的类数\r\n              global_pool=True, # 是否加入最后一层的全局平均池化\r\n              include_root_block=True,  # 是否加入最前面通常使用的7X7的卷积池化\r\n              reuse=None,  #是否重用\r\n              scope=None):  #整个网络的名称（命名空间）\r\n \r\n    with tf.variable_scope(scope, \'resnet_v2\', [inputs], reuse=reuse) as sc:\r\n        end_points_collection = sc.original_name_scope + \'_end_points\'\r\n        with slim.arg_scope([slim.conv2d, bottleneck,\r\n                             stack_blocks_dense],\r\n                            outputs_collections=end_points_collection):\r\n            net = inputs\r\n            if include_root_block:\r\n \r\n                with slim.arg_scope([slim.conv2d],\r\n                                    activation_fn=None, normalizer_fn=None):\r\n                    net = conv2d_same(net, 64, 7, stride=2, scope=\'conv1\')\r\n                net = slim.max_pool2d(net, [3, 3], stride=2, scope=\'pool1\')\r\n            net = stack_blocks_dense(net, blocks)\r\n \r\n            net = slim.batch_norm(net, activation_fn=tf.nn.relu, scope=\'postnorm\')\r\n            if global_pool:\r\n                # Global average pooling.\r\n                net = tf.reduce_mean(net, [1, 2], name=\'pool5\', keep_dims=True) # avg_pool\r\n            if num_classes is not None:\r\n                net = slim.conv2d(net, num_classes, [1, 1], activation_fn=None,\r\n                                  normalizer_fn=None, scope=\'logits\')\r\n            # Convert end_points_collection into a dictionary of end_points.\r\n            # 将collection转化为dict\r\n            end_points = slim.utils.convert_collection_to_dict(end_points_collection)\r\n            if num_classes is not None:\r\n                end_points[\'predictions\'] = slim.softmax(net, scope=\'predictions\')\r\n            # 返回net和end_points\r\n            return net, end_points\r\n \r\n\r\n#----------------------------------------------------------\r\n# 设计层数为50的ResNet V2\r\ndef resnet_v2_50(inputs,\r\n                 num_classes=None,\r\n                 global_pool=True,\r\n                 reuse=None,\r\n                 scope=\'resnet_v2_50\'):\r\n    blocks = [\r\n        Block(\'block1\', bottleneck, [(256, 64, 1)] * 2 + [(256, 64, 2)]),\r\n        # Depth:输出通道数,depth_bottleneck,stride\r\n        # (256,64,1): 256第三层输出的通道数，64:前两层输出的通道数，1:中间层的步长\r\n        Block(\r\n            \'block2\', bottleneck, [(512, 128, 1)] * 3 + [(512, 128, 2)]),\r\n        Block(\r\n            \'block3\', bottleneck, [(1024, 256, 1)] * 5 + [(1024, 256, 2)]),\r\n        Block(\r\n            \'block4\', bottleneck, [(2048, 512, 1)] * 3)]\r\n    return resnet_v2(inputs, blocks, num_classes, global_pool,\r\n                     include_root_block=True, reuse=reuse, scope=scope)\r\n \r\n# 设计101层的ResNet V2\r\ndef resnet_v2_101(inputs,\r\n                  num_classes=None,\r\n                  global_pool=True,\r\n                  reuse=None,\r\n                  scope=\'resnet_v2_101\'):\r\n    blocks = [\r\n        Block(\r\n            \'block1\', bottleneck, [(256, 64, 1)] * 2 + [(256, 64, 2)]),\r\n        Block(\r\n            \'block2\', bottleneck, [(512, 128, 1)] * 3 + [(512, 128, 2)]),\r\n        Block(\r\n            \'block3\', bottleneck, [(1024, 256, 1)] * 22 + [(1024, 256, 2)]),\r\n        Block(\r\n            \'block4\', bottleneck, [(2048, 512, 1)] * 3)]\r\n    return resnet_v2(inputs, blocks, num_classes, global_pool,\r\n                     include_root_block=True, reuse=reuse, scope=scope)\r\n \r\n# 设计152层的ResNet V2\r\ndef resnet_v2_152(inputs,\r\n                  num_classes=None,\r\n                  global_pool=True,\r\n                  reuse=None,\r\n                  scope=\'resnet_v2_152\'):\r\n    blocks = [\r\n        Block(\r\n            \'block1\', bottleneck, [(256, 64, 1)] * 2 + [(256, 64, 2)]),\r\n        Block(\r\n            \'block2\', bottleneck, [(512, 128, 1)] * 7 + [(512, 128, 2)]),\r\n        Block(\r\n            \'block3\', bottleneck, [(1024, 256, 1)] * 35 + [(1024, 256, 2)]),\r\n        Block(\r\n            \'block4\', bottleneck, [(2048, 512, 1)] * 3)]\r\n    return resnet_v2(inputs, blocks, num_classes, global_pool,\r\n                     include_root_block=True, reuse=reuse, scope=scope)\r\n \r\n# 设计200层的ResNet V2\r\ndef resnet_v2_200(inputs,\r\n                  num_classes=None,\r\n                  global_pool=True,\r\n                  reuse=None,\r\n                  scope=\'resnet_v2_200\'):\r\n    blocks = [\r\n        Block(\r\n            \'block1\', bottleneck, [(256, 64, 1)] * 2 + [(256, 64, 2)]),\r\n        Block(\r\n            \'block2\', bottleneck, [(512, 128, 1)] * 23 + [(512, 128, 2)]),\r\n        Block(\r\n            \'block3\', bottleneck, [(1024, 256, 1)] * 35 + [(1024, 256, 2)]),\r\n        Block(\r\n            \'block4\', bottleneck, [(2048, 512, 1)] * 3)]\r\n    return resnet_v2(inputs, blocks, num_classes, global_pool,\r\n                     include_root_block=True, reuse=reuse, scope=scope)\r\n \r\n \r\nfrom datetime import datetime\r\nimport math\r\nimport time\r\n \r\n# 评测函数\r\ndef time_tensorflow_run(session, target, info_string):\r\n    num_steps_burn_in = 10\r\n    total_duration = 0.0\r\n    total_duration_squared = 0.0\r\n    for i in range(num_batches + num_steps_burn_in):\r\n        start_time = time.time()\r\n        _ = session.run(target)\r\n        duration = time.time() - start_time\r\n        if i >= num_steps_burn_in:\r\n            if not i % 10:\r\n                print(\'%s: step %d, duration = %.3f\' %\r\n                      (datetime.now(), i - num_steps_burn_in, duration))\r\n            total_duration += duration\r\n            total_duration_squared += duration * duration\r\n    mn = total_duration / num_batches\r\n    vr = total_duration_squared / num_batches - mn * mn\r\n    sd = math.sqrt(vr)\r\n    print(\'%s: %s across %d steps, %.3f +/- %.3f sec / batch\' %\r\n          (datetime.now(), info_string, num_batches, mn, sd))\r\n \r\n \r\nbatch_size = 32\r\nheight, width = 224, 224\r\ninputs = tf.random_uniform((batch_size, height, width, 3))\r\nwith slim.arg_scope(resnet_arg_scope(is_training=False)):\r\n    net, end_points = resnet_v2_152(inputs, 1000) # 152层评测\r\n \r\ninit = tf.global_variables_initializer()\r\nsess = tf.Session()\r\nsess.run(init)\r\nnum_batches = 100\r\ntime_tensorflow_run(sess, net, \"Forward\")', 1, 0, 0, 1, '2021-05-08 11:28:11', 3, 1);
INSERT INTO `article` VALUES (10, '卷积核', NULL, 'Inception\r\n1.NIN\r\n1X1的卷积核，我们在深度学习之CNN中解释了为什么卷积核往往就是奇数，并且着重介绍了1X1的卷积核的作用，本节将重复介绍《Network in NetWork》 paper中关于1x1卷积核的作用，并为Inception中的应用做铺垫。\r\n\r\nNIN的paper主要对CNN结构进行改进，是得CNN能够学习更加抽象和有效的非线性特征。 统的卷积层只是将前一层的特征进行了线性组合，然后经过一个非线性激活。而在文章中，作者提出了使用一个微小的神经网络(主要是多层感知器)来替代普通的卷积过程，当然，这个微小的神经网络也和卷积的权值共享一样，即对于相同的特征层是相同的。传统的卷积过程和微网络分别如图所示：\r\n\r\n\r\n由图可知，mlpconv=convolution+mlp（图中为2层的mlp）。\r\n\r\n在实现上,mlpconv=convolution+1×1convolution+1×1convolution（2层的mlp）\r\n\r\n实现NIN就是在原来的卷积后再加上1X1的卷积即可，如下图，有三个NIN层，那么第一个NIN的实现应该是conv1[3X3], conv2[1X1],conv3[1X1]\r\n\r\n\r\n作者之所以进行这样的改进，主要是因为，传统的卷积层只是一个线性的过程，而且，层次比较深的网络层是对于浅层网络层学习到的特征的整合，因此，在对特征进行高层次整合之前，进行进一步的抽象是必要的。\r\n\r\n对于选择多层感知器作为微网络结构，主要是处于下面两个方面的考虑：\r\n\r\n多层感知器也是使用BP算法进行训练的，可以与CNN进行整合；\r\n\r\n多层感知器也可以作为一个深层结构，也包含了特征重用的思想。\r\n\r\n除此之外，文中作者使用了Global Average Pooling，来替代全连接层，这个主要是为了使得最后一个多层感知卷积层获得的每一个特征图能够对应于一个输出类别。 使用全局平均池化的优点有两个：\r\n\r\n使用全局平均池化能够强化特征图与类别的关系；\r\n\r\n全局平均池化没有参数需要进行优化，因此，可以避免在这一层出现过拟合。\r\n\r\n全局平均池化的过程是对于每一个特征图求出其平均数，然后将这些平均数组成一个特征向量，输入到softmax层中。如下图所示：\r\n\r\n\r\nReference:\r\n\r\n[1]. Network In Network\r\n\r\nNIN 这种思想被抽象成1X1的卷积核，这种1X1的卷积核被大量的应用在GoogleNet中。\r\n\r\nGoogle Inception Ne首次出现在ILSVRC 2014的比赛中，就以较大的优势取得第一名，那一届的比赛中的Inception Net通常被称为Inception V1.接着后边又出现了其他版本的Inception包括(v2,v3,v4),接下来我们就看一下基本的Inception结构及每一个版本的Inception的改进，最后通过Tendorflow实现一个Inception网络结构。\r\n\r\n2.GoogleNet(Inception V1)\r\n基本的网络结构，是把每个卷积核作用的结构进行堆叠，形成新的更深chanel的结构，如下图所示：\r\n\r\n\r\n为了降低计算的复杂度和参数个数引入了1X1的卷积核：\r\n\r\n\r\n论文中对应的结构为：\r\n\r\n\r\nGoogleLeNet的结构如下图所示：\r\n\r\n\r\nInception V1参数少且效果好的原因除了模型层数更深，表达能力更强之外，还有两点：一是去除了最后的全连接层，用NIN中的全局平均池化（参数少，泛化能力将会变强），二的原因是Inception V1中精心设计的Inception Module模块提高了参数的利用率。实际上这一部分可以借鉴与NIN中的思想，相当于在大网络中套了很多个子网络。除此之外InceptionV1网络层的中间层也会有输出。\r\n\r\nInception V1有22层的深度，除了最后一层的输出，中间节点的分类效果也不错，因此在Inception Net中，还是用了辅助分类节点，即将中间层的输出作为分类，并按照一定的权重加（比如0.3)加到最终的分类结果，这样相当于做了模型融合，就像在论文应引入的网络俚语一样：\r\n\r\n\r\n除此之外，Google Inception Net还有一个大家族，包括：\r\n\r\n2014年9月：Going Deeper with Convolutions提出的Inception V1（top-5的错误率6.67%）\r\n2015年2月：Batch Normalization:Accelerating Deep Network Training by Reducing Internal Covariate提出的Inception V2（Top-5的错误率是4.8%）\r\n2015年12月：Rethinking the Inception Architecture for Computer Vision提出的Inception V3（top-5错误率3.5%）\r\n2016年2月：Inception-v4,Inception-ResNet and the Impact of Residual Commentions on Learning提出的Inception V4(top-5错误率3.08%）\r\n下面我们就以依次来看一下这几个网络结构。\r\n\r\n3.Inception V2\r\nInceptin V2对V1做了如下的改变：首先在网络结构上，用两个3X3的卷积代替5X5的大卷积(用以降低参数量并减轻过拟合),同时和提出了著名的Batch Normalization（BN),下面我们细致的看一下这两个变化：\r\n\r\n关于卷积核的变化：\r\n\r\n\r\n关于BN:\r\n\r\nBN是一种非常有效的正则化方法，可以让大型卷积网络的训练速度加快很多倍，同时收敛后的分类准确率也可以大幅提高。BN在用于神经网络某层时，会对每一个mini-batch数据的内部进行标准化处理，使得输出规范到N(0,1)的正态分布，减少了内部神经元分布的改变(Internal Covariate Shift)。论文中提到，传统的深度神经网络在训练时，每一层的输入的分布都在变化，导致训练变得困难，我们只能使用一个很小的学习率来解决这个问题。而对于每一层使用BN之后，就可以有效的解决这个问题。因为BN某种意义上还起到了正则化的作用，因此可以减少或取消Dropout，简化网络结构。\r\n\r\nBN算法:\r\n\r\n\r\n\r\n4.Inception V3\r\nInception V3网络主要有两方面的改进：一是引入了Factorization into small convolutions的思想，将一个较大的二维卷积拆成两个较小的一维卷积，比如将7X7的卷积拆成1X7和7X1的卷积，或者将3X3的卷积拆成1X3或3x1的卷积,如下图所示：\r\n\r\n\r\n一方面节约了大量的参数，加速运算减轻了过拟合；同时增加了一层非线性扩展模型的表达能力。论文指出，这种非对称的卷积结构拆分，其结果比对称的拆分为几个相同的小卷积核效果更明显，可以处理更多，更丰富的空间特征，增加特征多样性。\r\n\r\n另一方面Inception V3优化了Inception Module的结构，现在Inception module有35X35,17X17,8X8三种不同的结构(如下图所示),这些Inception Module只在网络的后部分出现，前部还是普通的卷积层。并且Inception V3除在Inception Module中使用分支，还在分支中使用了分支（8X8)的结构中，可以说是Network in Network in Network。\r\n\r\n\r\nInception V3模型总共46层，由11个Inception模块组成，有96个卷积层，我们在第6部分将实现一个Inception V3的模型。\r\n\r\n5.Inception V4\r\nInception V4主要利用残差链接(Residual Connection）来改进v3结构，代表作有Inception-ResNet-v1,Inception-ResNet-v2,inception-v4。Inception-ResNet的改进就是使用以上三部分中的Inception module来替换ResNet shortcut中额1X1conv+conv,如下图所示:\r\n\r\n\r\n将Inception Module与Resdual Connection结合，提出了Inception-ResNet-v1,Inception-ResNet-v2,使得训练加速收敛更快，精度更高。\r\n\r\n设计了更深的Inception-v4版本，效果和Inception-ResNet-v2相当\r\n\r\n网络输入大小和V3相同买还是299X299\r\n\r\n下面我们看这几种网路结构\r\n\r\nInception V4:\r\n\r\n\r\nInception-ResNet V1:\r\n\r\n\r\nInception-ResNet v2:\r\n\r\n\r\n6.Tensorflow实现Inception\r\n本节我们将实现Inception V3结构，关于Google Inception的网络结构的Tnesorflow实现可以参考Tensorflow的官方示例代码。下面我们使用tensorflow-sim工具来更加简洁的实现一个卷积层\r\n\r\n# 直接使用Tnesorflow原始API实现卷积层\r\n\r\nwith tf.variable_scope(scope_name):\r\n	weights = tf.get_variable(\"weights\",...)\r\n	biases = tf.get_variable(\"bias\",...)\r\n	conv = tf.nn.conv2d(...)\r\nrelu = tf.nn.rrlu(tf.nn.bias_add(conv,biases))\r\n\r\nimport tensorflow as tf\r\nslim = tf.contrib.slim\r\n# 使用tensorflow-slim实现卷积层。通过tensorflow-slim可以在一行中实现一个卷积层\r\n# 的前向传播算法。slim.conv2d函数的有三个参数是必要的，第一个参数为输入节点矩阵\r\n# 第二个参数为当前卷积层过滤器的深度，第三个参数是过滤器的尺寸。可选的参数有过滤器\r\n# 移动的步长，是否使用全0填充，激活函数的选择以及变量的命名空间等。\r\n\r\nnet = slim.conv2d(input,32,[3,3])\r\n# slim.arg_scope函数可以用于设置默认的参数取值，slim.arg_scope函数的第一个参数是\r\n# 一个函数列表，在这个列表中的函数将使用默认的参数取值。比如通过下面的定义，调用\r\n# slim.conv2d(net,320,[1,1])函数时会自动加上stride=1和padding=\'SAME\'的参数。如果在\r\n# 函数调用时指定了stride,那么这里设置的默认值就不会再使用，通过这种方式可以进一步减少\r\n# 冗余的代码\r\n\r\nwith slim.arg_scope([slim.conv2d,slim.max_pool2d,slim.avg_pool2d],stride=1,padding=\"SAME\"):\r\n	...\r\n	# 此处省略Inception v3中的其他结构，而直接实现Inception Module部分的结构，其他结构\r\n	# 写法是相同的。\r\n	net = 上一层的输出节点矩阵\r\n\r\n	# 为一个Inception Module声明一个统一的命名空间\r\n	with tf.variable_scope(\"Maxed_7c\"):\r\n		# 给Inception Module中的每条路径声明一个命名空间\r\n		with tf.variable_scope(\"Branch_0\"):\r\n			# 实现一个过滤器边长为1，深度为320的卷积层\r\n			branch_0 = slim.conv2d(net,320,[1,1],scope=\'Conv2d_0a_1x1\')\r\n\r\n		# Inception Module中的第2条路径，这条路径上的结构本身也是一个Inception结构\r\n		with yf.variable_scope(\"Branch_1\"):\r\n			branch_1 = slim.conv2d(net,384,[1,1],scope=\"Conv2d_0a_1X1\")\r\n			# tf.concat函数可以将多个矩阵拼接起来。tf.concat函数的第一个参数指定了\r\n			# 拼接的维度，这里给出的“3”表示矩阵是在深度这个维度上进行拼接，这就是\r\n			# Inception Module中的拼接方式\r\n\r\n			branch_1 = tf.concat(3,[\r\n				# 注意此处的两层卷积的输入都是branch_1,而不是net\r\n				slim.conv2d(branch_1,384,[1,3],scope=\"Conv2d_0b_1X3\"),\r\n				slim.conv2d(branch_1,384,[3,1],scope=\"Conv2d_0b_3X1\") ])\r\n\r\n		# Inception Module中的第3条路径，此时计算路径也是一个Inception结构\r\n		with tf.variable_scope(\"Branch_2\"):\r\n			branch_2 = slim.conv2d(net,448,[1,1],scope=\"Conv2d_0a_1X1\")\r\n			branch_2 = slim.conv2d(branch_2,384,[3,3],scope=\"Cnv2d_0b_3X3\")\r\n			branch_2 = tf.concat(3,[\r\n				slim.conv2d(branch_2,384,[1,3],scope=\"Conv2d_0c_1X3\")\r\n				slim.conv2d(branch_2,384,[3,1],scope=\"Conv2d_0d_3X1\")\r\n				])\r\n\r\n		# Inception Module中额第4条路径.\r\n		with tf.variable_scope(\"Branch_3\"):\r\n			branch_3 = slim.avg_pool2d(net,[3,3],scope=\"AvgPool_0a_3X3\")\r\n			branch_3 = slim.conv2d(branch_3,192,[1,1],scope=\"Conv2d_0b_1X1\")\r\n		#当前Inception Module的最后输出是由上面四个计算结果拼接得到的\r\n		net = tf.concat(3,[branch_0,branch_1,branch_2,brnch_3])\r\n', 0, 0, 0, 1, '2021-05-08 11:29:14', 3, 1);
INSERT INTO `article` VALUES (11, 'Harr特征', NULL, 'R-CNN系列 & SPP-net\r\n我们本部分的学习路线为:R-CNN, Selective Search, SPP-net\r\n\r\n1.R-CNN\r\nR-CNN系列论文(R-CNN,fast R-CNN,faster R-CNN,mask R-CNN)是深度学习进行目标检测的鼻祖论文，都是沿用了R-CNN的思路，我们本节内容来自《Rich feature hierarchies for accurate object detection and semantic segmentation》(2014 CVRR)的R-CNN的论文。\r\n\r\n其实在R-CNN之前，overfeat已经是用深度学习的方法在做目标检测(关于overfeat的相关学习资料，已经放在了我的Github的repo中),但是R-CNN是第一个可以真正以工业级应用的解决方案。(这也是我们为什么介绍R-CNN系列的主要原因),可以说改变了目标检测的主要研究思路，紧随其后的系列文章都沿用R-CNN。\r\n\r\n\r\n图1：CV中的主要问题:Classify,localization(单目标),detection(多目标)\r\n\r\n0.摘要：\r\n\r\n过去几年，在权威数据集PASCAL上，物体检测的效果已经达到一个稳定水平。效果最好的方法是融合了多种低维图像特征和高维上下文环境的复杂融合系统。在这篇论文里，我们提出了一种简单并且可扩展的检测算法，可以将mAP在VOC2012最好结果的基础上提高30%以上——达到了53.3%。我们的方法结合了两个关键的因素：\r\n\r\n1.在候选区域上自下而上使用大型卷积神经网络(CNNs)，用以定位和分割物体。\r\n\r\n2.当带标签的训练数据不足时，先针对辅助任务进行有监督预训练，再进行特定任务的调优，就可以产生明显的性能提升。\r\n\r\n因为我们把region proposal（定位）和CNNs结合起来，所以该方法被称为R-CNN： Regions with CNN features。把R-CNN效果跟OverFeat比较了下（OverFeat是最近提出的在与我们相似的CNN特征下采用滑动窗口进行目标检测的一种方法，Overfeat:改进了AlexNet，并用图像缩放和滑窗方法在test数据集上测试网络；提出了一种图像定位的方法；最后通过一个卷积网络来同时进行分类，定位和检测三个计算机视觉任务，并在ILSVRC2013中获得了很好的结果。），结果发现RCNN在200类ILSVRC2013检测数据集上的性能明显优于OVerFeat。项目地址:https://github.com/rbgirshick/rcnn(MatLab)\r\n\r\n1.介绍\r\n\r\n特征很重要。在过去十年，各类视觉识别任务基本都建立在对SIFT[29]和HOG[7]特征的使用。但如果我们关注一下PASCAL VOC对象检测[15]这个经典的视觉识别任务，就会发现，2010-2012年进展缓慢，取得的微小进步都是通过构建一些集成系统和采用一些成功方法的变种才达到的。 【描述现状】\r\n\r\nSIFT和HOG是块方向直方图(blockwise orientation histograms)，两篇论文已经更新在Github的repo中，一种类似大脑初级皮层V1层复杂细胞的表示方法。但我们知道识别发生在多个下游阶段，（我们是先看到了一些特征，然后才意识到这是什么东西）也就是说对于视觉识别来说，更有价值的信息，是层次化的，多个阶段的特征。 【关于SIFT&HOG】\r\n\r\n\"神经认知机\",一种受生物学启发用于模式识别的层次化、移动不变性模型，算是这方面最早的尝试,但神经认知机缺乏监督学习算法。Lecun等人的工作表明基于反向传播的随机梯度下降(SGD)对训练卷积神经网络（CNNs）非常有效，CNNs被认为是继承自neocognitron的一类模型。 【神经认知机】\r\n\r\nCNNs在1990年代被广泛使用，但随即便因为SVM的崛起而淡出研究主流。2012年，Krizhevsky等人在ImageNet大规模视觉识别挑战赛(ILSVRC)上的出色表现重新燃起了世界对CNNs的兴趣（AlexNet）。他们的成功在于在120万的标签图像上使用了一个大型的CNN，并且对LeCUN的CNN进行了一些改造（比如ReLU和Dropout Regularization）。 【CNN的崛起】\r\n\r\n这个ImangeNet的结果的重要性在ILSVRC2012 workshop上得到了热烈的讨论。提炼出来的核心问题是：ImageNet上的CNN分类结果在何种程度上能够应用到PASCAL VOC挑战的物体检测任务上？【CNN何时使用到目标检测】\r\n\r\n我们通过连接图像分类和目标检测，回答了这个问题。本论文是第一个说明在PASCAL VOC的物体检测任务上CNN比基于简单类HOG特征的系统有大幅的性能提升。我们主要关注了两个问题：使用深度网络定位物体和在小规模的标注数据集上进行大型网络模型的训练。 【R-CNN解决的问题】\r\n\r\n与图像分类不同的是检测需要定位一个图像内的许多物体。一个方法是将框定位看做是回归问题。但Szegedy等人的工作说明这种策略并不work（在VOC2007上他们的mAP是30.5%，而我们的达到了58.5%）。【将定位问题单纯作为回归解决效果并不好】\r\n\r\n另一个可替代的方法是使用【滑动窗口探测器】，通过这种方法使用CNNs至少已经有20年的时间了，通常用于一些特定的种类如人脸，行人等。为了获得较高的空间分辨率，这些CNNs都采用了两个卷积层和两个池化层。我们本来也考虑过使用滑动窗口的方法，但是由于网络层次更深，输入图片有非常大的感受野（195×195）and 步长（32×32），这使得采用滑动窗口的方法充满挑战。【感受野大，滑动窗口出来的边界不准确】\r\n\r\n我们是通过操作”recognition using regions”[21]范式，解决了CNN的定位问题。\r\n\r\n测试时，对这每张图片，产生了接近2000个与类别无关的region proposal,\r\n对每个CNN抽取了一个固定长度的特征向量，\r\n然后借助专门针对特定类别数据的线性SVM对每个区域进行分类。\r\n我们不考虑region的大小，使用放射图像变形的方法来对每个不同形状的region proposal产生一个固定长度的作为CNN输入的特征向量（也就是把不同大小的proposal放到同一个大小）。图2展示了我们方法的全貌并突出展示了一些实验结果。由于我们结合了Region proposals[21]和CNNs，所以起名R-CNN：Regions with CNN features。【R-CNN的由来】\r\n\r\n\r\n图2：R-CNN目标检测系统过程. （1）获取一张输入图片，（2）产生2000个与类别无关的region proposal，（3）用大型的卷积计算备选区域的特征，（4）使用线性SVM对每一个定位进行分类\r\n\r\n检测中面对的第二个挑战是标签数据太少，现在可获得的数据远远不够用来训练一个大型卷积网络。传统方法多是采用无监督与训练，再进行有监督调优。本文的第二个核心贡献是在辅助数据集（ILSVRC）上进行有监督预训练，再在小数据集上针对特定问题进行调优。这是在训练数据稀少的情况下一个非常有效的训练大型卷积神经网络的方法。我们的实验中，针对检测的调优将mAP提高了8个百分点。调优后，我们的系统在VOC2010上达到了54%的mAP，远远超过高度优化的基于HOG的可变性部件模型（deformable part model，DPM） 【DPM:多尺度形变部件模型，连续获得07-09的检测冠军，2010年其作者Felzenszwalb Pedro被VOC授予”终身成就奖”。DPM把物体看成了多个组成的部件（比如人脸的鼻子、嘴巴等），用部件间的关系来描述物体，这个特性非常符合自然界很多物体的非刚体特征。DPM可以看做是HOG+SVM的扩展，很好的继承了两者的优点，在人脸检测、行人检测等任务上取得了不错的效果，但是DPM相对复杂，检测速度也较慢，从而也出现了很多改进的方法。】【挑战2及解决办法】\r\n\r\nR-CNN计算高效： 原因都是小型矩阵的乘积，特征在不同类别间共享；HOG-like特征的一个优点是简单性：能够很容易明白提取到的特征是什么（可视化出来）。介绍技术细节之前，我们提醒大家由于R-CNN是在推荐区域上进行操作，所以可以很自然地扩展到语义分割任务上。只要很小的改动，我们就在PASCAL VOC语义分割任务上达到了很有竞争力的结果，在VOC2011测试集上平均语义分割精度达到了47.9%。【R-CNN的其他应用】\r\n\r\n2.用R-CNN做目标检测\r\n\r\n我们的物体检测系统有三个模块构成。\r\n\r\n第一个，产生类别无关的region proposal。这些推荐定义了一个候选检测区域的集合；\r\n第二个是一个大型卷积神经网络，用于从每个区域抽取特定大小的特征向量；\r\n第三个是一个指定类别的线性SVM。\r\n本部分，将展示每个模块的设计，并介绍他们的测试阶段的用法，以及参数是如何学习的细节，最后给出在PASCAL VOC 2010-12和ILSVRC2013上的检测结果。\r\n\r\n2.1模块设计\r\n\r\n【region proposal：区域推荐】 近来有很多研究都提出了产生类别无关区域推荐的方法比如: objectness（物体性）[1]，selective search（选择性搜索）[39]，category-independent object proposals(类别无关物体推荐)[14]，constrained parametric min-cuts（受限参最小剪切, CPMC)[5]，multi-scal combinatorial grouping(多尺度联合分组)[3]，以及Ciresan[6]等人的方法,将CNN用在规律空间块裁剪上以检测有丝分裂细胞，也算是一种特殊的区域推荐类型。由于R-CNN对特定区域推荐算法是不关心的，所以我们采用了选择性搜索[39]以方便和前面的工作进行可控的比较。[region proposal方法，建议自行学习]\r\n\r\n【Feature extraction: 特征提取】我们使用Krizhevsky等人所描述的CNN的一个Caffe实现版本[24]对每个推荐区域抽取一个4096维度的特征向量把一个输入为277277大小的图片，通过五个卷积层和两个全连接层进行前向传播,最终得到一个4096-D的特征向量。读者可以参考AlexNet获得更多的网络架构细节。为了计算region proposal的特征，我们首先要对图像进行转换，使得它符合CNNC的输入（架构中的CNN只能接受固定大小：277277）这个变换有很多办法，我们使用了最简单的一种。无论候选区域是什么尺寸和宽高比，我们都把候选框变形成想要的尺寸,。具体的，变形之前，我们先在候选框周围加上16的padding,再进行各向异性缩放。这种形变使得mAp提高了3到5个百分点。在补充材料中，作者对比了各向异性和各向同性缩放缩放方法。\r\n\r\n2.2测试阶段的物体检测\r\n\r\n测试阶段，在测试图像上使用selective search抽取2000个推荐区域（实验中，我们使用了选择性搜索的快速模式）（关于selective search我们在下文中会详细讲解）然后变形每一个推荐区域，再通过CNN前向传播计算出特征。然后我们使用对每个类别训练出的SVM给整个特征向量中的每个类别单独打分。【对每一个框使用每个类别的SVM进行打分】然后给出一张图像中所有的打分区域，然后使用NMS【贪婪非最大化抑制算法】（每个类别是独立进行的），拒绝掉一些和高分区域的IOU大于阈值的候选框。\r\n\r\n【运行时间的分析】两个特性让检测变得很高效。首先，所有的CNN参数都是跨类别共享的。（参数共享）其次，通过CNN计算的特征向量相比其他通用方法（比如spatial pyramids with bag-of-visual-word encodings）维度是很低的。（低维特征）这种共享的结果就是计算推荐区域特征的耗时可以分摊到所有类别的头上（GPU：每张图13s，CPU：每张图53s）。\r\n\r\n唯一的和具体类别有关的计算是特征向量和SVM权重和点积，以及NMS实践中，所有的点积都可以批量化成一个单独矩阵间运算。特征矩阵的典型大小是2000×4096，SVM权重的矩阵是4096xN，其中N是类别的数量。\r\n\r\n分析表明R-CNN可以扩展到上千个类别，而不需要借用近似技术（如hashing）。及时有10万个类别，矩阵乘法在现代多核CPU上只需要10s而已。但这种高效不仅仅是因为使用了区域推荐和共享特征。\r\n\r\n2.3训练\r\n\r\n【**有监督的预训练 **】我们在大型辅助训练集ILSVRC2012分类数据集（没有约束框数据）上预训练了CNN。预训练采用了Caffe的CNN库。总体来说，我们的CNN十分接近krizhevsky等人的网络的性能，在ILSVRC2012分类验证集在top-1错误率上比他们高2.2%。差异主要来自于训练过程的简化。\r\n\r\n【**特定领域的参数调优 **】为了让我们的CNN适应新的任务（即检测任务）和新的领域（变形后的推荐窗口）。我们只使用变形后的推荐区域对CNN参数进行SGD训练。我们替换掉了ImageNet专用的1000-way分类层，换成了一个随机初始化的21-way分类层，（其中20是VOC的类别数，1代表背景）而卷积部分都没有改变，我们对待所有的推荐区域，如果其和真实标注的框的IoU>= 0.5就认为是正例，否则就是负例，SGD开始的learning_rate为0.001（是初始化预训练时的十分之一），这使得调优得以有效进行而不会破坏初始化的成果。每轮SGD迭代，我们统一使用32个正例窗口（跨所有类别）和96个背景窗口，即每个mini-batch的大小是128。另外我们倾向于采样正例窗口，因为和背景相比他们很稀少。\r\n\r\n【目标种类分类器】思考一下检测汽车的二分类器。很显然，一个图像区域紧紧包裹着一辆汽车应该就是正例。同样的，没有汽车的就是背景区域，也就是负例。较为不明确的是怎样标注哪些只和汽车部分重叠的区域。我们使用IoU重叠阈值来解决这个问题，低于这个阈值的就是负例。这个阈值我们选择了0.3，是在验证集上基于{0, 0.1, … 0.5}通过网格搜索得到的。我们发现认真选择这个阈值很重要。如果设置为0.5，可以提升mAP5个点，设置为0，就会降低4个点。正例就严格的是标注的框\r\n\r\n一旦特征提取出来，并应用标签数据，我们优化了每个类的线性SVM。由于训练数据太大，难以装进内存，我们选择了标准的hard negative mining method【难负例挖掘算法，用途就是负例数据不平衡，而负例分赛代表性又不够的问题，hard negative就是每次把那些顽固的棘手的错误，在送回去训练，训练到你的成绩不在提升为止，这个过程叫做hard negative mining】\r\n\r\n高难负例挖掘算法收敛很快，实践中只要在所有图像上经过一轮训练，mAP就可以基本停止增加了。 附录B中，讨论了，为什么在fine-tunning和SVM训练这两个阶段，我们定义得正负样例是不同的。【fine-tunning阶段是由于CNN对小样本容易过拟合，需要大量训练数据，故对IoU限制宽松： IoU>0.5的建议框为正样本，否则为负样本； SVM这种机制是由于其适用于小样本训练，故对样本IoU限制严格：Ground Truth为正样本，与Ground Truth相交IoU＜0.3的建议框为负样本。】\r\n\r\n我们也会讨论为什么训练一个分类器是必要的，而不只是简单地使用来自调优后的CNN的最终fc8层的输出。【为什么单独训练了一个SVM而不是直接用softmax，作者提到，刚开始时只是用了ImageNet预训练了CNN，并用提取的特征训练了SVMs，此时用正负样本标记方法就是前面所述的0.3,后来刚开始使用fine-tuning时，也使用了这个方法，但是发现结果很差，于是通过调试选择了0.5这个方法，作者认为这样可以加大样本的数量，从而避免过拟合。然而，IoU大于0.5就作为正样本会导致网络定位准确度的下降，故使用了SVM来做检测，全部使用ground-truth样本作为正样本，且使用非正样本的，且IoU大于0.3的“hard negatives”，提高了定位的准确度】\r\n\r\n2.4在PASCAL VOC 2010-12上的结果\r\n\r\n在数据集： PASCAL 2010-12:\r\n\r\n\r\n原paper的Table1\r\n\r\n在数据集ILSVR2013数据集上得到了相似的结果\r\n\r\n3.可视化、消融、模型的错误\r\n\r\n3.1可视化学习到的特征（如何展示CNN每层学到的东西，了解）\r\n\r\n直接可视化第一层filters非常容易理解，它们主要捕获方向性边缘和对比色。难以理解的是后面的层。Zeiler and Fergus提出了一种可视化的很棒的反卷积办法。我们则使用了一种简单的非参数化方法，直接展示网络学到的东西。这个想法是单一输出网络中一个特定单元（特征），然后把它当做一个正确类别的物体检测器来使用。 方法是这样的，先计算所有抽取出来的推荐区域（大约1000万），计算每个区域所导致的对应单元的激活值，然后按激活值对这些区域进行排序，然后进行最大值抑制，最后展示分值最高的若干个区域。这个方法让被选中的单元在遇到他想激活的输入时“自己说话”。我们避免平均化是为了看到不同的视觉模式和深入观察单元计算出来的不变性。 我们可视化了第五层的池化层pool5，是卷积网络的最后一层，feature_map(卷积核和特征数的总称)的大小是6 x 6 x 256 = 9216维。忽略边界效应，每个pool5单元拥有195×195的感受野，输入是227×227。pool5中间的单元，几乎是一个全局视角，而边缘的单元有较小的带裁切的支持。 图4的每一行显示了对于一个pool5单元的最高16个激活区域情况，这个实例来自于VOC 2007上我们调优的CNN，这里只展示了256个单元中的6个（附录D包含更多）。我们看看这些单元都学到了什么。第二行，有一个单元看到狗和斑点的时候就会激活，第三行对应红斑点，还有人脸，当然还有一些抽象的模式，比如文字和带窗户的三角结构。这个网络似乎学到了一些类别调优相关的特征，这些特征都是形状、纹理、颜色和材质特性的分布式表示。而后续的fc6层则对这些丰富的特征建立大量的组合来表达各种不同的事物。\r\n\r\n3.2消融研究(Ablation studies)\r\n\r\nablation study 就是为了研究模型中所提出的一些结构是否有效而设计的实验。如你提出了某某结构，但是要想确定这个结构是否有利于最终的效果，那就要将去掉该结构的网络与加上该结构的网络所得到的结果进行对比，这就是ablation study。也就是（控制变量法）\r\n\r\n【没有调优的各层性能】\r\n\r\n为了理解哪一层对于检测的性能十分重要，我们分析了CNN最后三层的每一层在VOC2007上面的结果。Pool5在3.1中做过剪短的表述。最后两层下面来总结一下。\r\n\r\nfc6是一个与pool5连接的全连接层。为了计算特征，它和pool5的feature map（reshape成一个9216维度的向量）做了一个4096×9216的矩阵乘法，并添加了一个bias向量。中间的向量是逐个组件的半波整流（component-wise half-wave rectified）【Relu（x<- max(0,x)）】\r\n\r\nfc7是网络的最后一层。跟fc6之间通过一个4096×4096的矩阵相乘。也是添加了bias向量和应用了ReLU。\r\n\r\n我们先来看看没有调优的CNN在PASCAL上的表现，没有调优是指所有的CNN参数就是在ILSVRC2012上训练后的状态。分析每一层的性能显示来自fc7的特征泛化能力不如fc6的特征。这意味29%的CNN参数，也就是1680万的参数可以移除掉，而且不影响mAP。更多的惊喜是即使同时移除fc6和fc7，仅仅使用pool5的特征，只使用CNN参数的6%也能有非常好的结果。可见CNN的主要表达力来自于卷积层，而不是全连接层。这个发现提醒我们也许可以在计算一个任意尺寸的图片的稠密特征图（dense feature map）时使仅仅使用CNN的卷积层。这种表示可以直接在pool5的特征上进行滑动窗口检测的实验。\r\n\r\n【调优后的各层性能】\r\n\r\n我们来看看调优后在VOC2007上的结果表现。提升非常明显，mAP提升了8个百分点，达到了54.2%。fc6和fc7的提升明显优于pool5，这说明pool5从ImageNet学习的特征通用性很强，在它之上层的大部分提升主要是在学习领域相关的非线性分类器。\r\n\r\n【对比其他特征学习方法】\r\n\r\nR-CNN是最好的，我们的mAP要多大约20个百分点，61%的相对提升。\r\n\r\n3.3网络结构 3.4 检测错误分析\r\n\r\n两个直接省略！！！\r\n\r\n3.5Bounding-box回归\r\n\r\n基于错误分析，我们使用了一种简单的方法减小定位误差。受到DPM[17]中使用的约束框回归训练启发，我们训练了一个线性回归模型在给定一个选择区域的pool5特征时去预测一个新的检测窗口。详细的细节参考附录C。表1、表2和图4的结果说明这个简单的方法，修复了大量的错位检测，提升了3-4个百分点。\r\n\r\n关于BoundingBox-Regression参考下文\r\n\r\n4.结论\r\n\r\n最近几年，物体检测陷入停滞，表现最好的检测系统是复杂的将多低层级的图像特征与高层级的物体检测器环境与场景识别相结合。本文提出了一种简单并且可扩展的物体检测方法，达到了VOC 2012数据集相对之前最好性能的30%的提升。 我们取得这个性能主要通过两个方面：第一是应用了自底向上的候选框训练的高容量的卷积神经网络进行定位和分割物体。另外一个是使用在标签数据匮乏的情况下训练大规模神经网络的一个方法。我们展示了在有监督的情况下使用丰富的数据集（图片分类）预训练一个网络作为辅助性的工作是很有效的，然后采用稀少数据（检测）去调优定位任务的网络。我们猜测“有监督的预训练+特定领域的调优”这一范式对于数据稀少的视觉问题是很有效的。 最后,我们注意到能得到这些结果，将计算机视觉中经典的工具和深度学习(自底向上的区域候选框和卷积神经网络）组合是非常重要的。而不是违背科学探索的主线，这两个部分是自然而且必然的结合。\r\n\r\n2.PASCAL & ILSVRC\r\nPattern Analysis, Statical Modeling and Computational Learning Visual Object Classes\r\n\r\n[主页]http://host.robots.ox.ac.uk/pascal/VOC/\r\n\r\nProvides standardised image data sets for object class recognition\r\nProvides a common set of tools for accessing the data sets and annotations\r\nEnables evaluation and comparison of different methods\r\nRan challenges evaluating performance on object class recognition (from 2005-2012, now finished)\r\n提供了2005-2012年的数据集，数据集的[参考格式]https://www.cnblogs.com/whlook/p/7220105.html\r\n\r\n\r\nLarge Scale Visual Recognition Challenge (ILSVRC)\r\nStanford Vison Lab\r\n\r\nImageNet比赛\r\n\r\n[主页]http://www.image-net.org/challenges/LSVRC/\r\n\r\nThe ImageNet Large Scale Visual Recognition Challenge (ILSVRC) evaluates algorithms for object detection and image classification at large scale. One high level motivation is to allow researchers to compare progress in detection across a wider variety of objects -- taking advantage of the quite expensive labeling effort. Another motivation is to measure the progress of computer vision for large scale image indexing for retrieval and annotation.\r\n\r\n3. 目标检测中用到的一些评价指标\r\n模型的好坏是相对的，什么样的模型好不仅取决于数据和算法，还取决于任务需求，因此选取一个合理的模型评价指标非常有必要。\r\n\r\nIOU\r\nIOU是由预测的包围盒与地面真相包围盒的重叠区域（交集），除以他们之间的联合区域（并集），gt代表针织框\r\n\r\n\r\n\r\nPrecision，Recall,......\r\n一般模型常用的错误率(Error)和精度(accuracy)就能解决(一般的机器学习任务),精度和错误率虽然常用，但不能满足所有需求\r\n\r\n\r\n\r\n其他常用的： ROC（AUC为ROC曲线下的面积)，P-R曲线，lift曲线，若当值，K-S值（二分类用的多一些），混淆矩阵，F1(F-score, F-Measure $\\aplpha=1$ )\r\n\r\n基于自己的学习任务，同时也可以修改(比如加一些惩罚)或自定义其他的评价指标。\r\n\r\nAP & mAP\r\nP: precision\r\n\r\nAP: average precision,每一类别P值的平均值\r\n\r\nmAP: mean average precision,对所有类别的AP取平均\r\n\r\n目标检测中的模型的分类和定位都需要进行评估，每个图像都可能具有不同类别的不同目标。\r\n\r\n** 计算mAP的过程**\r\n\r\n[Ground Truth的定义] 对于任何算法，度量总是与数据的真实值(Ground Truth)进行比较。我们只知道训练、验证和测试数据集的Ground Truth信息。对于物体检测问题，Ground Truth包括图像，图像中的目标的类别以及图像中每个目标的边界框。\r\n\r\n下图给出了一个真实的图像(JPG/PNG)和其他标注信息作为文本(边界框坐标(X, Y, 宽度和高度)和类)，其中上图的红色框和文本标签仅仅是为了更好的理解，手工标注可视化显示。\r\n\r\n\r\n标注图像：Ground Truth\r\n\r\n对于上面的例子，我们在模型在训练中得到了下图所示的目标边界框和3组数字定义的ground truth(假设这个图像是1000*800px，所有这些坐标都是构建在像素层面上的)\r\n\r\n\r\n模型需要预测的：关于详细的一些模型预测label的设定建议学习吴恩达的deeplearning.ai关于卷积网络学习的网课\r\n\r\n开始计算mAP的步骤：\r\n\r\n1.假设原始图像和真实的标注信息(ground truth)如上所示，训练和验证数据以相同的方式都进行了标注。该模型将返回大量的预测，但是在这些模型中，大多数都具有非常低的置信度分数，因此我们只考虑高于某个置信度分数的预测信息。我们通过我们的模型运行原始图像，在置信阈值确定之后，下面是目标检测算法返回的带有边框的图像区域(bounding boxes)。\r\n\r\n预测结果\r\n\r\n但是怎样在实际中量化这些检测区域的正确性呢？ 首先我们需要知道每个检测的正确性。测量一个给定的边框的正确性的度量标准是loU-交幷比(检测评价函数)，这是一个非常简单的视觉量。 下面给出loU的简单的解释。(我们在第一部分已经给出定义)\r\n\r\n2.IoU计算\r\nloU(交并比)是模型所预测的检测框和真实(ground truth)的检测框的交集和并集之间的比例。这个数据也被称为Jaccard指数。为了得到交集和并集值，我们首先将预测框叠加在ground truth实际框上面，如下图所示：\r\n\r\n\r\n现在对于每个类，预测框和真实框重叠的区域就是交集区域，预测框和真实框的总面积区域就是并集框。 在上面的目标马的交集和联合看起来是这样的：\r\n\r\n\r\n交集包括重叠区域(青色区域), 并集包括橙色和青色区域\r\n\r\n3.识别正确的检测和计算精度\r\n我们使用loU看检测是否正确需要设定一个阈值，最常用的阈值是0.5，即如果loU>0.5，则认为是真实的检测(true detection)，否则认为是错误的检测(false detection)。我们现在计算模型得到的每个检测框的loU值。用计算出的loU值与设定的loU阈值(例如0.5)比较，就可以计算出每个图像中每个类的正确检测次数(A)。对于每个图像，我们都有ground truth的数据(即知道每个图像的真实目标信息),因此也知道了该图像中给定类别的实际目标(B)的数量。因此我们可以使用这个公式来计算该类模型的精度(A/B)\r\n\r\n\r\n即给定一张图像的类别C的Precision=图像正确预测(True Positives)的数量除以在该图像上这一类的总的目标数量。\r\n\r\n假如现在有一个给定的类，验证集中有100个图像，并且我们知道每个图像都有其中的所有类(基于ground truth)。所以我们可以得到100个精度值，计算这100个精度值的平均值，得到的就是该类的平均精度。\r\n\r\n\r\n即一个C类的平均精度=在验证集上所有的图像对于类C的精度值的和/有类C这个目标的所有图像的数量。\r\n\r\n4.计算最终mAP\r\n现在假如我们整个集合中有20个类，对于每个类别，我们都先计算loU，接下来计算精度,然后计算平均精度。所有我们现在有20个不同的平均精度值。使用这些平均精度值，我们可以轻松的判断任何给定类别的模型的性能。\r\n\r\n但是问题是使用20个不同的平均精度使我们难以度量整个模型，所以我们可以选用一个单一的数字来表示一个模型的表现(一个度量来统一它们),我们可以取所有类的平均精度值的平均值，即mAP(均值平均精度)。\r\n\r\n\r\nMAP=所有类别的平均精度求和除以所有类别\r\n\r\n使用MAP值时我们需要满足一下条件： (1) MAP总是在固定的数据集上计算 (2)它不是量化模型输出的绝对度量，但是是一个比较好的相对度量。当我们在流行的公共数据集上计算这个度量时，这个度量可以很容易的用来比较不同目标检测方法 (3)根据训练中类的分布情况，平均精度值可能会因为某些类别(具有良好的训练数据)非常高(对于具有较少或较差数据的类别)而言非常低。所以我们需要mAP可能是适中的，但是模型可能对于某些类非常好，对于某些类非常不好。因此建议在分析模型结果的同时查看个各类的平均精度(AP)，这些值也可以作为我们是不是需要添加更多训练样本的一个依据。\r\n\r\n4.各向异性，各向同性缩放\r\nR-CNN的论文中提到了各向同性，各向异性缩放的概念，这里做一个详细解释：\r\n\r\n当我们输入一张图片时，我们要搜索出所有可能是物体的区域，R-CNN采用的就是Selective Search方法，通过这个算法我们搜索出2000个候选框。然后从R-CNN的总流程图中可以看到，搜出的候选框是矩形的，而且是大小各不相同。然而CNN对输入图片的大小是有固定的，如果把搜索到的矩形选框不做处理，就扔进CNN中，肯定不行。因此对于每个输入的候选框都需要缩放到固定的大小。\r\n\r\n下面我们讲解要怎么进行缩放处理，为了简单起见我们假设下一阶段CNN所需要的输入图片大小是个正方形图片227*227。因为我们经过selective search 得到的是矩形框，paper试验了两种不同的处理方法：\r\n\r\n各向异性缩放： 这种方法很简单，就是不管图片的长宽比例，管它是否扭曲，进行缩放就是了，全部缩放到CNN输入的大小227*227，如下图(D)所示；\r\n\r\n各向同性缩放： 因为图片扭曲后，估计会对后续CNN的训练精度有影响，于是作者也测试了“各向同性缩放”方案。有两种办法：\r\n\r\n先扩充后裁剪\r\n直接在原始图片中，把bounding box的边界进行扩展延伸成正方形，然后再进行裁剪；如果已经延伸到了原始图片的外边界，那么就用bounding box中的颜色均值填充；如下图(B)所示;\r\n\r\n先裁剪后扩充\r\n先把bounding box图片裁剪出来，然后用固定的背景颜色填充成正方形图片(背景颜色也是采用bounding box的像素颜色均值),如下图(C)所示;\r\n\r\n对于上面的异性、同性缩放，文献还有个padding处理，上面的示意图中第1、3行就是结合了padding=0, 第2、4行结果图采用padding=16的结果。经过最后的试验，作者发现采用各向异性缩放、padding=16的精度最高。（也就是最后一个图）\r\n\r\n\r\n5.NMS:非极大值抑制\r\n先假设有n个（假设有6个）候选框，根据分类器类别分类概率做排序，从小到大分别属于车辆的概率分别为A<=B<=C<=D<=E<=F。\r\n\r\n（1）从最大概率的矩形框开始（F），分别判断A-E与F的IOU是否大于某个设定的阈值\r\n\r\n（2）假设B,D与F的IOU超过F,那就扔掉B,D，并标记第一个矩形框F,是我们保留下来的\r\n\r\n（3）从剩余矩形框A,C.E中选择概率最大的E，然后判断E与A,C的IOU(重叠度），重叠度大于一定的阈值，那么就扔掉，标记E是我们保留下来的第2个矩形框\r\n\r\n（4）一直重复这个过程，找到所有被曾经保留下来的矩形框。\r\n\r\n为什么需要NMS?\r\n\r\n在测试过程完成到第4步之后[section7中的步骤]，获得2000×20维矩阵表示每个建议框是某个物体类别的得分情况，此时会遇到下图所示情况，同一个车辆目标会被多个建议框包围，这时需要非极大值抑制操作去除得分较低的候选框以减少重叠框。\r\n\r\n\r\n6.边框回归：BoundingBox-Regression(BBR)\r\n首先考虑R-CNN中为什么要做BBR?\r\n\r\nBounding Boxregression是 RCNN中使用的边框回归方法，在RCNN的论文中，作者指出：主要的错误是源于mislocalization。为了解决这个问题，作者使用了bounding box regression。这个方法使得mAp提高了3到4个点。\r\n\r\nBBR的输入 是什么？\r\n\r\n\r\n对于预测框P,我们有一个ground truth是G：当0.1< IoU < 0.5时出现重复，这种情况属于作者说的poor localiazation, 但注意：我们使用的并不是这样的框进行BBR(网上很多地方都在这里出现了误导),作者是用iou>0.6的进行BBR,也就是IOU<0.6的Bounding Box会直接被舍弃，不进行BBR。这样做是为了满足线性转换的条件。否则会导致训练的回归模型不 work.\r\n\r\n（当 P跟 G 离得较远，就是复杂的非线性问题了，此时用线性回归建模显然不合理。)\r\n\r\n至于为什么当IoU较大的时候，我们才认为是线性变化，我找到一个觉得解释的比较清楚的，截图在下面：\r\n\r\n\r\n线性回归就是给定输入的特征向量 X, 学习一组参数 W, 使得经过线性回归后的值跟真实值 Y(Ground Truth)非常接近. 即Y≈WX 。\r\n\r\n边框回归的目的既是：给定(Px,Py,Pw,Ph)寻找一种映射f， 使得f(Px,Py,Pw,Ph)=(Gx^,Gy^,Gw^,Gh^)并且(Gx^,Gy^,Gw^,Gh^)≈(Gx,Gy,Gw,Gh)\r\n\r\n例如上图：我们现在要讲P框进行BBR,gt为G框，那么我们希望经过变换之后，P框能接近G框（比如，上图的G^框）。现在进行变换,过程如下：\r\n\r\n我们用一个四维向量（x,y,w,h）来表示一个窗口，其中x,y,w,h分别代表框的中心点的坐标以及宽，高。我们要从P得到G^，需要经过平移和缩放。\r\n\r\n\r\n其实这并不是真正的BBR，因为我们只是把P映射回G^,得到一个一般变换的式子，那为什么不映射回最优答案G呢？于是，P映射回G而不是G^，那我们就能得到最优变换（这才是最终的BBR）：\r\n\r\n\r\n这里为什么会将tw,th写成exp形式？\r\n\r\n是因为tw,th代表着缩放的尺寸，这个尺寸是>0的，所以使用exp的形式正好满足这种约束。 也就是，我们将转换d换成转换t,就得到了P到G的映射。 di -> ti。 现在我们只需要学习 这四个变换dx(P),dy(P),dw(P),dh(P)，然后最小化t和d之间的距离，最小化这个loss，即可。\r\n\r\n注意：此时看起来我们只要输入P的四维向量，就可以学习,然后求出，但是，其实我们输入的是pool5之后的features，记做φ5，因为如果只是单纯的靠坐标回归的话，CNN根本就没有发挥任何作用，但其实，BB的位置应该有CNN计算得到的features来fine-tune。所以，我们选择将pool5的feature作为输入。\r\n\r\n\r\nloss为：\r\n\r\n\r\n最后，我们只需要利用梯度下降或最小二乘求解w即可。 另外不要认为BBR和分类信息没有什么关系，是针对每一类都会训练一个BBR\r\n\r\n7.R-CNN测试的一般步骤\r\n1.输入一张多目标图像，采用selective search算法提取约2000个建议框；\r\n\r\n2.先在每个建议框周围加上16个像素值为建议框像素平均值的边框，再直接变形为227×227的大小；\r\n\r\n3.先将所有建议框像素减去该建议框像素平均值后【预处理操作】，再依次将每个227×227的建议框输入AlexNet CNN网络获取4096维的特征【比以前的人工经验特征低两个数量级】，2000个建议框的CNN特征组合成2000×4096维矩阵；\r\n\r\n4.将2000×4096维特征与20个SVM组成的权值矩阵4096×20相乘【20种分类，SVM是二分类器，则有20个SVM】，获得2000×20维矩阵表示每个建议框是某个物体类别的得分；\r\n\r\n5.分别对上述2000×20维矩阵中每一列即每一类进行非极大值抑制剔除重叠建议框，得到该列即该类中得分最高的一些建议框；\r\n\r\n6.分别用20个回归器对上述20个类别中剩余的建议框进行回归操作，最终得到每个类别的修正后的得分最高的bounding box。\r\n\r\n8.R-CNN的训练过程\r\n1.有监督预训练\r\n\r\nILSVRC样本集上仅有图像类别标签，没有图像物体位置标注； 采用AlexNet CNN网络进行有监督预训练，学习率=0.01； 该网络输入为227×227的ILSVRC训练集图像，输出最后一层为4096维特征->1000类的映射，训练的是网络参数。\r\n\r\n2.特定样本下的微调\r\n\r\nPASCAL VOC 2007样本集上既有图像中物体类别标签，也有图像中物体位置标签； 采用训练好的AlexNet CNN网络进行PASCAL VOC 2007样本集下的微调，学习率=0.001【0.01/10为了在学习新东西时不至于忘记之前的记忆】； mini-batch为32个正样本和96个负样本【由于正样本太少】； 该网络输入为建议框【由selective search而来】变形后的227×227的图像，修改了原来的1000为类别输出，改为21维【20类+背景】输出，训练的是网络参数。\r\n\r\n3.SVM训练\r\n\r\n由于SVM是二分类器，需要为每个类别训练单独的SVM； SVM训练时输入正负样本在AlexNet CNN网络计算下的4096维特征，输出为该类的得分，训练的是SVM权重向量； 由于负样本太多，采用hard negative mining的方法在负样本中选取有代表性的负样本，该方法具体见\r\n\r\n4.Bounding-box regression训练\r\n\r\n结果怎么样?\r\n\r\nPASCAL VOC 2010测试集上实现了53.7%的mAP；\r\n\r\nPASCAL VOC 2012测试集上实现了53.3%的mAP；\r\n\r\n计算Region Proposals和features平均所花时间：13s/image on a GPU；53s/image on a CPU\r\n\r\n还存在什么问题?\r\n\r\n很明显，最大的缺点是对一张图片的处理速度慢，这是由于一张图片中由selective search算法得出的约2k个建议框都需要经过变形处理后由CNN前向网络计算一次特征，这其中涵盖了对一张图片中多个重复区域的重复计算，很累赘；\r\n\r\n知乎上有人说R-CNN网络需要两次CNN前向计算，第一次得到建议框特征给SVM分类识别，第二次对非极大值抑制后的建议框再次进行CNN前向计算获得Pool5特征，以便对建议框进行回归得到更精确的bounding-box，这里文中并没有说是怎么做的，个人认为也可能在计算2k个建议框的CNN特征时，在硬盘上保留了2k个建议框的Pool5特征，虽然这样做只需要一次CNN前向网络运算，但是耗费大量磁盘空间；\r\n\r\n训练时间长，虽然文中没有明确指出具体训练时间，但由于采用RoI-centric sampling【从所有图片的所有建议框中均匀取样】进行训练，那么每次都需要计算不同图片中不同建议框CNN特征，无法共享同一张图的CNN特征，训练速度很慢；\r\n\r\n整个测试过程很复杂，要先提取建议框，之后提取每个建议框CNN特征，再用SVM分类，做非极大值抑制，最后做bounding-box回归才能得到图片中物体的种类以及位置信息；同样训练过程也很复杂，ILSVRC 2012上预训练CNN，PASCAL VOC 2007上微调CNN，做20类SVM分类器的训练和20类bounding-box回归器的训练；这些不连续过程必然涉及到特征存储、浪费磁盘空间等问题。\r\n\r\n9. HOG(Histogram of Oriented Gradient)\r\n方向梯度直方图特征是一种在计算机视觉和图像处理中用来进行物体检测的特征描述子。它通过计算和统计图像局部区域的梯度方向直方图来构成特征。Hog特征结合SVM分类器已经被广泛应用于图像识别中，尤其在行人检测中获得了极大的成功。需要提醒的是，HOG+SVM进行行人检测的方法是法国研究人员Dalal在2005的CVPR上提出的，而如今虽然有很多行人检测算法不断提出，但基本都是以HOG+SVM的思路为主。\r\n\r\n其思想是 在一副图像中，局部目标的表象和形状（appearance and shape）能够被梯度或边缘的方向密度分布很好地描述。（本质：梯度的统计信息，而梯度主要存在于边缘的地方）\r\n\r\n梯度的概念：\r\n\r\n在图像中梯度的概念也是像素值变换最快的方向，把边缘（在图像合成中单一物体的轮廓叫做边缘）引入进来，边缘与梯度保持垂直方向。\r\n\r\n\r\n具体在HOG中方向梯度的实现：首先用[-1,0,1]梯度算子对原图像做卷积运算，得到x方向（水平方向，以向右为正方向）的梯度分量gradscalx，然后用[1,0,-1]T梯度算子对原图像做卷积运算，得到y方向（竖直方向，以向上为正方向）的梯度分量gradscaly。然后再用以下公式计算该像素点的梯度大小和方向。\r\n\r\n\r\n直方图\r\n\r\n这个就不做解释了！！！\r\n\r\n方向梯度直方图HOG的提取\r\n\r\n方向梯度直方图为图像局部区域的梯度特征量统计，我们为什么要提取这个东东呢？\r\n\r\nHOG主要应用于行人检测方面，以行人照片为例。\r\n\r\n\r\n上图是一张行人图的四种表示方式，原三色图，灰度图，边缘图，梯度图，人脑根据前期学习与先验知识很容易理解到图像中包含着一个行人，并可以根据一定情况将其从图像中抠选出来，但计算机是怎么思考的呢？怎样让计算机理解以上图像中包含的是一个行人呢？前三个图像现在情况不适用，所以选取梯度图，现在的梯度图同样也是人脑处理理解的平面结果，计算机是办不到的，需要将直观地的梯度图像转换成一种计算机容易理解的数据特征语言。\r\n\r\n对于64X128的图像而言，每8X8的像素组成一个cell，每2X2个cell组成一个块(block)，以8个像素为步长，那么，水平方向将有7个扫描窗口，垂直方向将有15个扫描窗口。也就是说，64X128的图片，总共有36X7X15=3780个特征。这里截取梯度图的一部分画图进行理解，尺寸与比例并不精确。\r\n\r\n\r\n单独将其中一个8X8的小格拿出来，方向梯度中指的方向范围为2π，360°，为了画直方图我们还需要选取合适的组距也就是bin，这里组距选取2π/9，也就是最后的直方图组数为9。下图为8X8像素的cell对应的方向梯度（未全部画出，共有8X8=64个）。\r\n\r\n\r\n　将上面的64个方向梯度，按着直方图的参数设置进行画图，其中梯度的大小在统计数量中呈线性关系，比如梯度大小为2，则直方图对应增加2个单位， 画出的对应直方图假设如下所示：\r\n\r\n\r\n把上图中单个cell对应的方向直方图转换为单维向量，也就是按规定组距对对应方向梯度个数进行编码，（8,10,6,12,4,5,8,6,14），得到单个cell的9个特征，每个block（扫描窗口）包含2X2个cell也就是2X2X9=36个特征，一个64X128大小的图像最后得到的特征数为36X7X15=3780个。这样将一幅直观的梯度图通过分解提取变为计算机容易理解的特征向量。 　　以上工作为HOG提取的主要内容，最后得到对应的行人的由方向梯度直方图HOG提取到的特征向量，但是计算机还是不知道这个数据数组代表了什么意思，什么时候这组向量代表行人，什么时候代表其他东西，怎样train，最后通过不断地学习，而后在检测积累的基础上对对未知图像检测识别有没有行人呢？那就是后一步SVM要做的事了。\r\n\r\n\r\n10.LBP（Local Binary Pattern)\r\nLBP（Local Binary Pattern，局部二值模式）是一种用来描述图像局部纹理特征的算子；它具有旋转不变性和灰度不变性等显著的优点。它是首先由T. Ojala, M.Pietikäinen, 和D. Harwood 在1994年提出，用于纹理特征提取。而且，提取的特征是图像的局部的纹理特征；\r\n\r\nLBP特征的描述\r\n\r\n原始的LBP算子定义为在3X3的窗口内，以窗口中心像素为阈值，将相邻的8个像素的灰度值与其进行比较，若周围像素值大于中心像素值，则该像素点的位置被标记为1，否则为0。这样，3X3邻域内的8个点经比较可产生8位二进制数（通常转换为十进制数即LBP码，共256种），即得到该窗口中心像素点的LBP值，并用这个值来反映该区域的纹理信息。如下图所示：\r\n\r\n\r\nLBP的改进版本\r\n\r\n原始的LBP提出后，研究人员不断对其提出了各种改进和优化。\r\n\r\n（1）圆形LBP算子\r\n\r\n基本的 LBP算子的最大缺陷在于它只覆盖了一个固定半径范围内的小区域，这显然不能满足不同尺寸和频率纹理的需要。为了适应不同尺度的纹理特征，并达到灰度和旋转不变性的要求，Ojala等对 LBP 算子进行了改进，将 3×3邻域扩展到任意邻域，并用圆形邻域代替了正方形邻域，改进后的 LBP 算子允许在半径为 R 的圆形邻域内有任意多个像素点。从而得到了诸如半径为R的圆形区域内含有P个采样点的LBP算子；\r\n\r\n\r\n（2）LBP旋转不变模式\r\n\r\n从 LBP 的定义可以看出，LBP 算子是灰度不变的，但却不是旋转不变的。图像的旋转就会得到不同的 LBP值。\r\n\r\nMaenpaa等人又将 LBP算子进行了扩展，提出了具有旋转不变性的 LBP 算子，即不断旋转圆形邻域得到一系列初始定义的 LBP值，取其最小值作为该邻域的 LBP 值。\r\n\r\n下图 给出了求取旋转不变的 LBP 的过程示意图，图中算子下方的数字表示该算子对应的 LBP值，图中所示的 8 种 LBP模式，经过旋转不变的处理，最终得到的具有旋转不变性的 LBP值为 15。也就是说，图中的 8种 LBP 模式对应的旋转不变的 LBP模式都是00001111。\r\n\r\n\r\n一个LBP算子可以产生不同的二进制模式，对于半径为R的圆形区域内含有P个采样点的LBP算子将会产生P2种模式。很显然，随着邻域集内采样点数的增加，二进制模式的种类是急剧增加的。例如：5×5邻域内20个采样点，有220＝1,048,576种二进制模式。如此多的二值模式无论对于纹理的提取还是对于纹理的识别、分类及信息的存取都是不利的。同时，过多的模式种类对于纹理的表达是不利的。例如，将LBP算子用于纹理分类或人脸识别时，常采用LBP模式的统计直方图来表达图像的信息，而较多的模式种类将使得数据量过大，且直方图过于稀疏。因此，需要对原始的LBP模式进行降维，使得数据量减少的情况下能最好的代表图像的信息。\r\n\r\n为了解决二进制模式过多的问题，提高统计性，Ojala提出了采用一种“等价模式”（Uniform Pattern）来对LBP算子的模式种类进行降维。Ojala等认为，在实际图像中，绝大多数LBP模式最多只包含两次从1到0或从0到1的跳变。因此，Ojala将“等价模式”定义为：当某个LBP所对应的循环二进制数从0到1或从1到0最多有两次跳变时，该LBP所对应的二进制就称为一个等价模式类。如00000000（0次跳变），00000111（只含一次从0到1的跳变），10001111（先由1跳到0，再由0跳到1，共两次跳变）都是等价模式类。除等价模式类以外的模式都归为另一类，称为混合模式类，例如10010111（共四次跳变）\r\n\r\n通过这样的改进，二进制模式的种类大大减少，而不会丢失任何信息。模式数量由原来的2P种减少为 P ( P-1)+2种，其中P表示邻域集内的采样点数。对于3×3邻域内8个采样点来说，二进制模式由原始的256种减少为58种，这使得特征向量的维数更少，并且可以减少高频噪声带来的影响。\r\n\r\nLBP特征用于检测的原理\r\n\r\n显而易见的是，上述提取的LBP算子在每个像素点都可以得到一个LBP“编码”，那么，对一幅图像（记录的是每个像素点的灰度值）提取其原始的LBP算子之后，得到的原始LBP特征依然是“一幅图片”（记录的是每个像素点的LBP值）。\r\n\r\n\r\nLBP的应用中，如纹理分类、人脸分析等，一般都不将LBP图谱作为特征向量用于分类识别，而是采用LBP特征谱的统计直方图作为特征向量用于分类识别。\r\n\r\n因为，从上面的分析我们可以看出，这个“特征”跟位置信息是紧密相关的。直接对两幅图片提取这种“特征”，并进行判别分析的话，会因为“位置没有对准”而产生很大的误差。后来，研究人员发现，可以将一幅图片划分为若干的子区域，对每个子区域内的每个像素点都提取LBP特征，然后，在每个子区域内建立LBP特征的统计直方图。如此一来，每个子区域，就可以用一个统计直方图来进行描述；整个图片就由若干个统计直方图组成；\r\n\r\n例如：一幅100X100像素大小的图片，划分为10X10=100个子区域（可以通过多种方式来划分区域），每个子区域的大小为10X10像素；在每个子区域内的每个像素点，提取其LBP特征，然后，建立统计直方图；这样，这幅图片就有10X10个子区域，也就有了10X10个统计直方图，利用这10X10个统计直方图，就可以描述这幅图片了。之后，我们利用各种相似性度量函数，就可以判断两幅图像之间的相似性了；\r\n\r\n对LBP特征向量进行提取的步骤\r\n\r\n（1）首先将检测窗口划分为16×16的小区域（cell）；\r\n\r\n（2）对于每个cell中的一个像素，将相邻的8个像素的灰度值与其进行比较，若周围像素值大于中心像素值，则该像素点的位置被标记为1，否则为0。这样，3X3邻域内的8个点经比较可产生8位二进制数，即得到该窗口中心像素点的LBP值；\r\n\r\n（3）然后计算每个cell的直方图，即每个数字（假定是十进制数LBP值）出现的频率；然后对该直方图进行归一化处理。\r\n\r\n（4）最后将得到的每个cell的统计直方图进行连接成为一个特征向量，也就是整幅图的LBP纹理特征向量；\r\n\r\n然后便可利用SVM或者其他机器学习算法进行分类了。\r\n\r\nR-CNN系列 & SPP-net\r\n我们本部分的学习路线为:R-CNN, Selective Search, SPP-net\r\n\r\n1.R-CNN\r\nR-CNN系列论文(R-CNN,fast R-CNN,faster R-CNN,mask R-CNN)是深度学习进行目标检测的鼻祖论文，都是沿用了R-CNN的思路，我们本节内容来自《Rich feature hierarchies for accurate object detection and semantic segmentation》(2014 CVRR)的R-CNN的论文。\r\n\r\n其实在R-CNN之前，overfeat已经是用深度学习的方法在做目标检测(关于overfeat的相关学习资料，已经放在了我的Github的repo中),但是R-CNN是第一个可以真正以工业级应用的解决方案。(这也是我们为什么介绍R-CNN系列的主要原因),可以说改变了目标检测的主要研究思路，紧随其后的系列文章都沿用R-CNN。\r\n\r\n\r\n图1：CV中的主要问题:Classify,localization(单目标),detection(多目标)\r\n\r\n0.摘要：\r\n\r\n过去几年，在权威数据集PASCAL上，物体检测的效果已经达到一个稳定水平。效果最好的方法是融合了多种低维图像特征和高维上下文环境的复杂融合系统。在这篇论文里，我们提出了一种简单并且可扩展的检测算法，可以将mAP在VOC2012最好结果的基础上提高30%以上——达到了53.3%。我们的方法结合了两个关键的因素：\r\n\r\n1.在候选区域上自下而上使用大型卷积神经网络(CNNs)，用以定位和分割物体。\r\n\r\n2.当带标签的训练数据不足时，先针对辅助任务进行有监督预训练，再进行特定任务的调优，就可以产生明显的性能提升。\r\n\r\n因为我们把region proposal（定位）和CNNs结合起来，所以该方法被称为R-CNN： Regions with CNN features。把R-CNN效果跟OverFeat比较了下（OverFeat是最近提出的在与我们相似的CNN特征下采用滑动窗口进行目标检测的一种方法，Overfeat:改进了AlexNet，并用图像缩放和滑窗方法在test数据集上测试网络；提出了一种图像定位的方法；最后通过一个卷积网络来同时进行分类，定位和检测三个计算机视觉任务，并在ILSVRC2013中获得了很好的结果。），结果发现RCNN在200类ILSVRC2013检测数据集上的性能明显优于OVerFeat。项目地址:https://github.com/rbgirshick/rcnn(MatLab)\r\n\r\n1.介绍\r\n\r\n特征很重要。在过去十年，各类视觉识别任务基本都建立在对SIFT[29]和HOG[7]特征的使用。但如果我们关注一下PASCAL VOC对象检测[15]这个经典的视觉识别任务，就会发现，2010-2012年进展缓慢，取得的微小进步都是通过构建一些集成系统和采用一些成功方法的变种才达到的。 【描述现状】\r\n\r\nSIFT和HOG是块方向直方图(blockwise orientation histograms)，两篇论文已经更新在Github的repo中，一种类似大脑初级皮层V1层复杂细胞的表示方法。但我们知道识别发生在多个下游阶段，（我们是先看到了一些特征，然后才意识到这是什么东西）也就是说对于视觉识别来说，更有价值的信息，是层次化的，多个阶段的特征。 【关于SIFT&HOG】\r\n\r\n\"神经认知机\",一种受生物学启发用于模式识别的层次化、移动不变性模型，算是这方面最早的尝试,但神经认知机缺乏监督学习算法。Lecun等人的工作表明基于反向传播的随机梯度下降(SGD)对训练卷积神经网络（CNNs）非常有效，CNNs被认为是继承自neocognitron的一类模型。 【神经认知机】\r\n\r\nCNNs在1990年代被广泛使用，但随即便因为SVM的崛起而淡出研究主流。2012年，Krizhevsky等人在ImageNet大规模视觉识别挑战赛(ILSVRC)上的出色表现重新燃起了世界对CNNs的兴趣（AlexNet）。他们的成功在于在120万的标签图像上使用了一个大型的CNN，并且对LeCUN的CNN进行了一些改造（比如ReLU和Dropout Regularization）。 【CNN的崛起】\r\n\r\n这个ImangeNet的结果的重要性在ILSVRC2012 workshop上得到了热烈的讨论。提炼出来的核心问题是：ImageNet上的CNN分类结果在何种程度上能够应用到PASCAL VOC挑战的物体检测任务上？【CNN何时使用到目标检测】\r\n\r\n我们通过连接图像分类和目标检测，回答了这个问题。本论文是第一个说明在PASCAL VOC的物体检测任务上CNN比基于简单类HOG特征的系统有大幅的性能提升。我们主要关注了两个问题：使用深度网络定位物体和在小规模的标注数据集上进行大型网络模型的训练。 【R-CNN解决的问题】\r\n\r\n与图像分类不同的是检测需要定位一个图像内的许多物体。一个方法是将框定位看做是回归问题。但Szegedy等人的工作说明这种策略并不work（在VOC2007上他们的mAP是30.5%，而我们的达到了58.5%）。【将定位问题单纯作为回归解决效果并不好】\r\n\r\n另一个可替代的方法是使用【滑动窗口探测器】，通过这种方法使用CNNs至少已经有20年的时间了，通常用于一些特定的种类如人脸，行人等。为了获得较高的空间分辨率，这些CNNs都采用了两个卷积层和两个池化层。我们本来也考虑过使用滑动窗口的方法，但是由于网络层次更深，输入图片有非常大的感受野（195×195）and 步长（32×32），这使得采用滑动窗口的方法充满挑战。【感受野大，滑动窗口出来的边界不准确】\r\n\r\n我们是通过操作”recognition using regions”[21]范式，解决了CNN的定位问题。\r\n\r\n测试时，对这每张图片，产生了接近2000个与类别无关的region proposal,\r\n对每个CNN抽取了一个固定长度的特征向量，\r\n然后借助专门针对特定类别数据的线性SVM对每个区域进行分类。\r\n我们不考虑region的大小，使用放射图像变形的方法来对每个不同形状的region proposal产生一个固定长度的作为CNN输入的特征向量（也就是把不同大小的proposal放到同一个大小）。图2展示了我们方法的全貌并突出展示了一些实验结果。由于我们结合了Region proposals[21]和CNNs，所以起名R-CNN：Regions with CNN features。【R-CNN的由来】\r\n\r\n\r\n图2：R-CNN目标检测系统过程. （1）获取一张输入图片，（2）产生2000个与类别无关的region proposal，（3）用大型的卷积计算备选区域的特征，（4）使用线性SVM对每一个定位进行分类\r\n\r\n检测中面对的第二个挑战是标签数据太少，现在可获得的数据远远不够用来训练一个大型卷积网络。传统方法多是采用无监督与训练，再进行有监督调优。本文的第二个核心贡献是在辅助数据集（ILSVRC）上进行有监督预训练，再在小数据集上针对特定问题进行调优。这是在训练数据稀少的情况下一个非常有效的训练大型卷积神经网络的方法。我们的实验中，针对检测的调优将mAP提高了8个百分点。调优后，我们的系统在VOC2010上达到了54%的mAP，远远超过高度优化的基于HOG的可变性部件模型（deformable part model，DPM） 【DPM:多尺度形变部件模型，连续获得07-09的检测冠军，2010年其作者Felzenszwalb Pedro被VOC授予”终身成就奖”。DPM把物体看成了多个组成的部件（比如人脸的鼻子、嘴巴等），用部件间的关系来描述物体，这个特性非常符合自然界很多物体的非刚体特征。DPM可以看做是HOG+SVM的扩展，很好的继承了两者的优点，在人脸检测、行人检测等任务上取得了不错的效果，但是DPM相对复杂，检测速度也较慢，从而也出现了很多改进的方法。】【挑战2及解决办法】\r\n\r\nR-CNN计算高效： 原因都是小型矩阵的乘积，特征在不同类别间共享；HOG-like特征的一个优点是简单性：能够很容易明白提取到的特征是什么（可视化出来）。介绍技术细节之前，我们提醒大家由于R-CNN是在推荐区域上进行操作，所以可以很自然地扩展到语义分割任务上。只要很小的改动，我们就在PASCAL VOC语义分割任务上达到了很有竞争力的结果，在VOC2011测试集上平均语义分割精度达到了47.9%。【R-CNN的其他应用】\r\n\r\n2.用R-CNN做目标检测\r\n\r\n我们的物体检测系统有三个模块构成。\r\n\r\n第一个，产生类别无关的region proposal。这些推荐定义了一个候选检测区域的集合；\r\n第二个是一个大型卷积神经网络，用于从每个区域抽取特定大小的特征向量；\r\n第三个是一个指定类别的线性SVM。\r\n本部分，将展示每个模块的设计，并介绍他们的测试阶段的用法，以及参数是如何学习的细节，最后给出在PASCAL VOC 2010-12和ILSVRC2013上的检测结果。\r\n\r\n2.1模块设计\r\n\r\n【region proposal：区域推荐】 近来有很多研究都提出了产生类别无关区域推荐的方法比如: objectness（物体性）[1]，selective search（选择性搜索）[39]，category-independent object proposals(类别无关物体推荐)[14]，constrained parametric min-cuts（受限参最小剪切, CPMC)[5]，multi-scal combinatorial grouping(多尺度联合分组)[3]，以及Ciresan[6]等人的方法,将CNN用在规律空间块裁剪上以检测有丝分裂细胞，也算是一种特殊的区域推荐类型。由于R-CNN对特定区域推荐算法是不关心的，所以我们采用了选择性搜索[39]以方便和前面的工作进行可控的比较。[region proposal方法，建议自行学习]\r\n\r\n【Feature extraction: 特征提取】我们使用Krizhevsky等人所描述的CNN的一个Caffe实现版本[24]对每个推荐区域抽取一个4096维度的特征向量把一个输入为277277大小的图片，通过五个卷积层和两个全连接层进行前向传播,最终得到一个4096-D的特征向量。读者可以参考AlexNet获得更多的网络架构细节。为了计算region proposal的特征，我们首先要对图像进行转换，使得它符合CNNC的输入（架构中的CNN只能接受固定大小：277277）这个变换有很多办法，我们使用了最简单的一种。无论候选区域是什么尺寸和宽高比，我们都把候选框变形成想要的尺寸,。具体的，变形之前，我们先在候选框周围加上16的padding,再进行各向异性缩放。这种形变使得mAp提高了3到5个百分点。在补充材料中，作者对比了各向异性和各向同性缩放缩放方法。\r\n\r\n2.2测试阶段的物体检测\r\n\r\n测试阶段，在测试图像上使用selective search抽取2000个推荐区域（实验中，我们使用了选择性搜索的快速模式）（关于selective search我们在下文中会详细讲解）然后变形每一个推荐区域，再通过CNN前向传播计算出特征。然后我们使用对每个类别训练出的SVM给整个特征向量中的每个类别单独打分。【对每一个框使用每个类别的SVM进行打分】然后给出一张图像中所有的打分区域，然后使用NMS【贪婪非最大化抑制算法】（每个类别是独立进行的），拒绝掉一些和高分区域的IOU大于阈值的候选框。\r\n\r\n【运行时间的分析】两个特性让检测变得很高效。首先，所有的CNN参数都是跨类别共享的。（参数共享）其次，通过CNN计算的特征向量相比其他通用方法（比如spatial pyramids with bag-of-visual-word encodings）维度是很低的。（低维特征）这种共享的结果就是计算推荐区域特征的耗时可以分摊到所有类别的头上（GPU：每张图13s，CPU：每张图53s）。\r\n\r\n唯一的和具体类别有关的计算是特征向量和SVM权重和点积，以及NMS实践中，所有的点积都可以批量化成一个单独矩阵间运算。特征矩阵的典型大小是2000×4096，SVM权重的矩阵是4096xN，其中N是类别的数量。\r\n\r\n分析表明R-CNN可以扩展到上千个类别，而不需要借用近似技术（如hashing）。及时有10万个类别，矩阵乘法在现代多核CPU上只需要10s而已。但这种高效不仅仅是因为使用了区域推荐和共享特征。\r\n\r\n2.3训练\r\n\r\n【**有监督的预训练 **】我们在大型辅助训练集ILSVRC2012分类数据集（没有约束框数据）上预训练了CNN。预训练采用了Caffe的CNN库。总体来说，我们的CNN十分接近krizhevsky等人的网络的性能，在ILSVRC2012分类验证集在top-1错误率上比他们高2.2%。差异主要来自于训练过程的简化。\r\n\r\n【**特定领域的参数调优 **】为了让我们的CNN适应新的任务（即检测任务）和新的领域（变形后的推荐窗口）。我们只使用变形后的推荐区域对CNN参数进行SGD训练。我们替换掉了ImageNet专用的1000-way分类层，换成了一个随机初始化的21-way分类层，（其中20是VOC的类别数，1代表背景）而卷积部分都没有改变，我们对待所有的推荐区域，如果其和真实标注的框的IoU>= 0.5就认为是正例，否则就是负例，SGD开始的learning_rate为0.001（是初始化预训练时的十分之一），这使得调优得以有效进行而不会破坏初始化的成果。每轮SGD迭代，我们统一使用32个正例窗口（跨所有类别）和96个背景窗口，即每个mini-batch的大小是128。另外我们倾向于采样正例窗口，因为和背景相比他们很稀少。\r\n\r\n【目标种类分类器】思考一下检测汽车的二分类器。很显然，一个图像区域紧紧包裹着一辆汽车应该就是正例。同样的，没有汽车的就是背景区域，也就是负例。较为不明确的是怎样标注哪些只和汽车部分重叠的区域。我们使用IoU重叠阈值来解决这个问题，低于这个阈值的就是负例。这个阈值我们选择了0.3，是在验证集上基于{0, 0.1, … 0.5}通过网格搜索得到的。我们发现认真选择这个阈值很重要。如果设置为0.5，可以提升mAP5个点，设置为0，就会降低4个点。正例就严格的是标注的框\r\n\r\n一旦特征提取出来，并应用标签数据，我们优化了每个类的线性SVM。由于训练数据太大，难以装进内存，我们选择了标准的hard negative mining method【难负例挖掘算法，用途就是负例数据不平衡，而负例分赛代表性又不够的问题，hard negative就是每次把那些顽固的棘手的错误，在送回去训练，训练到你的成绩不在提升为止，这个过程叫做hard negative mining】\r\n\r\n高难负例挖掘算法收敛很快，实践中只要在所有图像上经过一轮训练，mAP就可以基本停止增加了。 附录B中，讨论了，为什么在fine-tunning和SVM训练这两个阶段，我们定义得正负样例是不同的。【fine-tunning阶段是由于CNN对小样本容易过拟合，需要大量训练数据，故对IoU限制宽松： IoU>0.5的建议框为正样本，否则为负样本； SVM这种机制是由于其适用于小样本训练，故对样本IoU限制严格：Ground Truth为正样本，与Ground Truth相交IoU＜0.3的建议框为负样本。】\r\n\r\n我们也会讨论为什么训练一个分类器是必要的，而不只是简单地使用来自调优后的CNN的最终fc8层的输出。【为什么单独训练了一个SVM而不是直接用softmax，作者提到，刚开始时只是用了ImageNet预训练了CNN，并用提取的特征训练了SVMs，此时用正负样本标记方法就是前面所述的0.3,后来刚开始使用fine-tuning时，也使用了这个方法，但是发现结果很差，于是通过调试选择了0.5这个方法，作者认为这样可以加大样本的数量，从而避免过拟合。然而，IoU大于0.5就作为正样本会导致网络定位准确度的下降，故使用了SVM来做检测，全部使用ground-truth样本作为正样本，且使用非正样本的，且IoU大于0.3的“hard negatives”，提高了定位的准确度】\r\n\r\n2.4在PASCAL VOC 2010-12上的结果\r\n\r\n在数据集： PASCAL 2010-12:\r\n\r\n\r\n原paper的Table1\r\n\r\n在数据集ILSVR2013数据集上得到了相似的结果\r\n\r\n3.可视化、消融、模型的错误\r\n\r\n3.1可视化学习到的特征（如何展示CNN每层学到的东西，了解）\r\n\r\n直接可视化第一层filters非常容易理解，它们主要捕获方向性边缘和对比色。难以理解的是后面的层。Zeiler and Fergus提出了一种可视化的很棒的反卷积办法。我们则使用了一种简单的非参数化方法，直接展示网络学到的东西。这个想法是单一输出网络中一个特定单元（特征），然后把它当做一个正确类别的物体检测器来使用。 方法是这样的，先计算所有抽取出来的推荐区域（大约1000万），计算每个区域所导致的对应单元的激活值，然后按激活值对这些区域进行排序，然后进行最大值抑制，最后展示分值最高的若干个区域。这个方法让被选中的单元在遇到他想激活的输入时“自己说话”。我们避免平均化是为了看到不同的视觉模式和深入观察单元计算出来的不变性。 我们可视化了第五层的池化层pool5，是卷积网络的最后一层，feature_map(卷积核和特征数的总称)的大小是6 x 6 x 256 = 9216维。忽略边界效应，每个pool5单元拥有195×195的感受野，输入是227×227。pool5中间的单元，几乎是一个全局视角，而边缘的单元有较小的带裁切的支持。 图4的每一行显示了对于一个pool5单元的最高16个激活区域情况，这个实例来自于VOC 2007上我们调优的CNN，这里只展示了256个单元中的6个（附录D包含更多）。我们看看这些单元都学到了什么。第二行，有一个单元看到狗和斑点的时候就会激活，第三行对应红斑点，还有人脸，当然还有一些抽象的模式，比如文字和带窗户的三角结构。这个网络似乎学到了一些类别调优相关的特征，这些特征都是形状、纹理、颜色和材质特性的分布式表示。而后续的fc6层则对这些丰富的特征建立大量的组合来表达各种不同的事物。\r\n\r\n3.2消融研究(Ablation studies)\r\n\r\nablation study 就是为了研究模型中所提出的一些结构是否有效而设计的实验。如你提出了某某结构，但是要想确定这个结构是否有利于最终的效果，那就要将去掉该结构的网络与加上该结构的网络所得到的结果进行对比，这就是ablation study。也就是（控制变量法）\r\n\r\n【没有调优的各层性能】\r\n\r\n为了理解哪一层对于检测的性能十分重要，我们分析了CNN最后三层的每一层在VOC2007上面的结果。Pool5在3.1中做过剪短的表述。最后两层下面来总结一下。\r\n\r\nfc6是一个与pool5连接的全连接层。为了计算特征，它和pool5的feature map（reshape成一个9216维度的向量）做了一个4096×9216的矩阵乘法，并添加了一个bias向量。中间的向量是逐个组件的半波整流（component-wise half-wave rectified）【Relu（x<- max(0,x)）】\r\n\r\nfc7是网络的最后一层。跟fc6之间通过一个4096×4096的矩阵相乘。也是添加了bias向量和应用了ReLU。\r\n\r\n我们先来看看没有调优的CNN在PASCAL上的表现，没有调优是指所有的CNN参数就是在ILSVRC2012上训练后的状态。分析每一层的性能显示来自fc7的特征泛化能力不如fc6的特征。这意味29%的CNN参数，也就是1680万的参数可以移除掉，而且不影响mAP。更多的惊喜是即使同时移除fc6和fc7，仅仅使用pool5的特征，只使用CNN参数的6%也能有非常好的结果。可见CNN的主要表达力来自于卷积层，而不是全连接层。这个发现提醒我们也许可以在计算一个任意尺寸的图片的稠密特征图（dense feature map）时使仅仅使用CNN的卷积层。这种表示可以直接在pool5的特征上进行滑动窗口检测的实验。\r\n\r\n【调优后的各层性能】\r\n\r\n我们来看看调优后在VOC2007上的结果表现。提升非常明显，mAP提升了8个百分点，达到了54.2%。fc6和fc7的提升明显优于pool5，这说明pool5从ImageNet学习的特征通用性很强，在它之上层的大部分提升主要是在学习领域相关的非线性分类器。\r\n\r\n【对比其他特征学习方法】\r\n\r\nR-CNN是最好的，我们的mAP要多大约20个百分点，61%的相对提升。\r\n\r\n3.3网络结构 3.4 检测错误分析\r\n\r\n两个直接省略！！！\r\n\r\n3.5Bounding-box回归\r\n\r\n基于错误分析，我们使用了一种简单的方法减小定位误差。受到DPM[17]中使用的约束框回归训练启发，我们训练了一个线性回归模型在给定一个选择区域的pool5特征时去预测一个新的检测窗口。详细的细节参考附录C。表1、表2和图4的结果说明这个简单的方法，修复了大量的错位检测，提升了3-4个百分点。\r\n\r\n关于BoundingBox-Regression参考下文\r\n\r\n4.结论\r\n\r\n最近几年，物体检测陷入停滞，表现最好的检测系统是复杂的将多低层级的图像特征与高层级的物体检测器环境与场景识别相结合。本文提出了一种简单并且可扩展的物体检测方法，达到了VOC 2012数据集相对之前最好性能的30%的提升。 我们取得这个性能主要通过两个方面：第一是应用了自底向上的候选框训练的高容量的卷积神经网络进行定位和分割物体。另外一个是使用在标签数据匮乏的情况下训练大规模神经网络的一个方法。我们展示了在有监督的情况下使用丰富的数据集（图片分类）预训练一个网络作为辅助性的工作是很有效的，然后采用稀少数据（检测）去调优定位任务的网络。我们猜测“有监督的预训练+特定领域的调优”这一范式对于数据稀少的视觉问题是很有效的。 最后,我们注意到能得到这些结果，将计算机视觉中经典的工具和深度学习(自底向上的区域候选框和卷积神经网络）组合是非常重要的。而不是违背科学探索的主线，这两个部分是自然而且必然的结合。\r\n\r\n2.PASCAL & ILSVRC\r\nPattern Analysis, Statical Modeling and Computational Learning Visual Object Classes\r\n\r\n[主页]http://host.robots.ox.ac.uk/pascal/VOC/\r\n\r\nProvides standardised image data sets for object class recognition\r\nProvides a common set of tools for accessing the data sets and annotations\r\nEnables evaluation and comparison of different methods\r\nRan challenges evaluating performance on object class recognition (from 2005-2012, now finished)\r\n提供了2005-2012年的数据集，数据集的[参考格式]https://www.cnblogs.com/whlook/p/7220105.html\r\n\r\n\r\nLarge Scale Visual Recognition Challenge (ILSVRC)\r\nStanford Vison Lab\r\n\r\nImageNet比赛\r\n\r\n[主页]http://www.image-net.org/challenges/LSVRC/\r\n\r\nThe ImageNet Large Scale Visual Recognition Challenge (ILSVRC) evaluates algorithms for object detection and image classification at large scale. One high level motivation is to allow researchers to compare progress in detection across a wider variety of objects -- taking advantage of the quite expensive labeling effort. Another motivation is to measure the progress of computer vision for large scale image indexing for retrieval and annotation.\r\n\r\n3. 目标检测中用到的一些评价指标\r\n模型的好坏是相对的，什么样的模型好不仅取决于数据和算法，还取决于任务需求，因此选取一个合理的模型评价指标非常有必要。\r\n\r\nIOU\r\nIOU是由预测的包围盒与地面真相包围盒的重叠区域（交集），除以他们之间的联合区域（并集），gt代表针织框\r\n\r\n\r\n\r\nPrecision，Recall,......\r\n一般模型常用的错误率(Error)和精度(accuracy)就能解决(一般的机器学习任务),精度和错误率虽然常用，但不能满足所有需求\r\n\r\n\r\n\r\n其他常用的： ROC（AUC为ROC曲线下的面积)，P-R曲线，lift曲线，若当值，K-S值（二分类用的多一些），混淆矩阵，F1(F-score, F-Measure $\\aplpha=1$ )\r\n\r\n基于自己的学习任务，同时也可以修改(比如加一些惩罚)或自定义其他的评价指标。\r\n\r\nAP & mAP\r\nP: precision\r\n\r\nAP: average precision,每一类别P值的平均值\r\n\r\nmAP: mean average precision,对所有类别的AP取平均\r\n\r\n目标检测中的模型的分类和定位都需要进行评估，每个图像都可能具有不同类别的不同目标。\r\n\r\n** 计算mAP的过程**\r\n\r\n[Ground Truth的定义] 对于任何算法，度量总是与数据的真实值(Ground Truth)进行比较。我们只知道训练、验证和测试数据集的Ground Truth信息。对于物体检测问题，Ground Truth包括图像，图像中的目标的类别以及图像中每个目标的边界框。\r\n\r\n下图给出了一个真实的图像(JPG/PNG)和其他标注信息作为文本(边界框坐标(X, Y, 宽度和高度)和类)，其中上图的红色框和文本标签仅仅是为了更好的理解，手工标注可视化显示。\r\n\r\n\r\n标注图像：Ground Truth\r\n\r\n对于上面的例子，我们在模型在训练中得到了下图所示的目标边界框和3组数字定义的ground truth(假设这个图像是1000*800px，所有这些坐标都是构建在像素层面上的)\r\n\r\n\r\n模型需要预测的：关于详细的一些模型预测label的设定建议学习吴恩达的deeplearning.ai关于卷积网络学习的网课\r\n\r\n开始计算mAP的步骤：\r\n\r\n1.假设原始图像和真实的标注信息(ground truth)如上所示，训练和验证数据以相同的方式都进行了标注。该模型将返回大量的预测，但是在这些模型中，大多数都具有非常低的置信度分数，因此我们只考虑高于某个置信度分数的预测信息。我们通过我们的模型运行原始图像，在置信阈值确定之后，下面是目标检测算法返回的带有边框的图像区域(bounding boxes)。\r\n\r\n预测结果\r\n\r\n但是怎样在实际中量化这些检测区域的正确性呢？ 首先我们需要知道每个检测的正确性。测量一个给定的边框的正确性的度量标准是loU-交幷比(检测评价函数)，这是一个非常简单的视觉量。 下面给出loU的简单的解释。(我们在第一部分已经给出定义)\r\n\r\n2.IoU计算\r\nloU(交并比)是模型所预测的检测框和真实(ground truth)的检测框的交集和并集之间的比例。这个数据也被称为Jaccard指数。为了得到交集和并集值，我们首先将预测框叠加在ground truth实际框上面，如下图所示：\r\n\r\n\r\n现在对于每个类，预测框和真实框重叠的区域就是交集区域，预测框和真实框的总面积区域就是并集框。 在上面的目标马的交集和联合看起来是这样的：\r\n\r\n\r\n交集包括重叠区域(青色区域), 并集包括橙色和青色区域\r\n\r\n3.识别正确的检测和计算精度\r\n我们使用loU看检测是否正确需要设定一个阈值，最常用的阈值是0.5，即如果loU>0.5，则认为是真实的检测(true detection)，否则认为是错误的检测(false detection)。我们现在计算模型得到的每个检测框的loU值。用计算出的loU值与设定的loU阈值(例如0.5)比较，就可以计算出每个图像中每个类的正确检测次数(A)。对于每个图像，我们都有ground truth的数据(即知道每个图像的真实目标信息),因此也知道了该图像中给定类别的实际目标(B)的数量。因此我们可以使用这个公式来计算该类模型的精度(A/B)\r\n\r\n\r\n即给定一张图像的类别C的Precision=图像正确预测(True Positives)的数量除以在该图像上这一类的总的目标数量。\r\n\r\n假如现在有一个给定的类，验证集中有100个图像，并且我们知道每个图像都有其中的所有类(基于ground truth)。所以我们可以得到100个精度值，计算这100个精度值的平均值，得到的就是该类的平均精度。\r\n\r\n\r\n即一个C类的平均精度=在验证集上所有的图像对于类C的精度值的和/有类C这个目标的所有图像的数量。\r\n\r\n4.计算最终mAP\r\n现在假如我们整个集合中有20个类，对于每个类别，我们都先计算loU，接下来计算精度,然后计算平均精度。所有我们现在有20个不同的平均精度值。使用这些平均精度值，我们可以轻松的判断任何给定类别的模型的性能。\r\n\r\n但是问题是使用20个不同的平均精度使我们难以度量整个模型，所以我们可以选用一个单一的数字来表示一个模型的表现(一个度量来统一它们),我们可以取所有类的平均精度值的平均值，即mAP(均值平均精度)。\r\n\r\n\r\nMAP=所有类别的平均精度求和除以所有类别\r\n\r\n使用MAP值时我们需要满足一下条件： (1) MAP总是在固定的数据集上计算 (2)它不是量化模型输出的绝对度量，但是是一个比较好的相对度量。当我们在流行的公共数据集上计算这个度量时，这个度量可以很容易的用来比较不同目标检测方法 (3)根据训练中类的分布情况，平均精度值可能会因为某些类别(具有良好的训练数据)非常高(对于具有较少或较差数据的类别)而言非常低。所以我们需要mAP可能是适中的，但是模型可能对于某些类非常好，对于某些类非常不好。因此建议在分析模型结果的同时查看个各类的平均精度(AP)，这些值也可以作为我们是不是需要添加更多训练样本的一个依据。\r\n\r\n4.各向异性，各向同性缩放\r\nR-CNN的论文中提到了各向同性，各向异性缩放的概念，这里做一个详细解释：\r\n\r\n当我们输入一张图片时，我们要搜索出所有可能是物体的区域，R-CNN采用的就是Selective Search方法，通过这个算法我们搜索出2000个候选框。然后从R-CNN的总流程图中可以看到，搜出的候选框是矩形的，而且是大小各不相同。然而CNN对输入图片的大小是有固定的，如果把搜索到的矩形选框不做处理，就扔进CNN中，肯定不行。因此对于每个输入的候选框都需要缩放到固定的大小。\r\n\r\n下面我们讲解要怎么进行缩放处理，为了简单起见我们假设下一阶段CNN所需要的输入图片大小是个正方形图片227*227。因为我们经过selective search 得到的是矩形框，paper试验了两种不同的处理方法：\r\n\r\n各向异性缩放： 这种方法很简单，就是不管图片的长宽比例，管它是否扭曲，进行缩放就是了，全部缩放到CNN输入的大小227*227，如下图(D)所示；\r\n\r\n各向同性缩放： 因为图片扭曲后，估计会对后续CNN的训练精度有影响，于是作者也测试了“各向同性缩放”方案。有两种办法：\r\n\r\n先扩充后裁剪\r\n直接在原始图片中，把bounding box的边界进行扩展延伸成正方形，然后再进行裁剪；如果已经延伸到了原始图片的外边界，那么就用bounding box中的颜色均值填充；如下图(B)所示;\r\n\r\n先裁剪后扩充\r\n先把bounding box图片裁剪出来，然后用固定的背景颜色填充成正方形图片(背景颜色也是采用bounding box的像素颜色均值),如下图(C)所示;\r\n\r\n对于上面的异性、同性缩放，文献还有个padding处理，上面的示意图中第1、3行就是结合了padding=0, 第2、4行结果图采用padding=16的结果。经过最后的试验，作者发现采用各向异性缩放、padding=16的精度最高。（也就是最后一个图）\r\n\r\n\r\n5.NMS:非极大值抑制\r\n先假设有n个（假设有6个）候选框，根据分类器类别分类概率做排序，从小到大分别属于车辆的概率分别为A<=B<=C<=D<=E<=F。\r\n\r\n（1）从最大概率的矩形框开始（F），分别判断A-E与F的IOU是否大于某个设定的阈值\r\n\r\n（2）假设B,D与F的IOU超过F,那就扔掉B,D，并标记第一个矩形框F,是我们保留下来的\r\n\r\n（3）从剩余矩形框A,C.E中选择概率最大的E，然后判断E与A,C的IOU(重叠度），重叠度大于一定的阈值，那么就扔掉，标记E是我们保留下来的第2个矩形框\r\n\r\n（4）一直重复这个过程，找到所有被曾经保留下来的矩形框。\r\n\r\n为什么需要NMS?\r\n\r\n在测试过程完成到第4步之后[section7中的步骤]，获得2000×20维矩阵表示每个建议框是某个物体类别的得分情况，此时会遇到下图所示情况，同一个车辆目标会被多个建议框包围，这时需要非极大值抑制操作去除得分较低的候选框以减少重叠框。\r\n\r\n\r\n6.边框回归：BoundingBox-Regression(BBR)\r\n首先考虑R-CNN中为什么要做BBR?\r\n\r\nBounding Boxregression是 RCNN中使用的边框回归方法，在RCNN的论文中，作者指出：主要的错误是源于mislocalization。为了解决这个问题，作者使用了bounding box regression。这个方法使得mAp提高了3到4个点。\r\n\r\nBBR的输入 是什么？\r\n\r\n\r\n对于预测框P,我们有一个ground truth是G：当0.1< IoU < 0.5时出现重复，这种情况属于作者说的poor localiazation, 但注意：我们使用的并不是这样的框进行BBR(网上很多地方都在这里出现了误导),作者是用iou>0.6的进行BBR,也就是IOU<0.6的Bounding Box会直接被舍弃，不进行BBR。这样做是为了满足线性转换的条件。否则会导致训练的回归模型不 work.\r\n\r\n（当 P跟 G 离得较远，就是复杂的非线性问题了，此时用线性回归建模显然不合理。)\r\n\r\n至于为什么当IoU较大的时候，我们才认为是线性变化，我找到一个觉得解释的比较清楚的，截图在下面：\r\n\r\n\r\n线性回归就是给定输入的特征向量 X, 学习一组参数 W, 使得经过线性回归后的值跟真实值 Y(Ground Truth)非常接近. 即Y≈WX 。\r\n\r\n边框回归的目的既是：给定(Px,Py,Pw,Ph)寻找一种映射f， 使得f(Px,Py,Pw,Ph)=(Gx^,Gy^,Gw^,Gh^)并且(Gx^,Gy^,Gw^,Gh^)≈(Gx,Gy,Gw,Gh)\r\n\r\n例如上图：我们现在要讲P框进行BBR,gt为G框，那么我们希望经过变换之后，P框能接近G框（比如，上图的G^框）。现在进行变换,过程如下：\r\n\r\n我们用一个四维向量（x,y,w,h）来表示一个窗口，其中x,y,w,h分别代表框的中心点的坐标以及宽，高。我们要从P得到G^，需要经过平移和缩放。\r\n\r\n\r\n其实这并不是真正的BBR，因为我们只是把P映射回G^,得到一个一般变换的式子，那为什么不映射回最优答案G呢？于是，P映射回G而不是G^，那我们就能得到最优变换（这才是最终的BBR）：\r\n\r\n\r\n这里为什么会将tw,th写成exp形式？\r\n\r\n是因为tw,th代表着缩放的尺寸，这个尺寸是>0的，所以使用exp的形式正好满足这种约束。 也就是，我们将转换d换成转换t,就得到了P到G的映射。 di -> ti。 现在我们只需要学习 这四个变换dx(P),dy(P),dw(P),dh(P)，然后最小化t和d之间的距离，最小化这个loss，即可。\r\n\r\n注意：此时看起来我们只要输入P的四维向量，就可以学习,然后求出，但是，其实我们输入的是pool5之后的features，记做φ5，因为如果只是单纯的靠坐标回归的话，CNN根本就没有发挥任何作用，但其实，BB的位置应该有CNN计算得到的features来fine-tune。所以，我们选择将pool5的feature作为输入。\r\n\r\n\r\nloss为：\r\n\r\n\r\n最后，我们只需要利用梯度下降或最小二乘求解w即可。 另外不要认为BBR和分类信息没有什么关系，是针对每一类都会训练一个BBR\r\n\r\n7.R-CNN测试的一般步骤\r\n1.输入一张多目标图像，采用selective search算法提取约2000个建议框；\r\n\r\n2.先在每个建议框周围加上16个像素值为建议框像素平均值的边框，再直接变形为227×227的大小；\r\n\r\n3.先将所有建议框像素减去该建议框像素平均值后【预处理操作】，再依次将每个227×227的建议框输入AlexNet CNN网络获取4096维的特征【比以前的人工经验特征低两个数量级】，2000个建议框的CNN特征组合成2000×4096维矩阵；\r\n\r\n4.将2000×4096维特征与20个SVM组成的权值矩阵4096×20相乘【20种分类，SVM是二分类器，则有20个SVM】，获得2000×20维矩阵表示每个建议框是某个物体类别的得分；\r\n\r\n5.分别对上述2000×20维矩阵中每一列即每一类进行非极大值抑制剔除重叠建议框，得到该列即该类中得分最高的一些建议框；\r\n\r\n6.分别用20个回归器对上述20个类别中剩余的建议框进行回归操作，最终得到每个类别的修正后的得分最高的bounding box。\r\n\r\n8.R-CNN的训练过程\r\n1.有监督预训练\r\n\r\nILSVRC样本集上仅有图像类别标签，没有图像物体位置标注； 采用AlexNet CNN网络进行有监督预训练，学习率=0.01； 该网络输入为227×227的ILSVRC训练集图像，输出最后一层为4096维特征->1000类的映射，训练的是网络参数。\r\n\r\n2.特定样本下的微调\r\n\r\nPASCAL VOC 2007样本集上既有图像中物体类别标签，也有图像中物体位置标签； 采用训练好的AlexNet CNN网络进行PASCAL VOC 2007样本集下的微调，学习率=0.001【0.01/10为了在学习新东西时不至于忘记之前的记忆】； mini-batch为32个正样本和96个负样本【由于正样本太少】； 该网络输入为建议框【由selective search而来】变形后的227×227的图像，修改了原来的1000为类别输出，改为21维【20类+背景】输出，训练的是网络参数。\r\n\r\n3.SVM训练\r\n\r\n由于SVM是二分类器，需要为每个类别训练单独的SVM； SVM训练时输入正负样本在AlexNet CNN网络计算下的4096维特征，输出为该类的得分，训练的是SVM权重向量； 由于负样本太多，采用hard negative mining的方法在负样本中选取有代表性的负样本，该方法具体见\r\n\r\n4.Bounding-box regression训练\r\n\r\n结果怎么样?\r\n\r\nPASCAL VOC 2010测试集上实现了53.7%的mAP；\r\n\r\nPASCAL VOC 2012测试集上实现了53.3%的mAP；\r\n\r\n计算Region Proposals和features平均所花时间：13s/image on a GPU；53s/image on a CPU\r\n\r\n还存在什么问题?\r\n\r\n很明显，最大的缺点是对一张图片的处理速度慢，这是由于一张图片中由selective search算法得出的约2k个建议框都需要经过变形处理后由CNN前向网络计算一次特征，这其中涵盖了对一张图片中多个重复区域的重复计算，很累赘；\r\n\r\n知乎上有人说R-CNN网络需要两次CNN前向计算，第一次得到建议框特征给SVM分类识别，第二次对非极大值抑制后的建议框再次进行CNN前向计算获得Pool5特征，以便对建议框进行回归得到更精确的bounding-box，这里文中并没有说是怎么做的，个人认为也可能在计算2k个建议框的CNN特征时，在硬盘上保留了2k个建议框的Pool5特征，虽然这样做只需要一次CNN前向网络运算，但是耗费大量磁盘空间；\r\n\r\n训练时间长，虽然文中没有明确指出具体训练时间，但由于采用RoI-centric sampling【从所有图片的所有建议框中均匀取样】进行训练，那么每次都需要计算不同图片中不同建议框CNN特征，无法共享同一张图的CNN特征，训练速度很慢；\r\n\r\n整个测试过程很复杂，要先提取建议框，之后提取每个建议框CNN特征，再用SVM分类，做非极大值抑制，最后做bounding-box回归才能得到图片中物体的种类以及位置信息；同样训练过程也很复杂，ILSVRC 2012上预训练CNN，PASCAL VOC 2007上微调CNN，做20类SVM分类器的训练和20类bounding-box回归器的训练；这些不连续过程必然涉及到特征存储、浪费磁盘空间等问题。\r\n\r\n9. HOG(Histogram of Oriented Gradient)\r\n方向梯度直方图特征是一种在计算机视觉和图像处理中用来进行物体检测的特征描述子。它通过计算和统计图像局部区域的梯度方向直方图来构成特征。Hog特征结合SVM分类器已经被广泛应用于图像识别中，尤其在行人检测中获得了极大的成功。需要提醒的是，HOG+SVM进行行人检测的方法是法国研究人员Dalal在2005的CVPR上提出的，而如今虽然有很多行人检测算法不断提出，但基本都是以HOG+SVM的思路为主。\r\n\r\n其思想是 在一副图像中，局部目标的表象和形状（appearance and shape）能够被梯度或边缘的方向密度分布很好地描述。（本质：梯度的统计信息，而梯度主要存在于边缘的地方）\r\n\r\n梯度的概念：\r\n\r\n在图像中梯度的概念也是像素值变换最快的方向，把边缘（在图像合成中单一物体的轮廓叫做边缘）引入进来，边缘与梯度保持垂直方向。\r\n\r\n\r\n具体在HOG中方向梯度的实现：首先用[-1,0,1]梯度算子对原图像做卷积运算，得到x方向（水平方向，以向右为正方向）的梯度分量gradscalx，然后用[1,0,-1]T梯度算子对原图像做卷积运算，得到y方向（竖直方向，以向上为正方向）的梯度分量gradscaly。然后再用以下公式计算该像素点的梯度大小和方向。\r\n\r\n\r\n直方图\r\n\r\n这个就不做解释了！！！\r\n\r\n方向梯度直方图HOG的提取\r\n\r\n方向梯度直方图为图像局部区域的梯度特征量统计，我们为什么要提取这个东东呢？\r\n\r\nHOG主要应用于行人检测方面，以行人照片为例。\r\n\r\n\r\n上图是一张行人图的四种表示方式，原三色图，灰度图，边缘图，梯度图，人脑根据前期学习与先验知识很容易理解到图像中包含着一个行人，并可以根据一定情况将其从图像中抠选出来，但计算机是怎么思考的呢？怎样让计算机理解以上图像中包含的是一个行人呢？前三个图像现在情况不适用，所以选取梯度图，现在的梯度图同样也是人脑处理理解的平面结果，计算机是办不到的，需要将直观地的梯度图像转换成一种计算机容易理解的数据特征语言。\r\n\r\n对于64X128的图像而言，每8X8的像素组成一个cell，每2X2个cell组成一个块(block)，以8个像素为步长，那么，水平方向将有7个扫描窗口，垂直方向将有15个扫描窗口。也就是说，64X128的图片，总共有36X7X15=3780个特征。这里截取梯度图的一部分画图进行理解，尺寸与比例并不精确。\r\n\r\n\r\n单独将其中一个8X8的小格拿出来，方向梯度中指的方向范围为2π，360°，为了画直方图我们还需要选取合适的组距也就是bin，这里组距选取2π/9，也就是最后的直方图组数为9。下图为8X8像素的cell对应的方向梯度（未全部画出，共有8X8=64个）。\r\n\r\n\r\n　将上面的64个方向梯度，按着直方图的参数设置进行画图，其中梯度的大小在统计数量中呈线性关系，比如梯度大小为2，则直方图对应增加2个单位， 画出的对应直方图假设如下所示：\r\n\r\n\r\n把上图中单个cell对应的方向直方图转换为单维向量，也就是按规定组距对对应方向梯度个数进行编码，（8,10,6,12,4,5,8,6,14），得到单个cell的9个特征，每个block（扫描窗口）包含2X2个cell也就是2X2X9=36个特征，一个64X128大小的图像最后得到的特征数为36X7X15=3780个。这样将一幅直观的梯度图通过分解提取变为计算机容易理解的特征向量。 　　以上工作为HOG提取的主要内容，最后得到对应的行人的由方向梯度直方图HOG提取到的特征向量，但是计算机还是不知道这个数据数组代表了什么意思，什么时候这组向量代表行人，什么时候代表其他东西，怎样train，最后通过不断地学习，而后在检测积累的基础上对对未知图像检测识别有没有行人呢？那就是后一步SVM要做的事了。\r\n\r\n\r\n10.LBP（Local Binary Pattern)\r\nLBP（Local Binary Pattern，局部二值模式）是一种用来描述图像局部纹理特征的算子；它具有旋转不变性和灰度不变性等显著的优点。它是首先由T. Ojala, M.Pietikäinen, 和D. Harwood 在1994年提出，用于纹理特征提取。而且，提取的特征是图像的局部的纹理特征；\r\n\r\nLBP特征的描述\r\n\r\n原始的LBP算子定义为在3X3的窗口内，以窗口中心像素为阈值，将相邻的8个像素的灰度值与其进行比较，若周围像素值大于中心像素值，则该像素点的位置被标记为1，否则为0。这样，3X3邻域内的8个点经比较可产生8位二进制数（通常转换为十进制数即LBP码，共256种），即得到该窗口中心像素点的LBP值，并用这个值来反映该区域的纹理信息。如下图所示：\r\n\r\n\r\nLBP的改进版本\r\n\r\n原始的LBP提出后，研究人员不断对其提出了各种改进和优化。\r\n\r\n（1）圆形LBP算子\r\n\r\n基本的 LBP算子的最大缺陷在于它只覆盖了一个固定半径范围内的小区域，这显然不能满足不同尺寸和频率纹理的需要。为了适应不同尺度的纹理特征，并达到灰度和旋转不变性的要求，Ojala等对 LBP 算子进行了改进，将 3×3邻域扩展到任意邻域，并用圆形邻域代替了正方形邻域，改进后的 LBP 算子允许在半径为 R 的圆形邻域内有任意多个像素点。从而得到了诸如半径为R的圆形区域内含有P个采样点的LBP算子；\r\n\r\n\r\n（2）LBP旋转不变模式\r\n\r\n从 LBP 的定义可以看出，LBP 算子是灰度不变的，但却不是旋转不变的。图像的旋转就会得到不同的 LBP值。\r\n\r\nMaenpaa等人又将 LBP算子进行了扩展，提出了具有旋转不变性的 LBP 算子，即不断旋转圆形邻域得到一系列初始定义的 LBP值，取其最小值作为该邻域的 LBP 值。\r\n\r\n下图 给出了求取旋转不变的 LBP 的过程示意图，图中算子下方的数字表示该算子对应的 LBP值，图中所示的 8 种 LBP模式，经过旋转不变的处理，最终得到的具有旋转不变性的 LBP值为 15。也就是说，图中的 8种 LBP 模式对应的旋转不变的 LBP模式都是00001111。\r\n\r\n\r\n一个LBP算子可以产生不同的二进制模式，对于半径为R的圆形区域内含有P个采样点的LBP算子将会产生P2种模式。很显然，随着邻域集内采样点数的增加，二进制模式的种类是急剧增加的。例如：5×5邻域内20个采样点，有220＝1,048,576种二进制模式。如此多的二值模式无论对于纹理的提取还是对于纹理的识别、分类及信息的存取都是不利的。同时，过多的模式种类对于纹理的表达是不利的。例如，将LBP算子用于纹理分类或人脸识别时，常采用LBP模式的统计直方图来表达图像的信息，而较多的模式种类将使得数据量过大，且直方图过于稀疏。因此，需要对原始的LBP模式进行降维，使得数据量减少的情况下能最好的代表图像的信息。\r\n\r\n为了解决二进制模式过多的问题，提高统计性，Ojala提出了采用一种“等价模式”（Uniform Pattern）来对LBP算子的模式种类进行降维。Ojala等认为，在实际图像中，绝大多数LBP模式最多只包含两次从1到0或从0到1的跳变。因此，Ojala将“等价模式”定义为：当某个LBP所对应的循环二进制数从0到1或从1到0最多有两次跳变时，该LBP所对应的二进制就称为一个等价模式类。如00000000（0次跳变），00000111（只含一次从0到1的跳变），10001111（先由1跳到0，再由0跳到1，共两次跳变）都是等价模式类。除等价模式类以外的模式都归为另一类，称为混合模式类，例如10010111（共四次跳变）\r\n\r\n通过这样的改进，二进制模式的种类大大减少，而不会丢失任何信息。模式数量由原来的2P种减少为 P ( P-1)+2种，其中P表示邻域集内的采样点数。对于3×3邻域内8个采样点来说，二进制模式由原始的256种减少为58种，这使得特征向量的维数更少，并且可以减少高频噪声带来的影响。\r\n\r\nLBP特征用于检测的原理\r\n\r\n显而易见的是，上述提取的LBP算子在每个像素点都可以得到一个LBP“编码”，那么，对一幅图像（记录的是每个像素点的灰度值）提取其原始的LBP算子之后，得到的原始LBP特征依然是“一幅图片”（记录的是每个像素点的LBP值）。\r\n\r\n\r\nLBP的应用中，如纹理分类、人脸分析等，一般都不将LBP图谱作为特征向量用于分类识别，而是采用LBP特征谱的统计直方图作为特征向量用于分类识别。\r\n\r\n因为，从上面的分析我们可以看出，这个“特征”跟位置信息是紧密相关的。直接对两幅图片提取这种“特征”，并进行判别分析的话，会因为“位置没有对准”而产生很大的误差。后来，研究人员发现，可以将一幅图片划分为若干的子区域，对每个子区域内的每个像素点都提取LBP特征，然后，在每个子区域内建立LBP特征的统计直方图。如此一来，每个子区域，就可以用一个统计直方图来进行描述；整个图片就由若干个统计直方图组成；\r\n\r\n例如：一幅100X100像素大小的图片，划分为10X10=100个子区域（可以通过多种方式来划分区域），每个子区域的大小为10X10像素；在每个子区域内的每个像素点，提取其LBP特征，然后，建立统计直方图；这样，这幅图片就有10X10个子区域，也就有了10X10个统计直方图，利用这10X10个统计直方图，就可以描述这幅图片了。之后，我们利用各种相似性度量函数，就可以判断两幅图像之间的相似性了；\r\n\r\n对LBP特征向量进行提取的步骤\r\n\r\n（1）首先将检测窗口划分为16×16的小区域（cell）；\r\n\r\n（2）对于每个cell中的一个像素，将相邻的8个像素的灰度值与其进行比较，若周围像素值大于中心像素值，则该像素点的位置被标记为1，否则为0。这样，3X3邻域内的8个点经比较可产生8位二进制数，即得到该窗口中心像素点的LBP值；\r\n\r\n（3）然后计算每个cell的直方图，即每个数字（假定是十进制数LBP值）出现的频率；然后对该直方图进行归一化处理。\r\n\r\n（4）最后将得到的每个cell的统计直方图进行连接成为一个特征向量，也就是整幅图的LBP纹理特征向量；\r\n\r\n然后便可利用SVM或者其他机器学习算法进行分类了。\r\n\r\n', 1, 2, 0, 1, '2021-05-08 11:30:02', 3, 1);
INSERT INTO `article` VALUES (12, '神经网络NN算法', NULL, '起步\r\n神经网络算法( Neural Network )是机器学习中非常非常重要的算法。这是整个深度学习的核心算法，深度学习就是根据神经网络算法进行的一个延伸。理解这个算法的是怎么工作也能为后续的学习打下一个很好的基础。\r\n\r\n背景\r\n神经网络是受神经元启发的，对于神经元的研究由来已久，1904年生物学家就已经知晓了神经元的组成结构。\r\n\r\n\r\n\r\n\r\n\r\n\r\n1943年，心理学家McCulloch和数学家Pitts参考了生物神经元的结构，发表了抽象的神经元模型MP。\r\n1949年心理学家Hebb提出了Hebb学习率，认为人脑神经细胞的突触（也就是连接）上的强度上可以变化的。于是计算科学家们开始考虑用调整权值的方法来让机器学习。这为后面的学习算法奠定了基础。\r\n1958年，计算科学家Rosenblatt提出了由两层神经元组成的神经网络。他给它起了一个名字--感知器（ Perceptron ）。\r\n1986年，Rumelhar和Hinton等人提出了反向传播（ Backpropagation ，BP）算法，这是最著名的一个神经网络算法。\r\n神经网络的构成\r\n多层神经网络由三部分组成：输入层( input layer ), 隐藏层 ( hidden layers ), 输出层 ( output layers )。\r\n\r\n\r\n\r\n\r\n\r\n\r\n每一层都是有单元( units )组成，其中，输入层是由训练集中实例特征向量传入，根据连接点之间的权重传递到下一层，这样一层一层向前传递。\r\n\r\n输入层和输出层都只有一层，隐藏层的个数可以是任意的。神经网络的层数计算中不包括输入层，比方说一个神经网络中有2个隐藏层，我们就说这是一个3层的神经网络。\r\n\r\n作为多层向前神经网络，理论上，如果有足够多的隐藏层和训练集，是可以模拟出任何方程的。\r\n\r\n神经网络可以用来解决分类( classification ）问题，也可以解决回归( regression )问题。\r\n\r\n从单层到多层的神经网络\r\n由两层神经网络构成了单层神经网络，它还有个别名———— 感知器 。\r\n\r\n\r\n\r\n\r\n\r\n\r\n如图中，有3个输入，连接线的权值分别是 w1, w2, w3。将输入与权值进行乘积然后求和，作为 z 单元的输入，如果 z 单元是函数 g ，那么就有 z = g(a1 * w1 + a2 * w2 + a3 * w3) 。\r\n\r\n单层神经网络的扩展，也是一样的计算方式：\r\n\r\n\r\n\r\n\r\n\r\n\r\n在多层神经网络中，只不过是将输出作为下一层的输入，一样是乘以权重然后求和：\r\n\r\n\r\n\r\n\r\n\r\n\r\n设计神经网络结构\r\n使用神经网络进行训练之前，必须确定神经网络的层数，以及每一层中单元的个数。整个训练过程就是调整连接点之间的权重值。\r\n\r\n特征向量在被传入输入层前，通常要先标准化为 0 到 1 之间的数，这是为了加速学习过程。\r\n\r\n对于分类问题，如果是两类，可以用一个输出单元（0 和 1 表示分类结果）进行表示。如果是多分类问题，则每一个类别用一个输出单元表示。分类问题中，输出层单元个数通常等于类别的数量。\r\n\r\n目前没有明确的规则来设计最好有多少个隐藏层，通常是根据实验测试和误差，以及准确度来进行改进。\r\n\r\n交叉验证方法\r\n如何来预测准确度呢？在SVM的应用篇中，有个方法就是将数据集分为两类，训练集和测试集，利用测试集的数据将模型的预测结果进行对比，得出准确度。这里介绍另一个常用但更科学的方法————交叉验证方法( Cross-Validation )。\r\n\r\n\r\n\r\n\r\n\r\n\r\n这个方法不局限于将数据集分成两份，它可以分成 k 份。用第一份作为训练集，其余作为测试集，得出这一部分的准确度 ( evaluation )。再用第二份作为训练集，其余作为测试集，得出这第二部分的准确度。以此类推，最后取各部分的准确度的平均值。从而可以得到设计多少层最佳。\r\n\r\nBP 算法\r\nBP 算法 ( BackPropagation )是多层神经网络的训练一个核心的算法。目的是更新每个连接点的权重，从而减小预测值( predicted value )与真实值 ( target value )之间的差距。输入一条训练数据就会更新一次权重，反方向（从输出层=>隐藏层=>输入层）来以最小化误差（error）来更新权重（weitht）。\r\n\r\n在训练神经网络之前，需要初始化权重( weights )和偏向( bias )，初始化是随机值， -1 到 1 之间，每个单元有一个偏向。\r\n\r\n算法详细介绍\r\n数据集用 D 表示，学习率用 l 表示。对于每一个训练实例 X，都是一样的步骤。\r\n\r\n\r\n\r\n\r\n\r\n\r\n利用上一层的输入，得到本层的输入:\r\n\r\n\r\n\r\n\r\n得到输入值后，神经元要怎么做呢？我们先将单个神经元进行展开如图：\r\n\r\n\r\n\r\n\r\n\r\n\r\n得到值后需要进行一个非线性转化，这个转化在神经网络中称为激活函数( Activation function )，这个激活函数是一个 S 函数：\r\n\r\n\r\n\r\n\r\n更新权重\r\n通过上面的传递规则，可以得到最终的输出，而训练实例中包含实际的值，因此可以得到训练和实际之间的误差。根据误差(error)反向传送。\r\n\r\n对于输出层的误差为：\r\n\r\n\r\n\r\n\r\n对隐藏层的误差：\r\n\r\n\r\n\r\n\r\n更新权重：\r\n\r\n\r\n\r\n\r\n这里的 l 是学习率。偏向更新：\r\n\r\n\r\n\r\n\r\n训练的终止条件\r\n怎样才算是一个训练好了的神经网络呢？满足下面一个情况即可：\r\n\r\n权重的更新低于某个阈值，这个阈值是可以人工指定的；\r\n预测的错误率低于某个阈值；\r\n达到预设一定的循环次数。\r\nBP 算法举例\r\n假设有一个两层的神经网络，结构，权重和数据集如下：\r\n\r\n\r\n\r\n\r\n\r\n\r\n计算误差和更新权重：\r\n\r\n\r\n\r\n', 1, 0, 0, 0, '2021-05-08 11:31:02', 3, 1);
INSERT INTO `article` VALUES (13, '神经网络到深度学习', NULL, '转载于https://www.cnblogs.com/subconscious/p/5058741.html神经网络是一门重要的机器学习技术。它是目前最为火热的研究方向--深度学习的基础。学习神经网络不仅可以让你掌握一门强大的机器学习方法，同时也可以更好地帮助你理解深度学习技术。\r\n\r\n　　本文以一种简单的，循序的方式讲解神经网络。适合对神经网络了解不多的同学。本文对阅读没有一定的前提要求，但是懂一些机器学习基础会更好地帮助理解本文。\r\n\r\n　　神经网络是一种模拟人脑的神经网络以期能够实现类人工智能的机器学习技术。人脑中的神经网络是一个非常复杂的组织。成人的大脑中估计有1000亿个神经元之多。\r\n\r\n\r\n\r\n图1 人脑神经网络\r\n\r\n \r\n\r\n　　那么机器学习中的神经网络是如何实现这种模拟的，并且达到一个惊人的良好效果的？通过本文，你可以了解到这些问题的答案，同时还能知道神经网络的历史，以及如何较好地学习它。\r\n\r\n　　由于本文较长，为方便读者，以下是本文的目录：\r\n\r\n　　一.前言\r\n\r\n　　二.神经元\r\n\r\n　　三.单层神经网络（感知器）\r\n\r\n　　四.两层神经网络（多层感知器）\r\n\r\n　　五.多层神经网络（深度学习）\r\n\r\n　　六.回顾\r\n\r\n　　七.展望\r\n\r\n　　八.总结\r\n\r\n　　九.后记\r\n\r\n　　十.备注\r\n\r\n \r\n\r\n一. 前言\r\n\r\n　　让我们来看一个经典的神经网络。这是一个包含三个层次的神经网络。红色的是输入层，绿色的是输出层，紫色的是中间层（也叫隐藏层）。输入层有3个输入单元，隐藏层有4个单元，输出层有2个单元。后文中，我们统一使用这种颜色来表达神经网络的结构。\r\n\r\n\r\n\r\n图2 神经网络结构图\r\n\r\n \r\n\r\n　　在开始介绍前，有一些知识可以先记在心里：\r\n\r\n设计一个神经网络时，输入层与输出层的节点数往往是固定的，中间层则可以自由指定；\r\n神经网络结构图中的拓扑与箭头代表着预测过程时数据的流向，跟训练时的数据流有一定的区别；\r\n结构图里的关键不是圆圈（代表“神经元”），而是连接线（代表“神经元”之间的连接）。每个连接线对应一个不同的权重（其值称为权值），这是需要训练得到的。  \r\n　　除了从左到右的形式表达的结构图，还有一种常见的表达形式是从下到上来表示一个神经网络。这时候，输入层在图的最下方。输出层则在图的最上方，如下图：\r\n\r\n\r\n\r\n图3 从下到上的神经网络结构图 \r\n\r\n \r\n\r\n　　从左到右的表达形式以Andrew Ng和LeCun的文献使用较多，Caffe里使用的则是从下到上的表达。在本文中使用Andrew Ng代表的从左到右的表达形式。\r\n\r\n　　下面从简单的神经元开始说起，一步一步介绍神经网络复杂结构的形成。\r\n\r\n \r\n\r\n二. 神经元\r\n\r\n　　1.引子　\r\n\r\n　　对于神经元的研究由来已久，1904年生物学家就已经知晓了神经元的组成结构。\r\n\r\n　　一个神经元通常具有多个树突，主要用来接受传入信息；而轴突只有一条，轴突尾端有许多轴突末梢可以给其他多个神经元传递信息。轴突末梢跟其他神经元的树突产生连接，从而传递信号。这个连接的位置在生物学上叫做“突触”。\r\n\r\n　　人脑中的神经元形状可以用下图做简单的说明：\r\n\r\n\r\n\r\n图4 神经元\r\n\r\n \r\n\r\n 　　1943年，心理学家McCulloch和数学家Pitts参考了生物神经元的结构，发表了抽象的神经元模型MP。在下文中，我们会具体介绍神经元模型。\r\n\r\n   \r\n\r\n图5 Warren McCulloch（左）和 Walter Pitts（右）  \r\n\r\n　　2.结构 \r\n\r\n　　神经元模型是一个包含输入，输出与计算功能的模型。输入可以类比为神经元的树突，而输出可以类比为神经元的轴突，计算则可以类比为细胞核。\r\n\r\n　　下图是一个典型的神经元模型：包含有3个输入，1个输出，以及2个计算功能。\r\n\r\n　　注意中间的箭头线。这些线称为“连接”。每个上有一个“权值”。\r\n\r\n\r\n\r\n图6 神经元模型 \r\n\r\n \r\n\r\n　　连接是神经元中最重要的东西。每一个连接上都有一个权重。\r\n\r\n　　一个神经网络的训练算法就是让权重的值调整到最佳，以使得整个网络的预测效果最好。\r\n\r\n　　我们使用a来表示输入，用w来表示权值。一个表示连接的有向箭头可以这样理解：在初端，传递的信号大小仍然是a，端中间有加权参数w，经过这个加权后的信号会变成a*w，因此在连接的末端，信号的大小就变成了a*w。\r\n\r\n　　在其他绘图模型里，有向箭头可能表示的是值的不变传递。而在神经元模型里，每个有向箭头表示的是值的加权传递。\r\n\r\n\r\n\r\n图7 连接（connection）  \r\n\r\n \r\n\r\n　　如果我们将神经元图中的所有变量用符号表示，并且写出输出的计算公式的话，就是下图。\r\n\r\n\r\n\r\n图8 神经元计算  \r\n\r\n \r\n\r\n　　可见z是在输入和权值的线性加权和叠加了一个函数g的值。在MP模型里，函数g是sgn函数，也就是取符号函数。这个函数当输入大于0时，输出1，否则输出0。\r\n\r\n　　下面对神经元模型的图进行一些扩展。首先将sum函数与sgn函数合并到一个圆圈里，代表神经元的内部计算。其次，把输入a与输出z写到连接线的左上方，便于后面画复杂的网络。最后说明，一个神经元可以引出多个代表输出的有向箭头，但值都是一样的。\r\n\r\n　　神经元可以看作一个计算与存储单元。计算是神经元对其的输入进行计算功能。存储是神经元会暂存计算结果，并传递到下一层。\r\n\r\n\r\n\r\n图9 神经元扩展 \r\n\r\n \r\n\r\n　　当我们用“神经元”组成网络以后，描述网络中的某个“神经元”时，我们更多地会用“单元”（unit）来指代。同时由于神经网络的表现形式是一个有向图，有时也会用“节点”（node）来表达同样的意思。 \r\n\r\n　　3.效果 \r\n\r\n　　神经元模型的使用可以这样理解：\r\n\r\n　　我们有一个数据，称之为样本。样本有四个属性，其中三个属性已知，一个属性未知。我们需要做的就是通过三个已知属性预测未知属性。\r\n\r\n　　具体办法就是使用神经元的公式进行计算。三个已知属性的值是a1，a2，a3，未知属性的值是z。z可以通过公式计算出来。\r\n\r\n　　这里，已知的属性称之为特征，未知的属性称之为目标。假设特征与目标之间确实是线性关系，并且我们已经得到表示这个关系的权值w1，w2，w3。那么，我们就可以通过神经元模型预测新样本的目标。\r\n\r\n　　4.影响\r\n\r\n　　1943年发布的MP模型，虽然简单，但已经建立了神经网络大厦的地基。但是，MP模型中，权重的值都是预先设置的，因此不能学习。\r\n\r\n　　1949年心理学家Hebb提出了Hebb学习率，认为人脑神经细胞的突触（也就是连接）上的强度上可以变化的。于是计算科学家们开始考虑用调整权值的方法来让机器学习。这为后面的学习算法奠定了基础。\r\n\r\n\r\n\r\n图10 Donald Olding Hebb \r\n\r\n \r\n\r\n　　尽管神经元模型与Hebb学习律都已诞生，但限于当时的计算机能力，直到接近10年后，第一个真正意义的神经网络才诞生。\r\n\r\n \r\n\r\n三. 单层神经网络（感知器）\r\n\r\n　　1.引子　　\r\n\r\n　　1958年，计算科学家Rosenblatt提出了由两层神经元组成的神经网络。他给它起了一个名字--“感知器”（Perceptron）（有的文献翻译成“感知机”，下文统一用“感知器”来指代）。\r\n\r\n　　感知器是当时首个可以学习的人工神经网络。Rosenblatt现场演示了其学习识别简单图像的过程，在当时的社会引起了轰动。\r\n\r\n　　人们认为已经发现了智能的奥秘，许多学者和科研机构纷纷投入到神经网络的研究中。美国军方大力资助了神经网络的研究，并认为神经网络比“原子弹工程”更重要。这段时间直到1969年才结束，这个时期可以看作神经网络的第一次高潮。\r\n\r\n\r\n\r\n图11 Rosenblat与感知器 \r\n\r\n　　2.结构\r\n\r\n　　下面来说明感知器模型。\r\n\r\n　　在原来MP模型的“输入”位置添加神经元节点，标志其为“输入单元”。其余不变，于是我们就有了下图：从本图开始，我们将权值w1, w2, w3写到“连接线”的中间。\r\n\r\n\r\n\r\n图12 单层神经网络 \r\n\r\n \r\n\r\n　　在“感知器”中，有两个层次。分别是输入层和输出层。输入层里的“输入单元”只负责传输数据，不做计算。输出层里的“输出单元”则需要对前面一层的输入进行计算。\r\n\r\n　　我们把需要计算的层次称之为“计算层”，并把拥有一个计算层的网络称之为“单层神经网络”。有一些文献会按照网络拥有的层数来命名，例如把“感知器”称为两层神经网络。但在本文里，我们根据计算层的数量来命名。\r\n\r\n　　假如我们要预测的目标不再是一个值，而是一个向量，例如[2,3]。那么可以在输出层再增加一个“输出单元”。\r\n\r\n　　下图显示了带有两个输出单元的单层神经网络，其中输出单元z1的计算公式如下图。\r\n\r\n\r\n\r\n图13 单层神经网络(Z1)\r\n\r\n \r\n\r\n　　可以看到，z1的计算跟原先的z并没有区别。\r\n\r\n　　我们已知一个神经元的输出可以向多个神经元传递，因此z2的计算公式如下图。\r\n\r\n\r\n\r\n图14 单层神经网络(Z2)\r\n\r\n \r\n\r\n　　可以看到，z2的计算中除了三个新的权值：w4，w5，w6以外，其他与z1是一样的。\r\n\r\n　　整个网络的输出如下图。\r\n\r\n\r\n\r\n图15 单层神经网络(Z1和Z2)\r\n\r\n \r\n\r\n　　目前的表达公式有一点不让人满意的就是：w4，w5，w6是后来加的，很难表现出跟原先的w1，w2，w3的关系。\r\n\r\n　　因此我们改用二维的下标，用wx,y来表达一个权值。下标中的x代表后一层神经元的序号，而y代表前一层神经元的序号（序号的顺序从上到下）。\r\n\r\n　　例如，w1,2代表后一层的第1个神经元与前一层的第2个神经元的连接的权值（这种标记方式参照了Andrew Ng的课件）。根据以上方法标记，我们有了下图。\r\n\r\n\r\n\r\n图16 单层神经网络(扩展)\r\n\r\n \r\n\r\n　　如果我们仔细看输出的计算公式，会发现这两个公式就是线性代数方程组。因此可以用矩阵乘法来表达这两个公式。\r\n\r\n　　例如，输入的变量是[a1，a2，a3]T（代表由a1，a2，a3组成的列向量），用向量a来表示。方程的左边是[z1，z2]T，用向量z来表示。\r\n\r\n　　系数则是矩阵W（2行3列的矩阵，排列形式与公式中的一样）。\r\n\r\n　　于是，输出公式可以改写成：\r\n\r\ng(W * a) = z;\r\n\r\n \r\n\r\n　　这个公式就是神经网络中从前一层计算后一层的矩阵运算。\r\n\r\n　　3.效果\r\n\r\n　　与神经元模型不同，感知器中的权值是通过训练得到的。因此，根据以前的知识我们知道，感知器类似一个逻辑回归模型，可以做线性分类任务。\r\n\r\n　　我们可以用决策分界来形象的表达分类的效果。决策分界就是在二维的数据平面中划出一条直线，当数据的维度是3维的时候，就是划出一个平面，当数据的维度是n维时，就是划出一个n-1维的超平面。\r\n\r\n　　下图显示了在二维平面中划出决策分界的效果，也就是感知器的分类效果。\r\n\r\n\r\n\r\n图17 单层神经网络（决策分界）\r\n\r\n　　\r\n\r\n　　4.影响　\r\n\r\n　　感知器只能做简单的线性分类任务。但是当时的人们热情太过于高涨，并没有人清醒的认识到这点。于是，当人工智能领域的巨擘Minsky指出这点时，事态就发生了变化。\r\n\r\n　　Minsky在1969年出版了一本叫《Perceptron》的书，里面用详细的数学证明了感知器的弱点，尤其是感知器对XOR（异或）这样的简单分类任务都无法解决。\r\n\r\n　　Minsky认为，如果将计算层增加到两层，计算量则过大，而且没有有效的学习算法。所以，他认为研究更深层的网络是没有价值的。（本文成文后一个月，即2016年1月，Minsky在美国去世。谨在本文中纪念这位著名的计算机研究专家与大拿。）\r\n\r\n   \r\n\r\n图18 Marvin Minsky\r\n\r\n　　\r\n\r\n　　由于Minsky的巨大影响力以及书中呈现的悲观态度，让很多学者和实验室纷纷放弃了神经网络的研究。神经网络的研究陷入了冰河期。这个时期又被称为“AI winter”。\r\n\r\n　　接近10年以后，对于两层神经网络的研究才带来神经网络的复苏。\r\n\r\n \r\n\r\n四. 两层神经网络（多层感知器）\r\n\r\n　　1.引子\r\n\r\n　　两层神经网络是本文的重点，因为正是在这时候，神经网络开始了大范围的推广与使用。\r\n\r\n　　Minsky说过单层神经网络无法解决异或问题。但是当增加一个计算层以后，两层神经网络不仅可以解决异或问题，而且具有非常好的非线性分类效果。不过两层神经网络的计算是一个问题，没有一个较好的解法。\r\n\r\n　　1986年，Rumelhar和Hinton等人提出了反向传播（Backpropagation，BP）算法，解决了两层神经网络所需要的复杂计算量问题，从而带动了业界使用两层神经网络研究的热潮。目前，大量的教授神经网络的教材，都是重点介绍两层（带一个隐藏层）神经网络的内容。 \r\n\r\n　　这时候的Hinton还很年轻，30年以后，正是他重新定义了神经网络，带来了神经网络复苏的又一春。\r\n\r\n        \r\n\r\n图19 David Rumelhart（左）以及 Geoffery Hinton（右）\r\n\r\n \r\n\r\n　　2.结构\r\n\r\n　　两层神经网络除了包含一个输入层，一个输出层以外，还增加了一个中间层。此时，中间层和输出层都是计算层。我们扩展上节的单层神经网络，在右边新加一个层次（只含有一个节点）。\r\n\r\n　　现在，我们的权值矩阵增加到了两个，我们用上标来区分不同层次之间的变量。\r\n\r\n　　例如ax(y)代表第y层的第x个节点。z1，z2变成了a1(2)，a2(2)。下图给出了a1(2)，a2(2)的计算公式。\r\n\r\n\r\n\r\n图20 两层神经网络（中间层计算）\r\n\r\n \r\n\r\n　　计算最终输出z的方式是利用了中间层的a1(2)，a2(2)和第二个权值矩阵计算得到的，如下图。\r\n\r\n\r\n\r\n图21 两层神经网络（输出层计算）\r\n\r\n \r\n\r\n　　假设我们的预测目标是一个向量，那么与前面类似，只需要在“输出层”再增加节点即可。\r\n\r\n　　我们使用向量和矩阵来表示层次中的变量。a(1)，a(2)，z是网络中传输的向量数据。W(1)和W(2)是网络的矩阵参数。如下图。\r\n\r\n\r\n\r\n图22 两层神经网络（向量形式）\r\n\r\n \r\n\r\n　　使用矩阵运算来表达整个计算公式的话如下：\r\n\r\n  g(W(1) * a(1)) = a(2); \r\n\r\ng(W(2) * a(2)) = z;\r\n\r\n \r\n\r\n　　由此可见，使用矩阵运算来表达是很简洁的，而且也不会受到节点数增多的影响（无论有多少节点参与运算，乘法两端都只有一个变量）。因此神经网络的教程中大量使用矩阵运算来描述。\r\n\r\n　　需要说明的是，至今为止，我们对神经网络的结构图的讨论中都没有提到偏置节点（bias unit）。事实上，这些节点是默认存在的。它本质上是一个只含有存储功能，且存储值永远为1的单元。在神经网络的每个层次中，除了输出层以外，都会含有这样一个偏置单元。正如线性回归模型与逻辑回归模型中的一样。\r\n\r\n　　偏置单元与后一层的所有节点都有连接，我们设这些参数值为向量b，称之为偏置。如下图。\r\n\r\n\r\n\r\n图23 两层神经网络（考虑偏置节点）\r\n\r\n \r\n\r\n　　可以看出，偏置节点很好认，因为其没有输入（前一层中没有箭头指向它）。有些神经网络的结构图中会把偏置节点明显画出来，有些不会。一般情况下，我们都不会明确画出偏置节点。 \r\n\r\n　　在考虑了偏置以后的一个神经网络的矩阵运算如下：\r\n\r\n  g(W(1) * a(1) + b(1)) = a(2); \r\n\r\ng(W(2) * a(2) + b(2)) = z;\r\n\r\n \r\n\r\n　　需要说明的是，在两层神经网络中，我们不再使用sgn函数作为函数g，而是使用平滑函数sigmoid作为函数g。我们把函数g也称作激活函数（active function）。\r\n\r\n　　事实上，神经网络的本质就是通过参数与激活函数来拟合特征与目标之间的真实函数关系。初学者可能认为画神经网络的结构图是为了在程序中实现这些圆圈与线，但在一个神经网络的程序中，既没有“线”这个对象，也没有“单元”这个对象。实现一个神经网络最需要的是线性代数库。\r\n\r\n　　3.效果\r\n\r\n　　与单层神经网络不同。理论证明，两层神经网络可以无限逼近任意连续函数。\r\n\r\n　　这是什么意思呢？也就是说，面对复杂的非线性分类任务，两层（带一个隐藏层）神经网络可以分类的很好。\r\n\r\n　　下面就是一个例子（此两图来自colah的博客），红色的线与蓝色的线代表数据。而红色区域和蓝色区域代表由神经网络划开的区域，两者的分界线就是决策分界。\r\n\r\n\r\n\r\n图24 两层神经网络（决策分界）\r\n\r\n　　\r\n\r\n　　可以看到，这个两层神经网络的决策分界是非常平滑的曲线，而且分类的很好。有趣的是，前面已经学到过，单层网络只能做线性分类任务。而两层神经网络中的后一层也是线性分类层，应该只能做线性分类任务。为什么两个线性分类任务结合就可以做非线性分类任务？\r\n\r\n　　我们可以把输出层的决策分界单独拿出来看一下。就是下图。\r\n\r\n\r\n\r\n图25 两层神经网络（空间变换）\r\n\r\n \r\n\r\n　　可以看到，输出层的决策分界仍然是直线。关键就是，从输入层到隐藏层时，数据发生了空间变换。也就是说，两层神经网络中，隐藏层对原始的数据进行了一个空间变换，使其可以被线性分类，然后输出层的决策分界划出了一个线性分类分界线，对其进行分类。\r\n\r\n　　这样就导出了两层神经网络可以做非线性分类的关键--隐藏层。联想到我们一开始推导出的矩阵公式，我们知道，矩阵和向量相乘，本质上就是对向量的坐标空间进行一个变换。因此，隐藏层的参数矩阵的作用就是使得数据的原始坐标空间从线性不可分，转换成了线性可分。\r\n\r\n　　两层神经网络通过两层的线性模型模拟了数据内真实的非线性函数。因此，多层的神经网络的本质就是复杂函数拟合。\r\n\r\n　　下面来讨论一下隐藏层的节点数设计。在设计一个神经网络时，输入层的节点数需要与特征的维度匹配，输出层的节点数要与目标的维度匹配。而中间层的节点数，却是由设计者指定的。因此，“自由”把握在设计者的手中。但是，节点数设置的多少，却会影响到整个模型的效果。如何决定这个自由层的节点数呢？目前业界没有完善的理论来指导这个决策。一般是根据经验来设置。较好的方法就是预先设定几个可选值，通过切换这几个值来看整个模型的预测效果，选择效果最好的值作为最终选择。这种方法又叫做Grid Search（网格搜索）。\r\n\r\n　　了解了两层神经网络的结构以后，我们就可以看懂其它类似的结构图。例如EasyPR字符识别网络架构（下图）。\r\n\r\n\r\n\r\n图26 EasyPR字符识别网络\r\n\r\n \r\n\r\n　　EasyPR使用了字符的图像去进行字符文字的识别。输入是120维的向量。输出是要预测的文字类别，共有65类。根据实验，我们测试了一些隐藏层数目，发现当值为40时，整个网络在测试集上的效果较好，因此选择网络的最终结构就是120，40，65。\r\n\r\n　　4.训练\r\n\r\n　　下面简单介绍一下两层神经网络的训练。\r\n\r\n　　在Rosenblat提出的感知器模型中，模型中的参数可以被训练，但是使用的方法较为简单，并没有使用目前机器学习中通用的方法，这导致其扩展性与适用性非常有限。从两层神经网络开始，神经网络的研究人员开始使用机器学习相关的技术进行神经网络的训练。例如用大量的数据（1000-10000左右），使用算法进行优化等等，从而使得模型训练可以获得性能与数据利用上的双重优势。\r\n\r\n　　机器学习模型训练的目的，就是使得参数尽可能的与真实的模型逼近。具体做法是这样的。首先给所有参数赋上随机值。我们使用这些随机生成的参数值，来预测训练数据中的样本。样本的预测目标为yp，真实目标为y。那么，定义一个值loss，计算公式如下。\r\n\r\nloss = (yp - y)2\r\n\r\n \r\n\r\n　　这个值称之为损失（loss），我们的目标就是使对所有训练数据的损失和尽可能的小。\r\n\r\n　　如果将先前的神经网络预测的矩阵公式带入到yp中（因为有z=yp），那么我们可以把损失写为关于参数（parameter）的函数，这个函数称之为损失函数（loss function）。下面的问题就是求：如何优化参数，能够让损失函数的值最小。\r\n\r\n　　此时这个问题就被转化为一个优化问题。一个常用方法就是高等数学中的求导，但是这里的问题由于参数不止一个，求导后计算导数等于0的运算量很大，所以一般来说解决这个优化问题使用的是梯度下降算法。梯度下降算法每次计算参数在当前的梯度，然后让参数向着梯度的反方向前进一段距离，不断重复，直到梯度接近零时截止。一般这个时候，所有的参数恰好达到使损失函数达到一个最低值的状态。\r\n\r\n　　在神经网络模型中，由于结构复杂，每次计算梯度的代价很大。因此还需要使用反向传播算法。反向传播算法是利用了神经网络的结构进行的计算。不一次计算所有参数的梯度，而是从后往前。首先计算输出层的梯度，然后是第二个参数矩阵的梯度，接着是中间层的梯度，再然后是第一个参数矩阵的梯度，最后是输入层的梯度。计算结束以后，所要的两个参数矩阵的梯度就都有了。\r\n\r\n　　反向传播算法可以直观的理解为下图。梯度的计算从后往前，一层层反向传播。前缀E代表着相对导数的意思。\r\n\r\n\r\n\r\n图27 反向传播算法\r\n\r\n \r\n\r\n　　反向传播算法的启示是数学中的链式法则。在此需要说明的是，尽管早期神经网络的研究人员努力从生物学中得到启发，但从BP算法开始，研究者们更多地从数学上寻求问题的最优解。不再盲目模拟人脑网络是神经网络研究走向成熟的标志。正如科学家们可以从鸟类的飞行中得到启发，但没有必要一定要完全模拟鸟类的飞行方式，也能制造可以飞天的飞机。\r\n\r\n　　优化问题只是训练中的一个部分。机器学习问题之所以称为学习问题，而不是优化问题，就是因为它不仅要求数据在训练集上求得一个较小的误差，在测试集上也要表现好。因为模型最终是要部署到没有见过训练数据的真实场景。提升模型在测试集上的预测效果的主题叫做泛化（generalization），相关方法被称作正则化（regularization）。神经网络中常用的泛化技术有权重衰减等。\r\n\r\n　　5.影响\r\n\r\n　　两层神经网络在多个地方的应用说明了其效用与价值。10年前困扰神经网络界的异或问题被轻松解决。神经网络在这个时候，已经可以发力于语音识别，图像识别，自动驾驶等多个领域。\r\n\r\n　　历史总是惊人的相似，神经网络的学者们再次登上了《纽约时报》的专访。人们认为神经网络可以解决许多问题。就连娱乐界都开始受到了影响，当年的《终结者》电影中的阿诺都赶时髦地说一句：我的CPU是一个神经网络处理器，一个会学习的计算机。\r\n\r\n　　但是神经网络仍然存在若干的问题：尽管使用了BP算法，一次神经网络的训练仍然耗时太久，而且困扰训练优化的一个问题就是局部最优解问题，这使得神经网络的优化较为困难。同时，隐藏层的节点数需要调参，这使得使用不太方便，工程和研究人员对此多有抱怨。\r\n\r\n　　90年代中期，由Vapnik等人发明的SVM（Support Vector Machines，支持向量机）算法诞生，很快就在若干个方面体现出了对比神经网络的优势：无需调参；高效；全局最优解。基于以上种种理由，SVM迅速打败了神经网络算法成为主流。\r\n\r\n\r\n\r\n图28 Vladimir Vapnik\r\n\r\n \r\n\r\n　　神经网络的研究再次陷入了冰河期。当时，只要你的论文中包含神经网络相关的字眼，非常容易被会议和期刊拒收，研究界那时对神经网络的不待见可想而知。\r\n\r\n \r\n\r\n五. 多层神经网络（深度学习）\r\n\r\n　　1.引子　　\r\n\r\n　　在被人摒弃的10年中，有几个学者仍然在坚持研究。这其中的棋手就是加拿大多伦多大学的Geoffery Hinton教授。\r\n\r\n　　2006年，Hinton在《Science》和相关期刊上发表了论文，首次提出了“深度信念网络”的概念。与传统的训练方式不同，“深度信念网络”有一个“预训练”（pre-training）的过程，这可以方便的让神经网络中的权值找到一个接近最优解的值，之后再使用“微调”(fine-tuning)技术来对整个网络进行优化训练。这两个技术的运用大幅度减少了训练多层神经网络的时间。他给多层神经网络相关的学习方法赋予了一个新名词--“深度学习”。\r\n\r\n 　　很快，深度学习在语音识别领域暂露头角。接着，2012年，深度学习技术又在图像识别领域大展拳脚。Hinton与他的学生在ImageNet竞赛中，用多层的卷积神经网络成功地对包含一千类别的一百万张图片进行了训练，取得了分类错误率15%的好成绩，这个成绩比第二名高了近11个百分点，充分证明了多层神经网络识别效果的优越性。\r\n\r\n　　在这之后，关于深度神经网络的研究与应用不断涌现。\r\n\r\n\r\n\r\n图29 Geoffery Hinton \r\n\r\n \r\n\r\n　　由于篇幅原因，本文不介绍CNN（Conventional Neural Network，卷积神经网络）与RNN（Recurrent Neural Network，递归神经网络）的架构，下面我们只讨论普通的多层神经网络。\r\n\r\n　　2.结构\r\n\r\n　　我们延续两层神经网络的方式来设计一个多层神经网络。\r\n\r\n　　在两层神经网络的输出层后面，继续添加层次。原来的输出层变成中间层，新加的层次成为新的输出层。所以可以得到下图。\r\n\r\n\r\n\r\n图30 多层神经网络\r\n\r\n \r\n\r\n　　依照这样的方式不断添加，我们可以得到更多层的多层神经网络。公式推导的话其实跟两层神经网络类似，使用矩阵运算的话就仅仅是加一个公式而已。\r\n\r\n　　在已知输入a(1)，参数W(1)，W(2)，W(3)的情况下，输出z的推导公式如下：\r\n\r\n     g(W(1) * a(1)) = a(2); \r\n\r\n    g(W(2) * a(2)) = a(3);\r\n\r\ng(W(3) * a(3)) = z;\r\n\r\n \r\n\r\n　　多层神经网络中，输出也是按照一层一层的方式来计算。从最外面的层开始，算出所有单元的值以后，再继续计算更深一层。只有当前层所有单元的值都计算完毕以后，才会算下一层。有点像计算向前不断推进的感觉。所以这个过程叫做“正向传播”。\r\n\r\n　　下面讨论一下多层神经网络中的参数。\r\n\r\n　　首先我们看第一张图，可以看出W(1)中有6个参数，W(2)中有4个参数，W(3)中有6个参数，所以整个神经网络中的参数有16个（这里我们不考虑偏置节点，下同）。\r\n\r\n \r\n\r\n图31 多层神经网络（较少参数）\r\n\r\n \r\n\r\n　　假设我们将中间层的节点数做一下调整。第一个中间层改为3个单元，第二个中间层改为4个单元。\r\n\r\n　　经过调整以后，整个网络的参数变成了33个。\r\n\r\n \r\n\r\n图32 多层神经网络（较多参数）\r\n\r\n \r\n\r\n　　虽然层数保持不变，但是第二个神经网络的参数数量却是第一个神经网络的接近两倍之多，从而带来了更好的表示（represention）能力。表示能力是多层神经网络的一个重要性质，下面会做介绍。\r\n\r\n　　在参数一致的情况下，我们也可以获得一个“更深”的网络。\r\n\r\n \r\n\r\n图33 多层神经网络（更深的层次）\r\n\r\n \r\n\r\n　　上图的网络中，虽然参数数量仍然是33，但却有4个中间层，是原来层数的接近两倍。这意味着一样的参数数量，可以用更深的层次去表达。\r\n\r\n　　3.效果\r\n\r\n　　与两层层神经网络不同。多层神经网络中的层数增加了很多。\r\n\r\n　　增加更多的层次有什么好处？更深入的表示特征，以及更强的函数模拟能力。\r\n\r\n　　更深入的表示特征可以这样理解，随着网络的层数增加，每一层对于前一层次的抽象表示更深入。在神经网络中，每一层神经元学习到的是前一层神经元值的更抽象的表示。例如第一个隐藏层学习到的是“边缘”的特征，第二个隐藏层学习到的是由“边缘”组成的“形状”的特征，第三个隐藏层学习到的是由“形状”组成的“图案”的特征，最后的隐藏层学习到的是由“图案”组成的“目标”的特征。通过抽取更抽象的特征来对事物进行区分，从而获得更好的区分与分类能力。\r\n\r\n　　关于逐层特征学习的例子，可以参考下图。\r\n\r\n \r\n\r\n图34 多层神经网络（特征学习）\r\n\r\n \r\n\r\n　　更强的函数模拟能力是由于随着层数的增加，整个网络的参数就越多。而神经网络其实本质就是模拟特征与目标之间的真实关系函数的方法，更多的参数意味着其模拟的函数可以更加的复杂，可以有更多的容量（capcity）去拟合真正的关系。\r\n\r\n　　通过研究发现，在参数数量一样的情况下，更深的网络往往具有比浅层的网络更好的识别效率。这点也在ImageNet的多次大赛中得到了证实。从2012年起，每年获得ImageNet冠军的深度神经网络的层数逐年增加，2015年最好的方法GoogleNet是一个多达22层的神经网络。\r\n\r\n　　在最新一届的ImageNet大赛上，目前拿到最好成绩的MSRA团队的方法使用的更是一个深达152层的网络！关于这个方法更多的信息有兴趣的可以查阅ImageNet网站。\r\n\r\n　　4.训练\r\n\r\n　　在单层神经网络时，我们使用的激活函数是sgn函数。到了两层神经网络时，我们使用的最多的是sigmoid函数。而到了多层神经网络时，通过一系列的研究发现，ReLU函数在训练多层神经网络时，更容易收敛，并且预测性能更好。因此，目前在深度学习中，最流行的非线性函数是ReLU函数。ReLU函数不是传统的非线性函数，而是分段线性函数。其表达式非常简单，就是y=max(x,0)。简而言之，在x大于0，输出就是输入，而在x小于0时，输出就保持为0。这种函数的设计启发来自于生物神经元对于激励的线性响应，以及当低于某个阈值后就不再响应的模拟。\r\n\r\n　　在多层神经网络中，训练的主题仍然是优化和泛化。当使用足够强的计算芯片（例如GPU图形加速卡）时，梯度下降算法以及反向传播算法在多层神经网络中的训练中仍然工作的很好。目前学术界主要的研究既在于开发新的算法，也在于对这两个算法进行不断的优化，例如，增加了一种带动量因子（momentum）的梯度下降算法。　\r\n\r\n　　在深度学习中，泛化技术变的比以往更加的重要。这主要是因为神经网络的层数增加了，参数也增加了，表示能力大幅度增强，很容易出现过拟合现象。因此正则化技术就显得十分重要。目前，Dropout技术，以及数据扩容（Data-Augmentation）技术是目前使用的最多的正则化技术。\r\n\r\n　　5.影响\r\n\r\n　　目前，深度神经网络在人工智能界占据统治地位。但凡有关人工智能的产业报道，必然离不开深度学习。神经网络界当下的四位引领者除了前文所说的Ng，Hinton以外，还有CNN的发明人Yann Lecun，以及《Deep Learning》的作者Bengio。\r\n\r\n　　前段时间一直对人工智能持谨慎态度的马斯克，搞了一个OpenAI项目，邀请Bengio作为高级顾问。马斯克认为，人工智能技术不应该掌握在大公司如Google，Facebook的手里，更应该作为一种开放技术，让所有人都可以参与研究。马斯克的这种精神值得让人敬佩。\r\n\r\n   \r\n\r\n图35 Yann LeCun（左）和 Yoshua Bengio（右）\r\n\r\n \r\n\r\n　　多层神经网络的研究仍在进行中。现在最为火热的研究技术包括RNN，LSTM等，研究方向则是图像理解方面。图像理解技术是给计算机一幅图片，让它用语言来表达这幅图片的意思。ImageNet竞赛也在不断召开，有更多的方法涌现出来，刷新以往的正确率。\r\n\r\n \r\n\r\n六. 回顾\r\n\r\n　　1.影响　　\r\n\r\n　　我们回顾一下神经网络发展的历程。神经网络的发展历史曲折荡漾，既有被人捧上天的时刻，也有摔落在街头无人问津的时段，中间经历了数次大起大落。\r\n\r\n　　从单层神经网络（感知器）开始，到包含一个隐藏层的两层神经网络，再到多层的深度神经网络，一共有三次兴起过程。详见下图。\r\n\r\n \r\n\r\n图36 三起三落的神经网络\r\n\r\n \r\n\r\n　　上图中的顶点与谷底可以看作神经网络发展的高峰与低谷。图中的横轴是时间，以年为单位。纵轴是一个神经网络影响力的示意表示。如果把1949年Hebb模型提出到1958年的感知机诞生这个10年视为落下（没有兴起）的话，那么神经网络算是经历了“三起三落”这样一个过程，跟“小平”同志类似。俗话说，天将降大任于斯人也，必先苦其心志，劳其筋骨。经历过如此多波折的神经网络能够在现阶段取得成功也可以被看做是磨砺的积累吧。\r\n\r\n　　历史最大的好处是可以给现在做参考。科学的研究呈现螺旋形上升的过程，不可能一帆风顺。同时，这也给现在过分热衷深度学习与人工智能的人敲响警钟，因为这不是第一次人们因为神经网络而疯狂了。1958年到1969年，以及1985年到1995，这两个十年间人们对于神经网络以及人工智能的期待并不现在低，可结果如何大家也能看的很清楚。\r\n\r\n　　因此，冷静才是对待目前深度学习热潮的最好办法。如果因为深度学习火热，或者可以有“钱景”就一窝蜂的涌入，那么最终的受害人只能是自己。神经网络界已经两次有被人们捧上天了的境况，相信也对于捧得越高，摔得越惨这句话深有体会。因此，神经网络界的学者也必须给这股热潮浇上一盆水，不要让媒体以及投资家们过分的高看这门技术。很有可能，三十年河东，三十年河西，在几年后，神经网络就再次陷入谷底。根据上图的历史曲线图，这是很有可能的。\r\n\r\n　　2.效果　　\r\n\r\n　　下面说一下神经网络为什么能这么火热？简而言之，就是其学习效果的强大。随着神经网络的发展，其表示性能越来越强。\r\n\r\n　　从单层神经网络，到两层神经网络，再到多层神经网络，下图说明了，随着网络层数的增加，以及激活函数的调整，神经网络所能拟合的决策分界平面的能力。\r\n\r\n \r\n\r\n图37 表示能力不断增强\r\n\r\n \r\n\r\n　　可以看出，随着层数增加，其非线性分界拟合能力不断增强。图中的分界线并不代表真实训练出的效果，更多的是示意效果。\r\n\r\n　　神经网络的研究与应用之所以能够不断地火热发展下去，与其强大的函数拟合能力是分不开关系的。\r\n\r\n　　3.外因　　\r\n\r\n　　当然，光有强大的内在能力，并不一定能成功。一个成功的技术与方法，不仅需要内因的作用，还需要时势与环境的配合。神经网络的发展背后的外在原因可以被总结为：更强的计算性能，更多的数据，以及更好的训练方法。只有满足这些条件时，神经网络的函数拟合能力才能得已体现，见下图。\r\n\r\n \r\n\r\n图38 发展的外在原因\r\n\r\n \r\n\r\n　　之所以在单层神经网络年代，Rosenblat无法制作一个双层分类器，就在于当时的计算性能不足，Minsky也以此来打压神经网络。但是Minsky没有料到，仅仅10年以后，计算机CPU的快速发展已经使得我们可以做两层神经网络的训练，并且还有快速的学习算法BP。\r\n\r\n　　但是在两层神经网络快速流行的年代。更高层的神经网络由于计算性能的问题，以及一些计算方法的问题，其优势无法得到体现。直到2012年，研究人员发现，用于高性能计算的图形加速卡（GPU）可以极佳地匹配神经网络训练所需要的要求：高并行性，高存储，没有太多的控制需求，配合预训练等算法，神经网络才得以大放光彩。\r\n\r\n　　互联网时代，大量的数据被收集整理，更好的训练方法不断被发现。所有这一切都满足了多层神经网络发挥能力的条件。\r\n\r\n　　“时势造英雄”，正如Hinton在2006年的论文里说道的\r\n\r\n　　“... provided that computers were fast enough, data sets were big enough, and the initial weights were close enough to a good solution. All three conditions are now satisfied.”，\r\n\r\n \r\n\r\n　　外在条件的满足也是神经网络从神经元得以发展到目前的深度神经网络的重要因素。\r\n\r\n　　除此以外，一门技术的发扬没有“伯乐”也是不行的。在神经网络漫长的历史中，正是由于许多研究人员的锲而不舍，不断钻研，才能有了现在的成就。前期的Rosenblat，Rumelhart没有见证到神经网络如今的流行与地位。但是在那个时代，他们为神经网络的发展所打下的基础，却会永远流传下去，不会退色。\r\n\r\n \r\n\r\n七. 展望\r\n\r\n　　1.量子计算\r\n\r\n　　回到我们对神经网络历史的讨论，根据历史趋势图来看，神经网络以及深度学习会不会像以往一样再次陷入谷底？作者认为，这个过程可能取决于量子计算机的发展。\r\n\r\n　　根据一些最近的研究发现，人脑内部进行的计算可能是类似于量子计算形态的东西。而且目前已知的最大神经网络跟人脑的神经元数量相比，仍然显得非常小，仅不及1%左右。所以未来真正想实现人脑神经网络的模拟，可能需要借助量子计算的强大计算能力。\r\n\r\n　　各大研究组也已经认识到了量子计算的重要性。谷歌就在开展量子计算机D-wave的研究，希望用量子计算来进行机器学习，并且在前段时间有了突破性的进展。国内方面，阿里和中科院合作成立了量子计算实验室，意图进行量子计算的研究。\r\n\r\n　　如果量子计算发展不力，仍然需要数十年才能使我们的计算能力得以突飞猛进的发展，那么缺少了强大计算能力的神经网络可能会无法一帆风顺的发展下去。这种情况可以类比为80-90年时期神经网络因为计算能力的限制而被低估与忽视。假设量子计算机真的能够与神经网络结合，并且助力真正的人工智能技术的诞生，而且量子计算机发展需要10年的话，那么神经网络可能还有10年的发展期。直到那时期以后，神经网络才能真正接近实现AI这一目标。\r\n\r\n \r\n\r\n图39 量子计算\r\n\r\n \r\n\r\n　　2.人工智能\r\n\r\n　　最后，作者想简单地谈谈对目前人工智能的看法。虽然现在人工智能非常火热，但是距离真正的人工智能还有很大的距离。就拿计算机视觉方向来说，面对稍微复杂一些的场景，以及易于混淆的图像，计算机就可能难以识别。因此，这个方向还有很多的工作要做。\r\n\r\n　　就普通人看来，这么辛苦的做各种实验，以及投入大量的人力就是为了实现一些不及孩童能力的视觉能力，未免有些不值。但是这只是第一步。虽然计算机需要很大的运算量才能完成一个普通人简单能完成的识图工作，但计算机最大的优势在于并行化与批量推广能力。使用计算机以后，我们可以很轻易地将以前需要人眼去判断的工作交给计算机做，而且几乎没有任何的推广成本。这就具有很大的价值。正如火车刚诞生的时候，有人嘲笑它又笨又重，速度还没有马快。但是很快规模化推广的火车就替代了马车的使用。人工智能也是如此。这也是为什么目前世界上各著名公司以及政府都对此热衷的原因。\r\n\r\n　　目前看来，神经网络要想实现人工智能还有很多的路要走，但方向至少是正确的，下面就要看后来者的不断努力了。\r\n\r\n\r\n\r\n图40 人工智能\r\n\r\n \r\n\r\n八 总结\r\n\r\n　　本文回顾了神经网络的发展历史，从神经元开始，历经单层神经网络，两层神经网络，直到多层神经网络。在历史介绍中穿插讲解神经网络的结构，分类效果以及训练方法等。本文说明了神经网络内部实际上就是矩阵计算，在程序中的实现没有“点”和“线”的对象。本文说明了神经网络强大预测能力的根本，就是多层的神经网络可以无限逼近真实的对应函数，从而模拟数据之间的真实关系。除此之外，本文回顾了神经网络发展的历程，分析了神经网络发展的外在原因，包括计算能力的增强，数据的增多，以及方法的创新等。最后，本文对神经网络的未来进行了展望，包括量子计算与神经网络结合的可能性，以及探讨未来人工智能发展的前景与价值。\r\n\r\n \r\n\r\n九. 后记\r\n\r\n　　本篇文章可以视为作者一年来对神经网络的理解与总结，包括实验的体会，书籍的阅读，以及思考的火花等。神经网络虽然重要，但学习并不容易。这主要是由于其结构图较为难懂，以及历史发展的原因，导致概念容易混淆，一些介绍的博客与网站内容新旧不齐。本篇文章着眼于这些问题，没有太多的数学推导，意图以一种简单的，直观的方式对神经网络进行讲解。在2015年最后一天终于写完。希望本文可以对各位有所帮助。\r\n\r\n \r\n\r\n \r\n\r\n　　作者很感谢能够阅读到这里的读者。如果看完觉得好的话，还请轻轻点一下赞，你们的鼓励就是作者继续行文的动力。本文的备注部分是一些对神经网络学习的建议，供补充阅读与参考。\r\n\r\n　　\r\n\r\n　　目前为止，EasyPR的1.4版已经将神经网络（ANN）训练的模块加以开放，开发者们可以使用这个模块来进行自己的字符模型的训练。有兴趣的可以下载。\r\n\r\n \r\n\r\n十. 备注\r\n\r\n　　神经网络虽然很重要，但是对于神经网络的学习，却并不容易。这些学习困难主要来自以下三个方面：概念，类别，教程。下面简单说明这三点。\r\n\r\n　　1.概念\r\n\r\n　　对于一门技术的学习而言，首先最重要的是弄清概念。只有将概念理解清楚，才能顺畅的进行后面的学习。由于神经网络漫长的发展历史，经常会有一些概念容易混淆，让人学习中产生困惑。这里面包括历史的术语，不一致的说法，以及被遗忘的研究等。　\r\n\r\n　　历史的术语\r\n\r\n　　这个的代表就是多层感知器（MLP）这个术语。起初看文献时很难理解的一个问题就是，为什么神经网络又有另一个名称：MLP。其实MLP（Multi-Layer Perceptron）的名称起源于50-60年代的感知器（Perceptron）。由于我们在感知器之上又增加了一个计算层，因此称为多层感知器。值得注意的是，虽然叫“多层”，MLP一般都指的是两层（带一个隐藏层的）神经网络。\r\n\r\n　　MLP这个术语属于历史遗留的产物。现在我们一般就说神经网络，以及深度神经网络。前者代表带一个隐藏层的两层神经网络，也是EasyPR目前使用的识别网络，后者指深度学习的网络。\r\n\r\n　　不一致的说法\r\n\r\n　　这个最明显的代表就是损失函数loss function，这个还有两个说法是跟它完全一致的意思，分别是残差函数error function，以及代价函数cost function。loss function是目前深度学习里用的较多的一种说法，caffe里也是这么叫的。cost function则是Ng在coursera教学视频里用到的统一说法。这三者都是同一个意思，都是优化问题所需要求解的方程。虽然在使用的时候不做规定，但是在听到各种讲解时要心里明白。\r\n\r\n　　再来就是权重weight和参数parameter的说法，神经网络界由于以前的惯例，一般会将训练得到的参数称之为权重，而不像其他机器学习方法就称之为参数。这个需要记住就好。不过在目前的使用惯例中，也有这样一种规定。那就是非偏置节点连接上的值称之为权重，而偏置节点上的值称之为偏置，两者统一起来称之为参数。\r\n\r\n　　另外一个同义词就是激活函数active function和转移函数transfer function了。同样，他们代表一个意思，都是叠加的非线性函数的说法。\r\n\r\n　　被遗忘的研究\r\n\r\n　　由于神经网络发展历史已经有70年的漫长历史，因此在研究过程中，必然有一些研究分支属于被遗忘阶段。这里面包括各种不同的网络，例如SOM（Self-Organizing Map，自组织特征映射网络），SNN（Synergetic Neural Network，协同神经网络），ART（Adaptive Resonance Theory，自适应共振理论网络）等等。所以看历史文献时会看到许多没见过的概念与名词。\r\n\r\n　　有些历史网络甚至会重新成为新的研究热点，例如RNN与LSTM就是80年代左右开始的研究，目前已经是深度学习研究中的重要一门技术，在语音与文字识别中有很好的效果。　\r\n\r\n　　对于这些易于混淆以及弄错的概念，务必需要多方参考文献，理清上下文，这样才不会在学习与阅读过程中迷糊。\r\n\r\n　　2.类别\r\n\r\n　　下面谈一下关于神经网络中的不同类别。\r\n\r\n　　其实本文的名字“神经网络浅讲”并不合适，因为本文并不是讲的是“神经网络”的内容，而是其中的一个子类，也是目前最常说的前馈神经网络。根据下图的分类可以看出。\r\n\r\n \r\n\r\n图41 神经网络的类别\r\n\r\n \r\n\r\n　　神经网络其实是一个非常宽泛的称呼，它包括两类，一类是用计算机的方式去模拟人脑，这就是我们常说的ANN（人工神经网络），另一类是研究生物学上的神经网络，又叫生物神经网络。对于我们计算机人士而言，肯定是研究前者。\r\n\r\n　　在人工神经网络之中，又分为前馈神经网络和反馈神经网络这两种。那么它们两者的区别是什么呢？这个其实在于它们的结构图。我们可以把结构图看作是一个有向图。其中神经元代表顶点，连接代表有向边。对于前馈神经网络中，这个有向图是没有回路的。你可以仔细观察本文中出现的所有神经网络的结构图，确认一下。而对于反馈神经网络中，结构图的有向图是有回路的。反馈神经网络也是一类重要的神经网络。其中Hopfield网络就是反馈神经网络。深度学习中的RNN也属于一种反馈神经网络。\r\n\r\n　　具体到前馈神经网络中，就有了本文中所分别描述的三个网络：单层神经网络，双层神经网络，以及多层神经网络。深度学习中的CNN属于一种特殊的多层神经网络。另外，在一些Blog中和文献中看到的BP神经网络是什么？其实它们就是使用了反向传播BP算法的两层前馈神经网络。也是最普遍的一种两层神经网络。\r\n\r\n　　通过以上分析可以看出，神经网络这种说法其实是非常广义的，具体在文章中说的是什么网络，需要根据文中的内容加以区分。\r\n\r\n　　3.教程\r\n\r\n　　如何更好的学习神经网络，认真的学习一门课程或者看一本著作都是很有必要的。\r\n\r\n　　说到网络教程的话，这里必须说一下Ng的机器学习课程。对于一个初学者而言，Ng的课程视频是非常有帮助的。Ng一共开设过两门机器学习公开课程：一个是2003年在Standford开设的，面向全球的学生，这个视频现在可以在网易公开课上找到；另一个是2010年专门为Coursera上的用户开设的，需要登陆Coursera上才能学习。\r\n\r\n　　但是，需要注意点是，这两个课程对待神经网络的态度有点不同。早些的课程一共有20节课，Ng花了若干节课去专门讲SVM以及SVM的推导，而当时的神经网络，仅仅放了几段视频，花了大概不到20分钟（一节课60分钟左右）。而到了后来的课程时，总共10节的课程中，Ng给了完整的两节给神经网络，详细介绍了神经网络的反向传播算法。同时给SVM只有一节课，并且没有再讲SVM的推导过程。下面两张图分别是Ng介绍神经网络的开篇，可以大致看出一些端倪。\r\n\r\n \r\n\r\n图42 Ng与神经网络\r\n\r\n \r\n\r\n　　为什么Ng对待神经网络的反应前后相差那么大？事实上就是深度学习的原因。Ng实践了深度学习的效果，认识到深度学习的基础--神经网络的重要性。这就是他在后面重点介绍神经网络的原因。总之，对于神经网络的学习而言，我更推荐Coursera上的。因为在那个时候，Ng才是真正的把神经网络作为一门重要的机器学习方法去传授。你可以从他上课的态度中感受到他的重视，以及他希望你能学好的期望。', 0, 0, 0, 1, '2021-05-08 11:32:27', 3, 1);
INSERT INTO `article` VALUES (14, '自动驾驶实战系列(一)——利用NDT算法构建点云地图', NULL, '# 自动驾驶实战系列(一)——利用NDT算法构建点云地图\r\n\r\n作为系列的第一篇，主要讲解室外构建点云地图的常用方法，以及基本原理和实现。主要是一个基于NDT的激光里程计，然后配合IMU/Odom/Gps等传感器提供的初值，完成地图构建。\r\n\r\n![image-20200122134145413](31ndt-map/image-20200122134145413.png)\r\n\r\n<!-- more-->\r\n\r\nNDT算法原理见之前的博客(参考别人的，待修订)\r\n\r\n<a href=\"http://xchu.net/2019/09/14/NDT%E5%8E%9F%E7%90%86%E6%8E%A8%E5%AF%BC/\"  class=\"LinkCard\">NDT原理推导</a>\r\n\r\n阅读马丁博士以下几篇文章，第一篇是其博士论文，ndt的求解过程介绍十分详细，我仔细留意了下马丁博士的个人主页，他在09年博士毕业之后到现在，期间的十年也有好几篇NDT相关的文章发表，大家可以留意下。\r\n\r\n> 1. **Doctoral Thesis**：The Three-Dimensional Normal-Distributions Transform —an Efficient Representation for Registration, Surface Analysis, and Loop Detection\r\n> 2. 2009_ICRA_Appearance-Based Loop Detection from 3D Laser Data\r\n> 3. 2003_IROS_The Normal Distributions Transform A New Approach to Laser Scan\r\n\r\n在高精地图制作的环节中，制作点云地图是第一步，本章我们主要应用`NDT（Normal Distributions Transform`，正态分布变换）完成点云地图的构建。当然点云地图的构建方法还有很多，比如`LOAM系列(VLOAM/ALOAM/LEGO LOAM)`等各种激光slam方法。本篇我们将完成一个激光里程计，无回环，所以制图效果会比较粗糙，后续的文章会逐渐加入。基础代码来源于Autoware，个人将其剥离出来，加上一些修改，作为单独的ros模块，方便个人理解。\r\n\r\n​	我的激光雷达型号Robosense 16，mapping过程是离线的，对电脑性能要求较高，并且内存尽量大。\r\n\r\n​	这里说明一点，自动驾驶里面的建图和定位，是与机器人领域中的slam有一定的区别。后者要求实时，所以会注重一些性能和精度的平衡，但自动驾驶的定位一般是基于地图的，所以**地图是离线制作的，精度越高越好**，而不太注重性能。虽说自动驾驶汽车在运动过程中很少存在回环的情况，但**回环对于提升建图精度**十分重要，所以采集地图数据的时候需要多跑两圈，这点不要混淆。\r\n\r\n## 整体思路\r\n\r\n代码的整体逻辑很清晰，主要围绕以下两个部分展开\r\n\r\n- 获取初值（除lidar外的各种传感器callback）\r\n- 更新transform（当前位置到原点的transform）\r\n\r\n**scan to scan**\r\n\r\n​	将连续帧激光点云进行ndt配准，得到两帧转换的transform，包含平移T和旋转矩阵R。若匹配成功，则将配准结果作为下一帧点云配准的初值。可得到当前的pose，进而可求相对于起始帧的transform，可将当前帧点云对齐到坐标原点，逐帧降采样加入map中，即可完成地图构建。纯lidar计算的最终变换肯定会存在累计误差，这里我们的传感器还有odom、imu，可以利用其提供ndt配准的初值，理论上会显著改善这一情况。\r\n\r\n**保存map**\r\n\r\n​	这里一般通过slam算法完成的是特征点地图，或者是降采样之后的地图．如果想要构建高精地图，并且是通过手工标注的方式完成，那么我们就需要构建稠密的点云地图。构建稠密地图和构建普通的特征点地图方法都是差不多，得到每一帧相对于原点的transform之后，去除此帧过远过近的噪点部分，把关键帧加入map。这里**建议保留当前帧pcd，以及其对应的pose（时间戳），在地图的后处理部分作用很大，比如可以用ndt算法将制作好的点云地图进行压缩，网格化之后，每个网格保存点的均值和协方差，还可以保存高度均值-协方差，强度均值-协方差，进而大大压缩地图体积，可用来制作概率地图。**\r\n\r\n\r\n## CallBack\r\n\r\n在本篇的建图中，会用到一些其他的传感器比如imu/odom/gps数据，也可以用纯lidar，只是用到了传感器的相关数据作为辅助，谈不上融合。\r\n\r\n### Sub and Pub\r\n\r\n订阅相关话题，包括lidar/odom/imu，发布出来的有当前的当前已构建好的map话题/ndt_map，当前的激光点云/current_points，以及当前车辆运动的odometry话题/ndt_odom．\r\n\r\n```c++\r\nndt_map_pub = nh.advertise<sensor_msgs::PointCloud2>(\"/ndt_map\", 5);\r\n//		dense_map_pub = nh.advertise<sensor_msgs::PointCloud2>(\"/dense_map\", 1000);\r\nodom_pub = nh.advertise<nav_msgs::Odometry>(\"/ndt_odom\", 5, false);\r\ncurrent_points_pub = nh.advertise<sensor_msgs::PointCloud2>(\"/current_points\", 5);\r\n\r\npoints_sub = nh.subscribe(_lidar_topic, 5, &LidarMapping::points_callback, this);\r\nodom_sub = nh.subscribe(_odom_topic, 5, &LidarMapping::odom_callback, this);\r\nimu_sub = nh.subscribe(_imu_topic, 5, &LidarMapping::imu_callback, this);\r\n```\r\n\r\n### PointCloud\r\n\r\n**预处理**\r\n\r\n对于激光雷达,其过近的点由于落在车体上,过远的点已经非常稀疏,因此都需要被过滤掉。\r\n\r\n```c++\r\n// tmp为初始点云，截取有效范围内的点存到scan中\r\nfor (auto point:tmp.points) {\r\n    r = std::sqrt(pow(point.x, 2.0) + pow(point.y, 2.0));\r\n    if (min_scan_range < r && r < max_scan_range) {\r\n        scan.points.push_back(point);\r\n    }\r\n}\r\npcl::PointCloud<pcl::PointXYZI>::Ptr scan_ptr(new pcl::PointCloud<pcl::PointXYZI>(scan));  // scan保存到scan_ptr中\r\n```\r\n\r\n同时把第一帧激光点云加入map中，initial_scan_loaded标记这里是第一帧激光点云，后续的点云配准完成后直接加入map中来。\r\n\r\n\r\n```c++\r\n  if (initial_scan_loaded == 0)\r\n  {\r\n    pcl::transformPointCloud(*scan_ptr, *transformed_scan_ptr, tf_btol); \r\n    map += *transformed_scan_ptr;\r\n    initial_scan_loaded = 1;\r\n  }\r\n```\r\n\r\n这里的tf_btol是初始设定的，初始化tf_btol以获得初始变换矩阵，当车辆初始的起点不在预定义的globalMap原点时，就需要tf_btol了，后面配准的时候都是相对于localMap的原点，因此tf_ltob.inv将作为补偿的矩阵\r\n\r\n\r\n```c++\r\n// 根据初始设定的_tf,_roll等,初始化tl_btol rot_x_btol等\r\nEigen::Translation3f tl_btol(_tf_x, _tf_y, _tf_z);                \r\nEigen::AngleAxisf rot_x_btol(_tf_roll, Eigen::Vector3f::UnitX());  // rot: rotation\r\nEigen::AngleAxisf rot_y_btol(_tf_pitch, Eigen::Vector3f::UnitY());\r\nEigen::AngleAxisf rot_z_btol(_tf_yaw, Eigen::Vector3f::UnitZ());\r\n\r\ntf_btol = (tl_btol * rot_z_btol * rot_y_btol * rot_x_btol).matrix();\r\ntf_ltob = tf_btol.inverse();  // 将tf_btol取逆\r\n```\r\n\r\n**降采样**\r\n\r\n```c++\r\n//  用voxelgrid对点云进行降采样，存入filtered_scan_ptr\r\npcl::VoxelGrid<pcl::PointXYZI> voxel_grid_filter;\r\nvoxel_grid_filter.setLeafSize(voxel_leaf_size, voxel_leaf_size, voxel_leaf_size);\r\nvoxel_grid_filter.setInputCloud(scan_ptr);\r\nvoxel_grid_filter.filter(*filtered_scan_ptr);\r\n```\r\n\r\n### IMU\r\n\r\n这里imu数据在使用之前，需要确定一下方向，是否需要进行坐标轴的正负变换．只需要保证imu测量而得实时的yaw角和车头方向基本保持一致．这里特别需要注意，通**常我们在汽车上使用的imu分六轴和九轴的，九轴的imu是带有地磁仪的，那么imu测量的yaw角就是相当于地球正北方向的夹角，即为车头方向，数据可直接使用。如果是六轴的，那么测量出来的yaw角是相对于车身的，不能直接作为车头方向，需要计算连续帧的增量数据才能使用。对于组合导航而言，一般搭载的imu是六轴的，但是由于GPS双天线，可以得到正北的方向，最终融合输出的yaw角为和正北方向的夹角，能够直接使用。**\r\n\r\n​	这里我们需要自己的传感器设备有一个清楚的了解，可以参考我的第三篇文章，测试一下IMU的朝向问题。\r\n\r\n<a href=\"http://xchu.net/2020/01/10/37gnss-localizer/#more\"  class=\"LinkCard\">自动驾驶实战系列(四)——地理与平面坐标系对齐及INS数据可视化</a>\r\n\r\n```c++\r\nvoid imu_callback(const sensor_msgs::Imu::Ptr &input) {\r\n    if (_imu_upside_down)  // _imu_upside_down指示是否进行imu的正负变换\r\n        imuUpSideDown(input);\r\n\r\n    const ros::Time current_time = input->header.stamp;\r\n    static ros::Time previous_time = current_time;\r\n    const double diff_time = (current_time - previous_time).toSec();\r\n\r\n    // 解析imu消息,获得rpy\r\n    double imu_roll, imu_pitch, imu_yaw;\r\n    tf::Quaternion imu_orientation;\r\n    tf::quaternionMsgToTF(input->orientation, imu_orientation);\r\n    tf::Matrix3x3(imu_orientation).getRPY(imu_roll, imu_pitch, imu_yaw);\r\n\r\n    imu_roll = warpToPmPi(imu_roll);  // 保持在±180°内，角度转弧度\r\n    imu_pitch = warpToPmPi(imu_pitch);\r\n    imu_yaw = warpToPmPi(imu_yaw);\r\n\r\n    static double previous_imu_roll = imu_roll, previous_imu_pitch = imu_pitch, previous_imu_yaw = imu_yaw;\r\n    const double diff_imu_roll = calcDiffForRadian(imu_roll, previous_imu_roll);\r\n    const double diff_imu_pitch = calcDiffForRadian(imu_pitch, previous_imu_pitch);\r\n    const double diff_imu_yaw = calcDiffForRadian(imu_yaw, previous_imu_yaw);\r\n\r\n    imu.header = input->header;//瞬时加速度只考虑x方向\r\n    imu.linear_acceleration.x = input->linear_acceleration.x;\r\n    // imu.linear_acceleration.y = input->linear_acceleration.y;\r\n    // imu.linear_acceleration.z = input->linear_acceleration.z;\r\n    imu.linear_acceleration.y = 0;\r\n    imu.linear_acceleration.z = 0;\r\n\r\n    if (diff_time != 0) {\r\n        imu.angular_velocity.x = diff_imu_roll / diff_time;\r\n        imu.angular_velocity.y = diff_imu_pitch / diff_time;\r\n        imu.angular_velocity.z = diff_imu_yaw / diff_time;\r\n    } else {\r\n        imu.angular_velocity.x = 0;\r\n        imu.angular_velocity.y = 0;\r\n        imu.angular_velocity.z = 0;\r\n    }\r\n\r\n    imu_calc(input->header.stamp);//后面详细讲解\r\n\r\n    previous_time = current_time;\r\n    previous_imu_roll = imu_roll;\r\n    previous_imu_pitch = imu_pitch;\r\n    previous_imu_yaw = imu_yaw;\r\n}\r\n```\r\n\r\n### ODOM\r\n\r\n```c++\r\nvoid odom_callback(const nav_msgs::Odometry::ConstPtr &input) {\r\n    odom = *input;\r\n    odom_calc(input->header.stamp);//后续讲解\r\n}\r\n```\r\n\r\n### GPS\r\n\r\n如果有GPS当然也可以用GPS来提供初值，这里有些GPS会提供heading角和位置，有些则只有位置。有heading角的更准，只有位置也没关系，**通过连续的位置坐标，也可以计算一个平面运动的yaw角**，这种计算方法在我的系列博客中经常提到，这里只给出基本的代码，转换成T矩阵部分就参考之前的代码即可。\r\n\r\n**无heading**\r\n\r\n```c++\r\ngeometry_msgs::PoseStamped pose;\r\npose.header = msg.header;\r\npose.header.stamp = msg.header.stamp;\r\npose.header.frame_id = \"map\";\r\npose.pose.position.x = gps_pos_(0); //gps位置\r\npose.pose.position.y = gps_pos_(1);\r\npose.pose.position.z = gps_pos_(2);\r\n\r\n//  仅依靠位置点，计算yaw\r\ndouble distance = sqrt(pow(pose.pose.position.y - _prev_pose.pose.position.y, 2) + pow(pose.pose.position.x - _prev_pose.pose.position.x, 2));\r\nif (distance > 0.2)\r\n{\r\n    // 返回值是此点与远点连线与x轴正方向的夹角\r\n    yaw = atan2(pose.pose.position.y - _prev_pose.pose.position.y, pose.pose.position.x - _prev_pose.pose.position.x);\r\n    _quat = tf::createQuaternionMsgFromYaw(yaw);\r\n    _prev_pose = pose;\r\n}\r\npose.pose.orientation = _quat;　//yaw转四元数\r\n```\r\n\r\n**有heading**\r\n\r\n```c++\r\n//有heading\r\ngps_heading_time_ = heading_msg->header.stamp;\r\ngps_heading_ = Eigen::Quaterniond(q.z, 0, 0, q.w); // gps heading to map\r\nhas_heading_ = true;\r\n\r\nif (has_pos_) {\r\n    NODELET_INFO(\"INITIAL POSE AND HEADING...\");\r\n\r\n    auto ros_time_diff = gps_pos_time_ - gps_heading_time_;\r\n    double time_diff = ros_time_diff.toSec();\r\n\r\n    Eigen::Isometry3d e;\r\n    e.setIdentity();\r\n    if (has_heading_ && std::fabs(time_diff) < 0.5) {\r\n        e.prerotate(gps_heading_);\r\n    } else {\r\n        e.prerotate(Eigen::Quaterniond::Identity());\r\n    }\r\n    e.pretranslate(gps_pos_);\r\n\r\n    geometry_msgs::PoseStamped heading_pose;\r\n    heading_pose.header = heading_msg->header;\r\n    heading_pose.header.stamp = heading_msg->header.stamp;\r\n    heading_pose.header.frame_id = \"map\";\r\n    heading_pose.pose.position.x = gps_pos_(0);//位置\r\n    heading_pose.pose.position.y = gps_pos_(1);\r\n    heading_pose.pose.position.z = gps_pos_(2);\r\n\r\n    heading_pose.pose.orientation.x = gps_heading_.x();//heading角\r\n    heading_pose.pose.orientation.y = gps_heading_.y();\r\n    heading_pose.pose.orientation.z = gps_heading_.z();\r\n    heading_pose.pose.orientation.w = gps_heading_.w();\r\n    heading_pub.publish(heading_pose);\r\n\r\n    has_pos_ = false;\r\n    has_heading_ = false;\r\n}\r\n```\r\n\r\n## NDT配准\r\n\r\n### **参数设置**\r\n\r\n这里需要注意的关键参数是，ndt网格的分辨率，这个大小和激光雷达的型号相关，比如我用的robosense16，这款激光雷达一圈扫描的点可能只有velodyne16的1/3，所以我设定的网格大小是2.0，网格太小会导致网格中点的数量不够，太大导致精度降低。\r\n\r\n```c++\r\n  ndt.setTransformationEpsilon(trans_eps); // 两次变换之间允许的最大值,用于判断是否收敛,作为迭代计算完成的阈值; =0.01\r\n  ndt.setStepSize(step_size); //牛顿法优化的最大步长 0.1\r\n  ndt.setResolution(ndt_res);  //ndt cell的分辨率,我设定的是2.0，一般0.1-1，太大导致精度下降，太小导致内存撑爆\r\n  ndt.setMaximumIterations(max_iter); //ndt的最大迭代次数 这里我设置的是30\r\n  ndt.setInputSource(filtered_scan_ptr);  // 输入source点云\r\n```\r\n\r\n这里接着考虑map，如果是第一帧激光，会和初始的map配准，初始map为空。\r\n\r\n```c++\r\n static bool is_first_map = true;\r\n  if (is_first_map == true){\r\n    ndt.setInputTarget(map_ptr);\r\n    is_first_map = false;\r\n  }\r\n```\r\n\r\n考虑我们需要输出的pose，这里为避免混淆，我们定了guess_pose、previous_pose、guess_pose_for_ndt。其中guess_pose为当前时刻的初值，即ndt计算的初始估计位置,在不使用gnss/imu/odom的情况下,以上一帧车辆位置的变换矩阵（previous_pose）作为guess_pose，最后输出当前帧配准完成的guess_pose_for_ndt。\r\n\r\n```c++\r\n// 初始pose\r\nguess_pose.x = previous_pose.x + diff_x;\r\nguess_pose.y = previous_pose.y + diff_y;\r\nguess_pose.z = previous_pose.z + diff_z;\r\nguess_pose.roll = previous_pose.roll;\r\nguess_pose.pitch = previous_pose.pitch;\r\nguess_pose.yaw = previous_pose.yaw + diff_yaw; //平面上运动，近似只有偏航角变化\r\npose guess_pose_for_ndt;\r\nguess_pose_for_ndt = guess_pose;\r\n\r\nEigen::AngleAxisf init_rotation_x(guess_pose_for_ndt.roll, Eigen::Vector3f::UnitX()); //沿X轴转roll\r\nEigen::AngleAxisf init_rotation_y(guess_pose_for_ndt.pitch, Eigen::Vector3f::UnitY());\r\nEigen::AngleAxisf init_rotation_z(guess_pose_for_ndt.yaw, Eigen::Vector3f::UnitZ());\r\nEigen::Translation3f init_translation(guess_pose_for_ndt.x, guess_pose_for_ndt.y, guess_pose_for_ndt.z);\r\n\r\n//  旋转向量->初始的变换矩阵 角度*模长\r\nEigen::Matrix4f init_guess = (init_translation * init_rotation_z * init_rotation_y * init_rotation_x).matrix() * tf_btol;\r\n```\r\n\r\n### **获取NDT初值**\r\n\r\n对于NDT算法而言，当匹配的两帧点云已确定，配准结果很大程度上取决于初值的好坏，当然没有icp对初值那么敏感．不管是ndt还是icp，最终求出了cost function，都是采用牛顿法进行迭代优化，所以配准时间和迭代次数息息相关。这里我们有四种初值的获取方法，纯lidar建图的话，采用上一帧的变换作为初值，在有odom和imu的情况下，可以用这两个融合一个初值，有gps的话，也可以用gps计算初值。\r\n\r\n```c++\r\npose guess_pose_for_ndt; //命名guess_pose_for_ndt，方便处理\r\nif (_use_imu && _use_odom) {\r\n    guess_pose_for_ndt = guess_pose_imu_odom;\r\n    std::cout << \" use imu_odom guess pose\" << std::endl;\r\n} else if (_use_imu && !_use_odom) {\r\n    std::cout << \" use imu guess pose\" << std::endl;\r\n    guess_pose_for_ndt = guess_pose_imu;\r\n} else if (!_use_imu && _use_odom) {\r\n    std::cout << \" use odom guess pose\" << std::endl;\r\n    guess_pose_for_ndt = guess_pose_odom;\r\n} else {\r\n    std::cout << \" use origin guess pose\" << std::endl;\r\n    guess_pose_for_ndt = guess_pose;\r\n}\r\n\r\n//　计算init_guess\r\nEigen::AngleAxisf init_rotation_x(static_cast<const float &>(guess_pose_for_ndt.roll), Eigen::Vector3f::UnitX());\r\nEigen::AngleAxisf init_rotation_y(static_cast<const float &>(guess_pose_for_ndt.pitch), Eigen::Vector3f::UnitY());\r\nEigen::AngleAxisf init_rotation_z(static_cast<const float &>(guess_pose_for_ndt.yaw), Eigen::Vector3f::UnitZ());\r\n\r\nEigen::Translation3f init_translation(static_cast<const float &>(guess_pose_for_ndt.x),static_cast<const float &>(guess_pose_for_ndt.y), static_cast<const float &>(guess_pose_for_ndt.z));\r\n\r\nEigen::Matrix4f init_guess =　(init_translation * init_rotation_z * init_rotation_y * init_rotation_x).matrix() * tf_btol; \r\n```\r\n\r\n对于guess_pose，上面已经用previous_pose赋值．对于传感器imu/encoder均为增量型的，无法直接使用其瞬时值，而是需要计算在短时间内(前后两帧)的增量。对于imu而言，加速度计测量比较准，一次积分出来的速度，和二次积分出来的位移都会存在较大误差。\r\n\r\n```c++\r\nvoid imu_calc(ros::Time current_time) {\r\n    static ros::Time previous_time = current_time;\r\n    double diff_time = (current_time - previous_time).toSec();\r\n\r\n    double diff_imu_roll = imu.angular_velocity.x * diff_time;\r\n    double diff_imu_pitch = imu.angular_velocity.y * diff_time;\r\n    double diff_imu_yaw = imu.angular_velocity.z * diff_time;\r\n\r\n    current_pose_imu.roll += diff_imu_roll;\r\n    current_pose_imu.pitch += diff_imu_pitch;\r\n    current_pose_imu.yaw += diff_imu_yaw;\r\n\r\n    // 对imu由于不平衡造成的补偿问题\r\n    double accX1 = imu.linear_acceleration.x;\r\n    double accY1 = std::cos(current_pose_imu.roll) * imu.linear_acceleration.y -std::sin(current_pose_imu.roll) * imu.linear_acceleration.z;\r\n    double accZ1 = std::sin(current_pose_imu.roll) * imu.linear_acceleration.y + std::cos(current_pose_imu.roll) * imu.linear_acceleration.z;\r\n\r\n    double accX2 = std::sin(current_pose_imu.pitch) * accZ1 + std::cos(current_pose_imu.pitch) * accX1;\r\n    double accY2 = accY1;\r\n    double accZ2 = std::cos(current_pose_imu.pitch) * accZ1 - std::sin(current_pose_imu.pitch) * accX1;\r\n\r\n    double accX = std::cos(current_pose_imu.yaw) * accX2 - std::sin(current_pose_imu.yaw) * accY2;\r\n    double accY = std::sin(current_pose_imu.yaw) * accX2 + std::cos(current_pose_imu.yaw) * accY2;\r\n    double accZ = accZ2;\r\n\r\n  // imu计算xyz方向上的偏移,再加上考虑加速度以及时间参数,获得较为准确的距离偏移\r\n    offset_imu_x += current_velocity_imu_x * diff_time + accX * diff_time * diff_time / 2.0;\r\n    offset_imu_y += current_velocity_imu_y * diff_time + accY * diff_time * diff_time / 2.0;\r\n    offset_imu_z += current_velocity_imu_z * diff_time + accZ * diff_time * diff_time / 2.0;\r\n\r\n    current_velocity_imu_x += accX * diff_time;  // imu的速度值会通过slam进行修正,以避免累计误差\r\n    current_velocity_imu_y += accY * diff_time;  // 或者说imu计算时所用的速度并不是用imu得到的,而是用slam得到的\r\n    current_velocity_imu_z += accZ * diff_time;    // imu所提供的参数,主要用来计算角度上的偏移,以及加速度导致的距离上的偏移!@\r\n\r\n    offset_imu_roll += diff_imu_roll;\r\n    offset_imu_pitch += diff_imu_pitch;\r\n    offset_imu_yaw += diff_imu_yaw;\r\n\r\n    guess_pose_imu.x = previous_pose.x + offset_imu_x;\r\n    guess_pose_imu.y = previous_pose.y + offset_imu_y;\r\n    guess_pose_imu.z = previous_pose.z + offset_imu_z;\r\n    guess_pose_imu.roll = previous_pose.roll + offset_imu_roll;\r\n    guess_pose_imu.pitch = previous_pose.pitch + offset_imu_pitch;\r\n    guess_pose_imu.yaw = previous_pose.yaw + offset_imu_yaw;\r\n\r\n    previous_time = current_time;\r\n}\r\n```\r\n\r\n对于odometry而言，通过测量轮速来获取实时的速度，测量比较准，而由速度根据运动模型计算出的加速度等值也是有一定问题的．\r\n\r\n```c++\r\nvoid odom_calc(ros::Time current_time) {\r\n    static ros::Time previous_time = current_time;\r\n    double diff_time = (current_time - previous_time).toSec();\r\n\r\n    double diff_odom_roll = odom.twist.twist.angular.x * diff_time;\r\n    double diff_odom_pitch = odom.twist.twist.angular.y * diff_time;\r\n    double diff_odom_yaw = odom.twist.twist.angular.z * diff_time;\r\n\r\n    current_pose_odom.roll += diff_odom_roll;\r\n    current_pose_odom.pitch += diff_odom_pitch;\r\n    current_pose_odom.yaw += diff_odom_yaw;\r\n\r\n    double diff_distance = odom.twist.twist.linear.x * diff_time;\r\n    offset_odom_x += diff_distance * cos(-current_pose_odom.pitch) * cos(current_pose_odom.yaw);\r\n    offset_odom_y += diff_distance * cos(-current_pose_odom.pitch) * sin(current_pose_odom.yaw);\r\n    offset_odom_z += diff_distance * sin(-current_pose_odom.pitch);\r\n\r\n    offset_odom_roll += diff_odom_roll;\r\n    offset_odom_pitch += diff_odom_pitch;\r\n    offset_odom_yaw += diff_odom_yaw;\r\n\r\n    guess_pose_odom.x = previous_pose.x + offset_odom_x;\r\n    guess_pose_odom.y = previous_pose.y + offset_odom_y;\r\n    guess_pose_odom.z = previous_pose.z + offset_odom_z;\r\n    guess_pose_odom.roll = previous_pose.roll + offset_odom_roll;\r\n    guess_pose_odom.pitch = previous_pose.pitch + offset_odom_pitch;\r\n    guess_pose_odom.yaw = previous_pose.yaw + offset_odom_yaw;\r\n\r\n    previous_time = current_time;\r\n}\r\n```\r\n\r\n我们可以结合这两个传感器的优势和劣势，只用imu的陀螺仪和odom的速度，算出一个更可靠的初值．\r\n\r\n```c++\r\n void imu_odom_calc(ros::Time current_time) {\r\n     static ros::Time previous_time = current_time;\r\n     double diff_time = (current_time - previous_time).toSec();  // static声明的变量只会在第一次使用时被声明,因此不会被覆盖\r\n\r\n     // imu只使用陀螺仪,即 只输出转角信息roll,pitch,yaw\r\n     double diff_imu_roll = imu.angular_velocity.x * diff_time;\r\n     double diff_imu_pitch = imu.angular_velocity.y * diff_time;\r\n     double diff_imu_yaw = imu.angular_velocity.z * diff_time;\r\n\r\n     current_pose_imu_odom.roll += diff_imu_roll;  \r\n     current_pose_imu_odom.pitch += diff_imu_pitch;\r\n     current_pose_imu_odom.yaw += diff_imu_yaw;\r\n\r\n     // odom信息处理,计算 -- xyz移动距离的计算,融合odom的速度(位移)信息和imu的转角信息\r\n     double diff_distance = odom.twist.twist.linear.x * diff_time;\r\n     offset_imu_odom_x += diff_distance * cos(-current_pose_imu_odom.pitch) * cos(current_pose_imu_odom.yaw);\r\n     offset_imu_odom_y += diff_distance * cos(-current_pose_imu_odom.pitch) * sin(current_pose_imu_odom.yaw);\r\n     offset_imu_odom_z += diff_distance * sin(-current_pose_imu_odom.pitch);\r\n\r\n     offset_imu_odom_roll += diff_imu_roll;\r\n     offset_imu_odom_pitch += diff_imu_pitch;\r\n     offset_imu_odom_yaw += diff_imu_yaw;\r\n\r\n     // 融合imu和odom输出一个guess_pose\r\n     // 注:guess_pose是在previous_pose基础上叠加一个offset,包括xyz的和rpy的\r\n     // xyz的offset需要融合imu的转角和odom的速度(位移)\r\n     // rpy的offset直接采用imu的rpy偏差值\r\n     guess_pose_imu_odom.x = previous_pose.x + offset_imu_odom_x;\r\n     guess_pose_imu_odom.y = previous_pose.y + offset_imu_odom_y;\r\n     guess_pose_imu_odom.z = previous_pose.z + offset_imu_odom_z;\r\n     guess_pose_imu_odom.roll = previous_pose.roll + offset_imu_odom_roll;\r\n     guess_pose_imu_odom.pitch = previous_pose.pitch + offset_imu_odom_pitch;\r\n     guess_pose_imu_odom.yaw = previous_pose.yaw + offset_imu_odom_yaw;\r\n\r\n     previous_time = current_time;\r\n }\r\n```\r\n\r\n利用gps提供初值的方法在上一节已经讲过，这里直接拿实时的gps位置＋姿态即可，而不需要计算增量．\r\n\r\n### **NDT配准**\r\n\r\n\r\n\r\n```c++\r\npcl::PointCloud<pcl::PointXYZI>::Ptr output_cloud(new pcl::PointCloud<pcl::PointXYZI>);\r\n\r\nndt.align(*output_cloud, init_guess); //开始配准\r\nfitness_score = ndt.getFitnessScore(); //配准得分\r\nt_localizer = ndt.getFinalTransformation(); //配准成功得到的变换矩阵\r\nhas_converged = ndt.hasConverged();\r\nfinal_num_iteration = ndt.getFinalNumIteration(); //最终迭代次数\r\ntransformation_probability = ndt.getTransformationProbability();\r\n```\r\n\r\noutput_cloud: 存储source经过配准后的点云(由于source_pointcloud被极大的降采样了,因此这个数据没什么用)，我们只需要得到变换矩阵，再把scan_ptr变换过去，加入map中即可。\r\n\r\n```cpp\r\nt_base_link = t_localizer * tf_ltob; //当前时刻相对于原点的变换（定位）\r\npcl::transformPointCloud(*scan_ptr, *transformed_scan_ptr, t_localizer); // 对原始点云进行变换\r\n```\r\n\r\n 注:与icp相比的话，ndt对于初值不那么敏感。**正常情况下，只要初始位置和真实位置的距离在2m内，角度在10度以内，ndt算法都能够成功匹配，并将其位置给拉回来。相比位置而言，ndt算法对角度更敏感。**\r\n\r\n下面给出真实环境中ndt算法的测试结果，表中的数值是牛顿法优化的cost function，越小表示效果越好，当然也可能出现极端的负优化情况，这里暂不考虑。\r\n\r\n首先**固定位置**，在初始yaw分别相差2度的情况下测试，数据表明，在yaw角变化超过10，损失值就会出现跳变，此时ndt匹配效果极差。\r\n\r\n![12](31ndt-map/12.jpg)\r\n\r\n然后**固定yaw**，在初始位置相差0-3米内测试，数据表明，距离超过2米，匹配效果就会突变。\r\n\r\n![13](31ndt-map/13.jpg)\r\n\r\n```c++\r\ntf::Matrix3x3 mat_l, mat_b; //相邻帧、相对于全局的旋转矩阵\r\n\r\nmat_l.setValue(static_cast<double>(t_localizer(0, 0)), static_cast<double>(t_localizer(0, 1)),\r\n               static_cast<double>(t_localizer(0, 2)), static_cast<double>(t_localizer(1, 0)),\r\n               static_cast<double>(t_localizer(1, 1)), static_cast<double>(t_localizer(1, 2)),\r\n               static_cast<double>(t_localizer(2, 0)), static_cast<double>(t_localizer(2, 1)),\r\n               static_cast<double>(t_localizer(2, 2)));\r\n\r\nmat_b.setValue(static_cast<double>(t_base_link(0, 0)), static_cast<double>(t_base_link(0, 1)),\r\n               static_cast<double>(t_base_link(0, 2)), static_cast<double>(t_base_link(1, 0)),\r\n               static_cast<double>(t_base_link(1, 1)), static_cast<double>(t_base_link(1, 2)),\r\n               static_cast<double>(t_base_link(2, 0)), static_cast<double>(t_base_link(2, 1)),\r\n               static_cast<double>(t_base_link(2, 2)));\r\n\r\n// Update localizer_pose. 相邻帧\r\nlocalizer_pose.x = t_localizer(0, 3);\r\nlocalizer_pose.y = t_localizer(1, 3);\r\nlocalizer_pose.z = t_localizer(2, 3);\r\nmat_l.getRPY(localizer_pose.roll, localizer_pose.pitch, localizer_pose.yaw, 1);\r\n\r\n// Update ndt_pose. 全局\r\nndt_pose.x = t_base_link(0, 3);\r\nndt_pose.y = t_base_link(1, 3);\r\nndt_pose.z = t_base_link(2, 3);\r\nmat_b.getRPY(ndt_pose.roll, ndt_pose.pitch, ndt_pose.yaw, 1);\r\n\r\ncurrent_pose.x = ndt_pose.x;\r\ncurrent_pose.y = ndt_pose.y;\r\ncurrent_pose.z = ndt_pose.z;\r\ncurrent_pose.roll = ndt_pose.roll;\r\ncurrent_pose.pitch = ndt_pose.pitch;\r\ncurrent_pose.yaw = ndt_pose.yaw;\r\n\r\n// tf变换 map->base_link\r\ntransform.setOrigin(tf::Vector3(current_pose.x, current_pose.y, current_pose.z));\r\nq.setRPY(current_pose.roll, current_pose.pitch, current_pose.yaw);\r\ntransform.setRotation(q);\r\nbr.sendTransform(tf::StampedTransform(transform, current_scan_time, \"map\", \"base_link\"));\r\n```\r\n\r\n因为有些帧会配准失败，需要舍弃，前面的diff，即相邻帧之间的位移也需要计算\r\n\r\n```c++\r\n//  计算两帧时间\r\n  scan_duration = current_scan_time - previous_scan_time;\r\n  double secs = scan_duration.toSec();\r\n\r\n  // Calculate the offset (curren_pos - previous_pos) 计算两帧之间的位移、速度和偏航角变化\r\n  diff_x = current_pose.x - previous_pose.x;\r\n  diff_y = current_pose.y - previous_pose.y;\r\n  diff_z = current_pose.z - previous_pose.z;\r\n  diff_yaw = calcDiffForRadian(current_pose.yaw, previous_pose.yaw);\r\n  diff = sqrt(diff_x * diff_x + diff_y * diff_y + diff_z * diff_z);\r\n\r\n//  匀速运动模型\r\n  current_velocity_x = diff_x / secs;\r\n  current_velocity_y = diff_y / secs;\r\n  current_velocity_z = diff_z / secs;\r\n\r\n  // Update position and posture. current_pos -> previous_pos 更新当前位姿\r\n  previous_pose.x = current_pose.x;\r\n  previous_pose.y = current_pose.y;\r\n  previous_pose.z = current_pose.z;\r\n  previous_pose.roll = current_pose.roll;\r\n  previous_pose.pitch = current_pose.pitch;\r\n  previous_pose.yaw = current_pose.yaw;\r\n\r\n  previous_scan_time.sec = current_scan_time.sec;\r\n  previous_scan_time.nsec = current_scan_time.nsec;\r\n```\r\n\r\n## **地图更新**\r\n\r\n每隔n米更新一次全局地图，同时使用单独的线程,按照一定的频率进行地图的保存。注意，这里需要对当前帧进行降采样才能加入地图里。否则可能会匹配失败，我之前出现这个问题，百思不得其解，后面仔细考虑才明白。\r\n\r\n> **匹配的当前帧预处理过程中，是做过降采样的，也可以理解成一种特征，用网格中心点代替此网格内的点云，必然会损失一些点云细节。如果是稠密建图，直接将原始点云帧加入map里面，地图细节必然会保留得更加完整，但是在当前降采样的点云帧和map做匹配的时候，就不一定能够匹配上了。**\r\n\r\n```c++\r\n// Calculate the shift between added_pos and current_pos\r\ndouble shift = sqrt(pow(current_pose.x - added_pose.x, 2.0) + pow(current_pose.y - added_pose.y, 2.0));\r\n\r\n//  给定两帧距离\r\nif (shift >= min_add_scan_shift)\r\n{\r\n    //注意：必须降采样，才能加入map中\r\n    pcl::VoxelGrid <pcl::PointXYZI> voxel_grid_filter_tomap;\r\n    voxel_grid_filter_tomap.setLeafSize(voxel_leaf_size * 2, voxel_leaf_size * 2, voxel_leaf_size * 2);\r\n    voxel_grid_filter_tomap.setInputCloud(transformed_scan_ptr);\r\n    voxel_grid_filter_tomap.filter(*transformed_scan_ptr);\r\n\r\n    submap_size += shift;\r\n    map += *transformed_scan_ptr;\r\n\r\n    added_pose.x = current_pose.x;\r\n    added_pose.y = current_pose.y;\r\n    added_pose.z = current_pose.z;\r\n    added_pose.roll = current_pose.roll;\r\n    added_pose.pitch = current_pose.pitch;\r\n    added_pose.yaw = current_pose.yaw;\r\n\r\n// 此时加入的target:map_ptr并不包括刚加入点云的transformed_scan_ptr\r\n//map更新了,因此target也需要随之更新\r\n    if (_incremental_voxel_update) \r\n        cpu_ndt.updateVoxelGrid(transformed_scan_ptr);\r\n    else\r\n        cpu_ndt.setInputTarget(map_ptr);\r\n}\r\n```\r\n\r\n发布map和当前的odometry\r\n\r\n```c++\r\n// ros发布map\r\nsensor_msgs::PointCloud2::Ptr map_msg_ptr(new sensor_msgs::PointCloud2);\r\npcl::toROSMsg(*map_ptr, *map_msg_ptr);\r\nndt_map_pub.publish(*map_msg_ptr);\r\n\r\n // publish the odom\r\nnav_msgs::Odometry odom;\r\nodom.header.stamp = current_scan_time;\r\nodom.header.frame_id = \"map\";\r\n\r\nodom.pose.pose.position.x = current_pose.x;\r\nodom.pose.pose.position.y = current_pose.y;\r\nodom.pose.pose.position.z = current_pose.z;\r\n\r\nodom.pose.pose.orientation.x = q.x();\r\nodom.pose.pose.orientation.y = q.y();\r\nodom.pose.pose.orientation.z = q.z();\r\nodom.pose.pose.orientation.w = q.w();\r\n\r\nodom.child_frame_id = \"base_link\";\r\nodom.twist.twist.linear.x = current_velocity_x;\r\nodom.twist.twist.linear.y = current_velocity_y;\r\nodom.twist.twist.angular.z = current_velocity_z;\r\n\r\nodom_pub.publish(odom);\r\n\r\n//  实时的点云\r\nsensor_msgs::PointCloud2::Ptr pointcloud_current_ptr(new sensor_msgs::PointCloud2);\r\npcl::toROSMsg(*transformed_scan_ptr, *pointcloud_current_ptr);\r\npointcloud_current_ptr->header.frame_id = \"map\";\r\ncurrent_points_pub.publish(*pointcloud_current_ptr);\r\n```\r\n\r\n最后是一些初值的设定\r\n\r\n```c++\r\n  diff = 0.0, diff_x = 0.0, diff_y = 0.0, diff_z = 0.0, diff_yaw= 0.0;  // current_pose - previous_pose\r\n  current_velocity_x = 0.0, current_velocity_y = 0.0, current_velocity_z = 0.0;\r\n\r\n  // Default values\r\n  max_iter = 30;        // Maximum iterations\r\n  //static float ndt_res = 1.0;      // Resolution\r\n  ndt_res = 1;      // Resolution\r\n  step_size = 0.1;   // Step size\r\n  trans_eps = 0.01;  // Transformation epsilon\r\n  voxel_leaf_size = 0.1; // Leaf size of VoxelGrid filter.\r\n  initial_scan_loaded = 0;\r\n  min_scan_range = 5;\r\n  max_scan_range = 80;   //static double min_scan_range = 1.0;\r\n  min_add_scan_shift = 0.5;   //static double min_add_scan_shift = 0.5;\r\n  _tf_x=0.0, _tf_y=0.0, _tf_z=0.0, _tf_roll=0.0, _tf_pitch=0.0, _tf_yaw=0.0;\r\n\r\n  previous_pose.x = previous_pose.y = previous_pose.z = 0.0;\r\n  previous_pose.roll = previous_pose.pitch = previous_pose.yaw = 0.0;\r\n  ndt_pose.x = ndt_pose.y = ndt_pose.z = 0.0;\r\n  ndt_pose.roll = ndt_pose.pitch = ndt_pose.yaw = 0.0;\r\n  current_pose.x = current_pose.y = current_pose.z = 0.0;\r\n  current_pose.roll = current_pose.pitch = current_pose.yaw = 0.0;\r\n  guess_pose.x = guess_pose.y = guess_pose.z = 0.0;\r\n  guess_pose.roll = guess_pose.pitch = guess_pose.yaw = 0.0;\r\n  added_pose.x = added_pose.y = added_pose.z = 0.0;\r\n  added_pose.roll = added_pose.pitch = added_pose.yaw = 0.0;\r\n\r\n  diff_x = 0.0;\r\n  diff_y = 0.0;\r\n  diff_z = 0.0;\r\n  diff_yaw = 0.0;\r\n```\r\n\r\n以上代码是我们整个纯激光mapping的过程，是基于cpu_ndt完成的，\r\n\r\n> 这里如果要保存地图pcd文件的话，可以命令行保存这个/ndt_map的话题，但建图是否完成只能自己把握了。这里我们可以定义submap，定义一个submap_size来记录shift的和，给定阈值max_submap_size来判定是否停止建图。\r\n\r\n```c++\r\n if (submap_size >= max_submap_size)\r\n  {\r\n    std::string s1 = \"submap_\";\r\n    std::string s2 = std::to_string(submap_num);\r\n    std::string s3 = \".pcd\";\r\n//    std::string pcd_filename = s1 + s2 + s3;\r\n    std::string pcd_filename = \"/home/catalina/\"+s1 + s2 + s3;\r\n\r\n    if (submap.size() != 0)\r\n    {\r\n      if (pcl::io::savePCDFileBinary(pcd_filename, submap) == -1)\r\n      {\r\n        std::cout << \"Failed saving \" << pcd_filename << \".\" << std::endl;\r\n      }\r\n      std::cout << \"Saved \" << pcd_filename << \" (\" << submap.size() << \" points)\" << std::endl;\r\n\r\n      map = submap;\r\n      submap.clear();\r\n      submap_size = 0.0;\r\n    }\r\n    submap_num++;\r\n  }\r\n```\r\n\r\n## 最终效果\r\n\r\n　每帧扫描到的点云中，落在地面上的点云大概占30%，地面上的点云对抑制z轴漂移还是有很大作用的，因此，**在NDT_Mapping中进行配准时保留地面**，这部分地面去除算法可以参考lego_loam，近几年也有许多其他的效果比较好的地面去除算法，比如地面平面拟合，Ransanc等，后续会专门写一两篇博客来分析。\r\n\r\n### 添加车辆模型\r\n\r\n​	在文章的最后，我们在可视化的部分，做一点共作，在rviz里面添加一个小车模型．做法非常简单，在launch文件中加入\r\n\r\n```xml\r\n <include file=\"$(find vehicle_description)/launch/lexus.launch\"/>\r\n```\r\n\r\n我修改的小车模型的代码提供在下面，放在工作空间下编译即可使用，提供了６款小车模型，可修改lexus.launch为milee.launch，vehicle_model.launch等，可视化效果如下图。\r\n\r\n![image-20200122132010638](31ndt-map/image-20200122132010638.png)\r\n\r\n小车模型代码：`https://github.com/JokerJohn/vehicle_description.git`\r\n\r\n### 建图效果分析\r\n\r\n最后观察我们输出的log，可以稍作分析．一般来说，ndt是基于概率分布的算法，速度很快，迭代次数不会超过5次，score得分是越低越好，一般来说，小于1。迭代时间的话，在我的i5 8代笔记本上测试，一次迭代不到10ms，正常成功匹配一次也差不多10ms左右。在工程上可以用多线程有进行优化，可能会加快速度。\r\n\r\n![image-20200122132100319](31ndt-map/image-20200122132100319.png)\r\n\r\n### 建图场景评价\r\n\r\n从整个算法中我们可以发现，ndt相比如传统特征点法的优势在于，匹配速度快，可以理解成均匀采样，对点云的细节会保留得相对来说比较完整，在结构化环境/树木多的环境中，比如空旷广场/湖边等场景下，很难提取到合适的特征点，ndt算法的优势就很明显。\r\n\r\n下面的两张图，一张是空旷广场，一张是湖边，两个场景的特点都是树木，草丛比较多，采用lego loam等算法建图的时候会失败，因为很难提取到一些线，面特征点，最终都是用ndt算法完成的建图，并且只有激光里程计部分，由此看来ndt算法还是有一些可取之处。\r\n\r\n![image-20200122133920979](31ndt-map/image-20200122133920979.png)\r\n\r\n![image-20200122133930131](31ndt-map/image-20200122133930131.png)\r\n\r\n之前我们已经提过ndt算法的一些缺点，就是对旋转很敏感，比如下面的位置，就是匹配效果不好的情况．目前我们采用的ndt库的实现是八叉树，目前有很多变种的ndt算法，可以在一定程度上减小旋转的影响。\r\n\r\n![image-20200122134346952](31ndt-map/image-20200122134346952.png)\r\n\r\n## 致谢\r\n\r\nAutoware.AI\r\n\r\nAutocore陈晨\r\n\r\n一清创新RAMLAB\r\n\r\n<a href=\"https://zhuanlan.zhihu.com/p/77623762\" class=\"LinkCard\">使用NDT（正态分布变换）进行点云建图和定位</a>\r\n\r\n', 1, 0, 0, 1, '2021-05-09 11:41:32', 4, 1);
INSERT INTO `article` VALUES (15, '自动驾驶实战系列(二)——点云地图划分网格并可视化', NULL, '# 自动驾驶实战系列(二)——点云地图划分网格并可视化\r\n\r\n​	系列第一篇博客有朋友反映篇幅过长，我也感觉过长不利于阅读。\r\n\r\n​	本章将完成一个点云地图处理的工作，即对点云地图进行网格划分，这样做的好处是可以根据GPS位置动态加载相应的网格地图，大量减少内存占用。本篇主要介绍点云地图的网格划分方法以及可视化。\r\n\r\n\r\n![](32pcd-divider/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20190927112349.png)\r\n\r\n> ​	需要注意的是，点云地图PCD文件里面存储的都是三维的坐标点（x，y，z），这些点的值是相对于建图时起始位置（0，0，0）的距离．如果记录了建图时起始点的GPS坐标，那么点云地图里面每一个点对应的经纬高坐标，均可以转换的来．\r\n\r\nLLA转换BLH方法见我之后的博客\r\n<a href=\"http://xchu.net/2020/01/10/37gnss-localizer/#more\"  class=\"LinkCard\">自动驾驶实战系列(四)——INS数据可视化及坐标系对齐\r\n</a>\r\n\r\n<!-- more-->\r\n\r\n### 一、主要思路\r\n​	主要思路是去掉z轴，仅对平面x、y方向上的点云按自定义的grid size划分方形网格。**在定位的时候根据当前的GPS位置，可实时加载所在区域的网格点云，大量減小內存占用**。\r\n\r\n​	点云地图网格划分是离线处理的过程，处理完成后，每一个网格PCD都按一定的格式命名，并且在csv文件中记录，方便后续按文件名加载。文章第一张图就是本篇的网格划分最终的可视化结果。在这一部分，按顺序加载点云，随机上色，以方便查看。\r\n\r\n处理好的PCD文件示例如下:\r\n\r\n![1572490937083](32pcd-divider/1572490937083.png)\r\n\r\n部分csv文件命名:\r\n\r\n```c++\r\n50_-100_-150.pcd,-100,-150,0,-50,-100,0\r\n50_-50_-150.pcd,-50,-150,0,0,-100,0\r\n50_0_-150.pcd,0,-150,0,50,-100,0\r\n50_50_-150.pcd,50,-150,0,100,-100,0\r\n50_-100_-100.pcd,-100,-100,0,-50,-50,0\r\n50_-50_-100.pcd,-50,-100,0,0,-50,0\r\n50_0_-100.pcd,0,-100,0,50,-50,0\r\n50_50_-100.pcd,50,-100,0,100,-50,0\r\n50_100_-100.pcd,100,-100,0,150,-50,0\r\n50_-100_-50.pcd,-100,-50,0,-50,0,0\r\n50_-50_-50.pcd,-50,-50,0,0,0,0\r\n50_0_-50.pcd,0,-50,0,50,0,0\r\n50_50_-50.pcd,50,-50,0,100,0,0\r\n50_100_-50.pcd,100,-50,0,150,0,0\r\n50_150_-50.pcd,150,-50,0,200,0,0\r\n50_-150_0.pcd,-150,0,0,-100,50,0\r\n50_-100_0.pcd,-100,0,0,-50,50,0\r\n```\r\n\r\n### 二、实现过程\r\n\r\n**加载原始点云地图（可能多个）**\r\n\r\n```c++\r\nPointCloud map;\r\nPointCloud tmp;\r\nfor (int i = 0; i < files.size(); i++)\r\n{\r\n    if (pcl::io::loadPCDFile<Point>(files[i], tmp) == -1)\r\n    {\r\n        std::cout << \"Failed to load \" << files[i] << \".\" << std::endl;\r\n    }\r\n    map += tmp;\r\n    std::cout << \"Finished to load \" << files[i] << \".\" << std::endl;\r\n}\r\nstd::cout << \"Finished to load all PCDs: \" << map.size() << \" points.\"\r\n```\r\n\r\n**网格划分规则**\r\n\r\n考虑对整个点云地图文件的点**在xy方向的最大最小值**，找到x坐标，y坐标的最大最小值，记为`min_x，min_y，max_x， max_y`，形成一个长方形网格，这个网格就包含了当前地图里面所有的点．\r\n\r\n```c++\r\n  double min_x = 10000000000.0;\r\n  double max_x = -10000000000.0;\r\n  double min_y = 10000000000.0;\r\n  double max_y = -10000000000.0;\r\n\r\n  for (PointCloud::const_iterator p = map.begin(); p != map.end(); p++)\r\n  {\r\n    if (p->x < min_x)\r\n    {\r\n      min_x = p->x;\r\n    }\r\n    if (p->x > max_x)\r\n    {\r\n      max_x = p->x;\r\n    }\r\n    if (p->y < min_y)\r\n    {\r\n      min_y = p->y;\r\n    }\r\n    if (p->y > max_y)\r\n    {\r\n      max_y = p->y;\r\n    }\r\n  }\r\n```\r\n\r\n按照自行设定的grid_size对网格进行划分，计算网格个数\r\n\r\n```c++\r\nint div_x = (max_x_b - min_x_b) / grid_size;\r\nint div_y = (max_y_b - min_y_b) / grid_size;\r\nint grid_num = div_x * div_y;\r\n```\r\n\r\n找到边界网格的xy方向上的坐标\r\n\r\n```c++\r\nint min_x_b = grid_size * static_cast<int>(floor(min_x / grid_size));\r\nint max_x_b = grid_size * static_cast<int>(floor(max_x / grid_size) + 1);\r\nint min_y_b = grid_size * static_cast<int>(floor(min_y / grid_size));\r\nint max_y_b = grid_size * static_cast<int>(floor(max_y / grid_size) + 1);\r\n```\r\n\r\n每个网格的四个顶点坐标可记录为（x_min，y_min）（x_min，y_max）（x_max，y_min） （x_max，y_max）,可以用网格左下角坐标（x_min，y_min）来表征此块网格的位置．那么后续如果知道了当前的GPS坐标，转化为当前位置的xy平面坐标，根据xy坐标值，可以查到当前位置在哪一个方格里面．\r\n\r\n> 比如当前位置的平面坐标为(34，110)，网格大小为30米，那么按以上表征方法当前位置所在的方格必定为(30，90)\r\n\r\n用左下角坐标表征唯一的网格还是较为复杂，我们考虑重新对地图里面所有的网格按先x后y，坐标从小到达的顺序进行编号，记为grid_id．\r\n\r\n> 比如x第一行的方格依次编号为0-10，y的第二行即从11开始。grid_id_x、grid_id_y分别为方格在x、y方向上的编号，即行号和列号。lower_bound_x等四个数为当前方格的四个边界点。\r\n\r\n**定义网格结构**\r\n\r\n```c++\r\nstruct pcd_xyz_grid\r\n{\r\n  std::string filename;　//网格PCD文件名\r\n  std::string name;\r\n  int grid_id;　//网格编号\r\n  int grid_id_x;　//行号\r\n  int grid_id_y;　//列号\r\n  int lower_bound_x;　//x_min\r\n  int lower_bound_y; //y_min\r\n  int upper_bound_x; //x_max\r\n  int upper_bound_y; //y_max\r\n  pcl::PointCloud<pcl::PointXYZ> cloud;\r\n};\r\n```\r\n**重新按网格序号组织点云**\r\n\r\n```c++\r\nfor (PointCloud::const_iterator p = map.begin(); p != map.end(); p++)\r\n  {\r\n    int idx = static_cast<int>(floor((p->x - static_cast<float>(min_x_b)) / grid_size));\r\n    int idy = static_cast<int>(floor((p->y - static_cast<float>(min_y_b)) / grid_size));\r\n    int id = idy * div_x + idx;\r\n\r\n    const Point &tmp = *p;\r\n    grids[id].cloud.points.push_back(tmp);\r\n  }\r\n```\r\n\r\n按**一定格式定义文件名**。\r\n\r\n划分好的PCD文件命名格式为`grid_size_x_min_y_min.pcd`，比如30_30_0，即grid size为30m，左下角顶点坐标为（30， 0）的方格。\r\n\r\n**那么在我们只需要首次读取csv文件就可以拿到所有的网格文件名和顶点位置坐标并存储起来，后续只需要查询此文件名列表即可得知当前GPS坐标所在的网格，然后根据文件名去加载对应PCD文件即可**．\r\n\r\n```c++\r\n std::vector<pcd_xyz_grid> grids(grid_num);\r\n  for (int y = 0; y < div_y; y++)\r\n  {\r\n    for (int x = 0; x < div_x; x++)\r\n    {\r\n      int id = div_x * y + x;\r\n      grids[id].grid_id = id; //序号\r\n      grids[id].grid_id_x = x; //行号\r\n      grids[id].grid_id_y = y; //列号\r\n      grids[id].lower_bound_x = min_x_b + grid_size * x; //方格的四个顶点\r\n      grids[id].lower_bound_y = min_y_b + grid_size * y;\r\n      grids[id].upper_bound_x = min_x_b + grid_size * (x + 1);\r\n      grids[id].upper_bound_y = min_y_b + grid_size * (y + 1);\r\n      grids[id].filename = OUT_DIR + std::to_string(grid_size) + \"_\" +\r\n                           std::to_string(grids[id].lower_bound_x) + \"_\" +\r\n                           std::to_string(grids[id].lower_bound_y) + \".pcd\";\r\n      grids[id].name = std::to_string(grid_size) + \"_\" +\r\n                       std::to_string(grids[id].lower_bound_x) + \"_\" +\r\n                       std::to_string(grids[id].lower_bound_y) + \".pcd\";\r\n    }\r\n  }\r\n```\r\n\r\n将点云写入pcd文件\r\n\r\n```c++\r\n  int points_num = 0;\r\n  for (int i = 0; i < grid_num; i++)\r\n  {\r\n    if (grids[i].cloud.points.size() > 0)\r\n    {\r\n      pcl::io::savePCDFileBinary(grids[i].filename, grids[i].cloud);\r\n      std::cout << \"Wrote \" << grids[i].cloud.points.size() << \" points to \"\r\n                << grids[i].filename << \".\" << std::endl;\r\n      points_num += grids[i].cloud.points.size();\r\n    }\r\n  }\r\n  write_csv(grids);\r\n  std::cout << \"Total points num: \" << points_num << \" points.\" << std::endl;\r\n```\r\n\r\n同时把每一个网格的相关信息按一定格式存储到csv文件中，方便查找。每一行存储的信息为PCD文件名-网格的边界，比如`30_-90_-120.pcd,-90,-120,0,-60,-90,0`\r\n\r\n```c++\r\nvoid write_csv(std::vector<pcd_xyz_grid> &grids)\r\n{\r\n  std::string whole_file_name = OUT_DIR + FILE_NAME;\r\n  std::ofstream ofs(whole_file_name.c_str());\r\n  int grid_num = grids.size();\r\n  for (int i = 0; i < grid_num; i++)\r\n  {\r\n    if (grids[i].cloud.points.size() > 0)\r\n    {\r\n      ofs << grids[i].name\r\n          << \",\" << grids[i].lower_bound_x\r\n          << \",\" << grids[i].lower_bound_y\r\n          << \",\" << 0.0\r\n          << \",\" << grids[i].upper_bound_x\r\n          << \",\" << grids[i].upper_bound_y\r\n          << \",\" << 0.0 << std::endl;\r\n    }\r\n  }\r\n}\r\n```\r\n\r\n### 三、网格可视化\r\n\r\n​	这里我们先用pcl加载所有的网格地图进行可视化，方便查看效果，后续在实际使用过程中，可能需要通过ROS来加载指定序号的网格，代码逻辑非常简单。\r\n\r\n**网格pcd按文件名称排序**\r\n\r\n这是我经常使用的一个很有用的工具函数，这里path为网格PCD的文件路径，我们需要将pcd_info.csv文件先移除，只留PCD文件。\r\n\r\n```c++\r\nvoid getAllFiles(std::string path, std::vector<std::string> &files)\r\n{\r\n    if (path[path.length() - 1] != \'/\')\r\n        path = path + \"/\";\r\n    DIR *dir;\r\n    struct dirent *ptr;\r\n    char base[1000];\r\n    if ((dir = opendir(path.c_str())) == NULL)\r\n    {\r\n        perror(\"Open dir error...\");\r\n        std::cout << \"Check: \" << path << std::endl;\r\n        exit(1);\r\n    }\r\n\r\n    while ((ptr = readdir(dir)) != NULL)\r\n    {\r\n        if (ptr->d_type == 8) // 文件\r\n        {\r\n            std::string name = ptr->d_name;\r\n            int length = name.length();\r\n            if (name.substr(length - 3, length - 1) == \"pcd\" || name.substr(length - 3, length - 1) == \"PCD\")\r\n            {\r\n                std::cout << path + name << std::endl;\r\n                files.push_back(path + name);\r\n            }\r\n        }\r\n    }\r\n    closedir(dir);\r\n    std::sort(files.begin(), files.end());\r\n    return;\r\n}\r\n\r\n```\r\n\r\n**加载PCD网格**\r\n\r\nmain函数里面，我们设定了输入目录，遍历读取PCD文件，用pcl_viewer可视化即可。\r\n\r\n```c++\r\n\r\n  std::string OUT_DIR = \"/home/catalina/ndt_ws/src/smartcar/location/packages/pcl_map_tools/grid_pcd\";\r\n// Load all PCDs\r\n    PointCloud::Ptr map_ptr(new PointCloud);\r\n    PointCloud::Ptr tmp_ptr(new PointCloud);\r\n    boost::shared_ptr<pcl::visualization::PCLVisualizer> viewer(new pcl::visualization::PCLVisualizer(\"map viewer\"));\r\n\r\n    int num = 0;\r\n    int num2 = 255;\r\n\r\n    for (int i = 0; i < grid_files.size(); i++)\r\n    {\r\n        if (pcl::io::loadPCDFile<Point>(grid_files[i], *tmp_ptr) == -1)\r\n        {\r\n            std::cout << \"Failed to load \" << grid_files[i] << \".\" << std::endl;\r\n        }\r\n\r\n        num++;\r\n        pcl::visualization::PointCloudColorHandlerCustom<pcl::PointXYZI> single_color(tmp_ptr, random(255), random(255), random(255)); // green\r\n        viewer->addPointCloud<pcl::PointXYZI>(tmp_ptr, single_color, \"sample cloud\"+num);\r\n        viewer->setPointCloudRenderingProperties(pcl::visualization::PCL_VISUALIZER_POINT_SIZE, 1.0, \"sample cloud\"+num); // 设置点云大小\r\n\r\n        *map_ptr += *tmp_ptr;\r\n        std::cout << \"Finished to load \" << grid_files[i] << \".\" << std::endl;\r\n    }\r\n\r\n    std::cout << \"map size:\" << map_ptr->size()<< \".\" << std::endl;\r\n\r\n//    pcl::visualization::PointCloudColorHandlerGenericField<pcl::PointXYZI> fildColor(map_ptr, \"z\"); // 按照z字段进行渲染\r\n    while (!viewer->wasStopped())\r\n    {\r\n        viewer->spinOnce(100);\r\n        boost::this_thread::sleep(boost::posix_time::microseconds(100000));\r\n    }\r\n```\r\n\r\n根据初始位置动态加载网格点云的代码后续再结合定位一起来写，预计在第五篇。\r\n\r\n### 参考及致谢\r\n\r\nAutoware.AI\r\n\r\nAutocore陈晨\r\n\r\n一清创新RAMLAB\r\n\r\n…', 2, 0, 0, 1, '2021-05-09 11:42:06', 4, 1);
INSERT INTO `article` VALUES (16, '自动驾驶实战系列(三)——组合导航调试实践', NULL, '# 自动驾驶实战系列(三)——组合导航调试实践\r\n\r\n自动驾驶系列博客第三篇姗姗来迟...由于篇幅过长，继续拆成两篇，逐一细致讲解。\r\n\r\n​	近期在调试广州导远电子的INS55D组合导航设备，中间遇到了一些坑，最终算是顺利完成。基于目前主流的无人驾驶方案离不开GNSS/IMU，加之大多数厂家直接使用组合导航设备。此部分网上教程比较零散，将这一部分的工作整理出来作为自动驾驶系列博客的第三篇，我认为很有意义。\r\n\r\n![image-20200109182825682](35nmea/image-20200109182825682.png)\r\n\r\n​	本篇主要说明组合导航的安装配置流程等模块，不同类型的驱动协议解析则留到下一节。本人实属新手，若文中出现错误，纯属个人理解不到位，请多指点交流。\r\n\r\n<!--more -->\r\n\r\n## 一、概述\r\n\r\n### 1、设备概览\r\n\r\n- 组合导航INS550D\r\n- 通用4G模块DTU (型号MD-649)\r\n- 串转USB转接线，4G吸盘天线\r\n- 千寻服务差分账号、SIM卡\r\n- Ins Asstiant(厂商提供)、dtucfg相关软件(官网下载)\r\n\r\n![image-20200109182857315](35nmea/image-20200109182857315.png)\r\n\r\n### 2、INS基本形式及原理\r\n\r\n#### 1、只有移动站（推荐,本文的案例）\r\n\r\n由惯性导航单元、四频双天线RTK 卫星导航接收机和4G 差分模块组成。4G 差分模块通过4G 网络接收千寻位置等RTCM 差分信息，发送给卫星导航板卡。导航计算机接收3 轴陀螺、3 轴加速度计和卫导板卡信息，实时得到精确的位置、速度、方位。\r\n\r\n![image-20200109183104334](35nmea/image-20200109183104334.png)\r\n\r\n#### 2、包括移动站和CORS 站\r\n\r\n移动站由惯性导航单元、四频双天线RTK 卫星导航接收机和数传电台组成。卫星导航接收机通过RTK 差分解算，测得载体的位置和方位角，惯性导航单元给出载体的姿态角、角速度和加速度，并运行组合导航算法得到实时位置和方位数据。CORS站由四频卫星导航接收机和数传电台组成，发送RTCM和载波信息。\r\n\r\n![image-20200109183119349](35nmea/image-20200109183119349.png)\r\n\r\n### 3、DTU原理\r\n\r\n​	MD-649是一款具有高速数据传输能力的4G DTU产品，特别适合传输数据量大，实时性要求高的场合。\r\n![image-20200109182919587](35nmea/image-20200109182919587.png)\r\n​	在MD-649中设置数据中心的IP（或域名）和端口后，MD-649利用4G无线网络拨号连上Internet，随后发起对所配的IP和端口（即mServer的监听端口）的连接，另外，用户软件系统通过虚拟串口等接口连接到mServer，进而实现了从用户设备到用户软件系统之间的无线、双向数据通信。\r\n\r\n![image-20200109183833199](35nmea/image-20200109183833199.png)\r\n\r\n## 二、组合导航安装配置\r\n\r\n![image-20200110161945209](35nmea/image-20200110161945209.png)\r\n\r\n由于我并未进行过组合导航的标定工作，所以以下内容暂时不会涉及，后续有经验了再补上\r\n\r\n### 1、安装方式\r\n\r\n双天线位置安装，距离大于1米。\r\n\r\n![image-20200109230623815](35nmea/image-20200109230623815.png)\r\n惯导安装朝向，一般惯导X轴向为车头方向。\r\n\r\n![image-20200110162606015](35nmea/image-20200110162606015.png)\r\n\r\n![image-20200109183604101](35nmea/image-20200109183604101.png)\r\n\r\n惯导、DTU、工控机连接\r\n\r\n![image-20200109183751401](35nmea/image-20200109183751401.png)\r\n\r\n### 2、DTU配置\r\n\r\n- 千寻差分账号：淘宝可买，每个手机号均可申请试用2小时。\r\n\r\n- 硬件连接：笔记本（win/linux）->RS232转USB->DTU\r\n\r\n  将SIM卡激活并安装到DTU中，打开dtucfg.exe，设置正确的串口号以及波特率(115200)\r\n\r\n按连续回车进行配置，直到恢复出厂设置\r\n\r\n- **修改数据中心端口号8002**\r\n\r\n- **修改波特率115200**（此波特率为差分口输出的波特率，注意与后面RS422口输出区分开来）\r\n\r\n- 输入NTRIP账号和密码（你的差分账号和密码，切记不同于千寻登录账号和密码）\r\n\r\n![image-20200109183918476](35nmea/image-20200109183918476.png)\r\n\r\n确认正常情况：**绿灯常亮（连接到数据中心）、红灯闪烁（正在传送数据）**\r\n\r\n![image-20200109183931083](35nmea/image-20200109183931083.png)\r\n\r\n从上电到DTU连接正常可能需要半分钟左右，属正常情况。\r\n\r\n### 3、上位机软件设置\r\n\r\n打开Ins Asstiant选择波特率230400和串口COM6，打开串口，若当前信息显示数据在更新，即，则硬件连接成功。这里数据更新主要看以下两点\r\n\r\n- 位置更新\r\n- 姿态更新\r\n- 组合导航状态\r\n\r\n如果位置更新显示绿色，姿态更新显示蓝色，即组合导航初始化成功。\r\n\r\n![image-20200109184104568](35nmea/image-20200109184104568.png)\r\n\r\n查看组合导航RTK状态。FLAG这里显示NARROW_INT，解释为窄巷固定解，收星数为19，初始化成功，RTK状态很好。\r\n![image-20200109184246400](35nmea/image-20200109184246400.png)\r\n\r\n>   这里对RTK STATUS做一个简单说明\r\n>\r\n>   STATUS=0，即RTK无解。\r\n>\r\n>   STATUS = 48/49/50，L1 固定解、宽巷固定解、窄巷固定解，即为厘米级定位\r\n>\r\n>   STATUS=32/33/34，浮动解，即为亚米级定位。\r\n>\r\n>   后面会展示一下测试结果，有RTK，亚米级RTK，厘米级RTK\r\n\r\n![image-20200109184849190](35nmea/image-20200109184849190.png)\r\n\r\n如果组合导航初始化未成功，具体检查是姿态还是位置初始化不成功。\r\n\r\n#### 1.位置初始化失败\r\n\r\n- DTU直接连接个人电脑。\r\n\r\n- 检查DTU信号灯，若非绿灯常亮，红灯闪烁，则重新配置DTU，检查配置流程是否出错。\r\n\r\n- 检查千寻差分账号是否正在服务中，可以更换账号测试，**切勿弄成千寻网站登录账号**（本人就犯过这个错，浪费不少时间）。**这里注意，即使差分账号配置错误，也是红灯闪烁，绿灯常亮的**。\r\n\r\n这几步做完，基本可以排除位置更新的大部分问题了。\r\n\r\n​	如果还是失败，那么就需要分析千寻服务从串口返回的数据了，可以用串口工具UartTool查看是否有数据输出，并根据数据字段联系千寻厂家加以分析原因。（千寻服务很稳定，一般不会走到这一步）\r\n\r\n#### 2.姿态初始化失败\r\n\r\n![image-20200109184050982](35nmea/image-20200109184050982.png)\r\n\r\n- 惯导差分口直接连接电脑。\r\n\r\n- 打开串口工具，我这里使用的是UartTool，查看惯导COM口是否有数据输出，检查数据状态是否正常（这里需要联系厂商）。\r\n\r\n如果无数据输出，则检查波特率是否选错，都尝试一下。\r\n\r\n有数据输出并且乱码了，则可能是hex数据，点一下hex显示即可。有些厂家用的差分口输出ins数据，直接发的GTIMU协议数据。\r\n\r\n![image-20200109185706753](35nmea/image-20200109185706753.png)\r\n\r\n数据正常输出的话，可能需要重新配置一下。\r\n\r\n命令行向串口发送`config`指令，查看输出结果，如图所示即正常。\r\n\r\n![image-20200109185444703](35nmea/image-20200109185444703.png)\r\n\r\n继续发送指令`CONFIG COM2 115200 8 n 1`，观察是否有`response ok`字样返回，最后发送`SAVECONFIG`即可配置完成。（这里联系惯导厂家）\r\n\r\n![image-20200109185503842](35nmea/image-20200109185503842.png)\r\n\r\n再用INS550D差分口直接连接电脑，打开上位机软件观察姿态能否初始化。\r\n\r\n> 如果初始化失败，则用万用表量下550D的通讯线束通断情况，DB9差分口pin3对应DB15的10，DB9差分口pin2对应DB15的14，这两组通断，测量差分口和DB15。有DB15外壳上有引脚标志。\r\n\r\n\r\n\r\n## 三、致谢\r\n\r\n参考：INS550D、MD-649说明手册\r\n\r\n感谢：一清创新RAMLAB、导远电子程工、中科院自动化所飞哥、主线科技刘工、哈工大刘博等', 0, 0, 0, 1, '2021-05-09 11:42:37', 4, 1);
INSERT INTO `article` VALUES (17, '自动驾驶实战系列(五)——地理与平面坐标系对齐及INS数据可视化', NULL, '# 自动驾驶实战系列(五)——地理与平面坐标系对齐及INS数据可视化\r\n\r\n决定还是分两篇来写吧！本篇主要介绍INS数据的可视化及基本分析。\r\n\r\n![cas](37gnss-localizer/cas.png)\r\n<!-- more-->\r\n\r\n接上一篇：\r\n\r\n<a href=\"http://xchu.net/2019/12/30/35nmea/#more\"  class=\"LinkCard\">自动驾驶实战系列(三)——组合导航调试与驱动实践</a>\r\n\r\n按第三篇步骤完成组合导航配置之后可以进行精度的测试，这里我们首先录制一个bag包，用以下两种方式来进行分析。如果有理解出错的地方，请在下方评论交流。\r\n\r\n## 一、INS数据分析\r\n\r\nPlotJugger是ROS提供的的插件工具，安装之后可以通过`rosrun plotjugger plotjugger`来启动，是我们查看bag包数据的常用工具。直接load bag数据包，选定指定的topic数据字段到程序中进行分析即可。如下图，这里我们主要分析位置（LLA）和姿态（YAW）变化情况。\r\n\r\n- 经纬度轨迹是否和预期一致\r\n- yaw角变化是否和预期一致\r\n- 加速度/角速度变化情况\r\n\r\n### 1、加速度/角速度简单分析\r\n\r\n**对于角速度而言，在静止情况下应该都为0，加速度水平的话，y轴为0，z轴为重力加速度，基本为1。**\r\n\r\n![image-20200109192510507](37gnss-localizer/image-20200110165838993.png)\r\n\r\n### 2、位置分析\r\n\r\n左侧选定经纬度字段（也可以是utm_east、utm_north字段），鼠标右键拖到右侧plot中可以明显看到小车INS记录的运动轨迹，点击启动按钮，观察红色点的变动情况，可跟踪小车运行状态。显然这里我们的GPS轨迹是符合预期的。\r\n\r\n![image-20200109192510507](37gnss-localizer/image-20200109192510507-1578646938940.png)\r\n\r\n### 3、姿态数据分析\r\n\r\n![image-20200109192909463](37gnss-localizer/image-20200109192909463.png)\r\n\r\n继续查看yaw角，起始位置一直保持yaw角为160度，我们需要关注的是yaw角变化的一些节点，一般来说小车是在进行转向操作。\r\n\r\n>   对于yaw角的取值，我们需要明确其来源。以组合导航为例，有双天线RTK时可以计算heading，即与正北方向的夹角，这里惯导输出的融合之后的yaw角肯定就是相对于正北方向的夹角，简单的说就是此时刻的yaw即为车头方向。若RTK无解，我们知道IMU上电之后测量的yaw角为0，此种情况下组合导航输出的yaw角即为相对于惯导上电时刻朝向的夹角。\r\n>\r\n>   组合导航仪在定位过程中，会遇到RTK无解的情况，此时输出的yaw角为第二种情况，在后续运动过程中找回了RTK有解了，也会逐步较准回来。\r\n>\r\n>   另外，针对于单个IMU而言，九轴IMU配有地磁仪，可以考虑为第一种情况。而六轴IMU无地磁仪，考虑为第二种情况。\r\n\r\n![image-20200109193929363](37gnss-localizer/image-20200109193929363.png)\r\n\r\n**观察yaw角大小变化还有一种简单的测试方法，打开手机指南针软件，朝向车头方向沿着车的行进轨迹走，观察与正北方向的夹角变化情况，特别注意转弯地方的夹角变化，若基本一致，则yaw角数据正常。**\r\n\r\n最后我们还可以查看一下测试路面的坡度变化，这里x轴朝向车头，坡度变化对应的是pitch角，也符合我们的预期。\r\n\r\n![image-20200109194131616](37gnss-localizer/image-20200109194131616.png)\r\n\r\n> 这里提醒一下,车子在平面上加速的时候,轮胎的传动轴会有扭矩作用,让车轮转动.车子本身会有反扭矩,这个反作用力在传动轴上会有一个向上或者向下的作用力,从而使车头向上或向下.这个角度虽然肉眼看不出来,但车身的传感器能够感受到,从而产生一个较大的pitch,此pitch角可能会被误当做一个坡度信息.\r\n>\r\n> 这个问题我之前一直没考虑过,但在实车测试的时候发现的,目前只能通过其他的传感器来解决此问题.\r\n\r\n## 二、可视化及坐标对齐\r\n\r\n这里我们完成一个简单的测试程序，在地图上观察GPS轨迹和IMU朝向是否正常。\r\n\r\n![image-20200109195037217](37gnss-localizer/image-20200109195037217.png)\r\n\r\n### 1、基本思路\r\n\r\n我们需要一张点云地图及其地图原点坐标，可以通过SLAM算法完成地图构建并记录地图起点的经纬坐标。\r\n\r\n程序的大致流程：\r\n\r\n- 接收ins数据，LL转XY为位置，yaw角为姿态。\r\n- 发布odometry\r\n\r\n### 2、地理系与平面系对齐\r\n\r\n首先地理系和平面系如何进行对齐呢？\r\n\r\n我们知道建图的时候，如果不记录GPS数据的话，一般的slam算法完成的地图就是点云数据，地图里面存储的这些点的坐标原点，就是（0，0，0）了。如果记录下起点对应的经纬LLA坐标，那么点云地图里面的每一个位置都可以转换成经纬坐标。这样在定位的时候，我们可以把每一个GPS点在地图上标出来，就可以清晰看到小车在地图上的运动轨迹了。\r\n\r\n这里点坐标，比如（1，1，1），即为平面系，将所有的GPS LLA坐标转换到平面系中进行后续的计算。这里坐标系转换流程，LLA->ECEF->ENU，ENU即为我们的平面系，东北天。\r\n\r\n核心代码如下\r\n\r\n```c++\r\nnh.getParam(\"origin_longitude\", origin_longitude);//点云地图原点LLA\r\nnh.getParam(\"origin_latitude\", origin_latitude);\r\nnh.getParam(\"origin_altitude\", origin_altitude);\r\n\r\nnh.getParam(\"imu_topic\", imu_topic);//TOPIC\r\nnh.getParam(\"ins_topic\", ins_topic);\r\nnh.getParam(\"gps_topic\", gps_topic);   \r\n\r\npose_pub = nh.advertise<nav_msgs::Odometry>(\"/odom\", 1, false);//PUB or SUB\r\nros::Subscriber imu_sub = nh.subscribe(imu_topic, 5, imu_callback);\r\nros::Subscriber ins_sub = nh.subscribe(ins_topic, 5, ins_callback);\r\n```\r\n\r\n**INS_callback(const raw_sensor_msgs::GnssImuInfo &msg)**\r\n\r\n```c++\r\nsensor_msgs::NavSatFix gps_msgs;\r\ngps_msgs.status.status = msg.gps_status;\r\n\r\ngps_msgs.header.seq = msg.header.seq;\r\ngps_msgs.header.stamp = msg.header.stamp;\r\ngps_msgs.header.frame_id = msg.header.frame_id;\r\n\r\ngps_msgs.latitude = msg.latitude;\r\ngps_msgs.longitude = msg.longitude;\r\ngps_msgs.altitude = msg.altitude; \r\n\r\n\r\nif (std::isnan(msg.latitude + msg.longitude + msg.altitude)) {\r\n     ROS_INFO(\"GPS LLA NAN...\"); //去NAN\r\n     return;\r\n }\r\n\r\ngpsTools gpsTools;\r\ngpsTools.lla_origin_ << origin_latitude, origin_longitude, origin_altitude; //点云地图原点\r\n\r\n//    if (!(msg.gps_status == 48 || msg.gps_status == 49 || msg.gps_status == 50)) {\r\nif (msg.gps_status == 0) {\r\n    ROS_ERROR(\"NO RTK.....\");\r\n    return;\r\n}\r\n\r\n//由于我们原来的工具类是使用NavsatFix标准格式写的转换工具类，这里我的ins是自定义的msg格式，所以就用了//gps_msg存储了经纬，方便转换\r\nEigen::Vector3d lla = gpsTools.GpsMsg2Eigen(gps_msgs);//LLA->ENU \r\nEigen::Vector3d ecef = gpsTools.LLA2ECEF(lla);\r\nEigen::Vector3d enu = gpsTools.ECEF2ENU(ecef);\r\ngps_pos_ = enu;\r\n\r\n// publish the odometry\r\nnav_msgs::Odometry odom;\r\nodom.header.stamp = msg.header.stamp;\r\nodom.header.frame_id = \"map\";\r\n\r\nodom.pose.pose.position.x = gps_pos_(0);\r\nodom.pose.pose.position.y = gps_pos_(1);\r\nodom.pose.pose.position.z = gps_pos_(2);\r\n//这里需要补偿这个固定的夹角，根据自己车上的情况来处理\r\nodom.pose.pose.orientation = tf::createQuaternionMsgFromYaw(-imu_yaw+M_PI/2);\r\n\r\nodom.child_frame_id = \"base_link\";\r\nodom.twist.twist.linear.x = 0.0;\r\nodom.twist.twist.linear.y = 0.0;\r\nodom.twist.twist.angular.z = 0.0;\r\n\r\npose_pub.publish(odom);\r\n```\r\n\r\n**IMU_callback(const sensor_msgs::Imu::Ptr &input)**\r\n\r\n```c++\r\ntf::Quaternion imu_orientation;\r\ntf::quaternionMsgToTF(input->orientation, imu_orientation);\r\ntf::Matrix3x3(imu_orientation).getRPY(imu_roll, imu_pitch, imu_yaw);\r\n\r\n//  角度转弧度\r\nimu_roll = wrapToPmPi(imu_roll);\r\nimu_pitch = wrapToPmPi(imu_pitch);\r\nimu_yaw = wrapToPmPi(imu_yaw);\r\n```\r\n\r\n**工具类及全局变量**\r\n\r\n```c++\r\n#include <nav_msgs/Odometry.h>\r\n#include <sensor_msgs/NavSatFix.h>\r\n#include <boost/foreach.hpp>\r\n#include <geometry_msgs/QuaternionStamped.h>\r\n#include <Eigen/Core>\r\n\r\n#define DEG_TO_RAD 0.01745329252\r\n#define EARTH_MAJOR 6378137.0            ///< WGS84 MAJOR AXIS\r\n#define EARTH_MINOR 6356752.31424518    ///< WGS84 MINOR AXIS\r\n\r\ndouble imu_roll = 0.0, imu_pitch = 0.0, imu_yaw = 0.0;\r\n//1.lla的起点\r\nEigen::Vector3d lla_origin_;\r\n//2.enu下的坐标\r\nEigen::Vector3d gps_pos_;\r\n\r\nstatic double wrapToPm(double a_num, const double a_max) {\r\n    if (a_num >= a_max) {\r\n        a_num -= 2.0 * a_max;\r\n    }\r\n    return a_num;\r\n}\r\n\r\nstatic double wrapToPmPi(const double a_angle_rad) {\r\n    return wrapToPm(a_angle_rad, M_PI);\r\n}\r\n\r\nstatic double calcDiffForRadian(const double lhs_rad, const double rhs_rad) {\r\n    double diff_rad = lhs_rad - rhs_rad;\r\n    if (diff_rad >= M_PI)\r\n        diff_rad = diff_rad - 2 * M_PI;\r\n    else if (diff_rad < -M_PI)\r\n        diff_rad = diff_rad + 2 * M_PI;\r\n    return diff_rad;\r\n}\r\n\r\nEigen::Vector3d gpsTools::GpsMsg2Eigen(const sensor_msgs::NavSatFix &gps_msgs) {\r\n	Eigen::Vector3d\r\n			lla(gps_msgs.latitude, gps_msgs.longitude, gps_msgs.altitude);\r\n	return lla;\r\n}\r\n\r\nEigen::Vector3d gpsTools::LLA2ECEF(const Eigen::Vector3d &lla) {\r\n	Eigen::Vector3d ecef;\r\n	double lat = deg2rad(lla.x());\r\n	double lon = deg2rad(lla.y());\r\n	double alt = lla.z();\r\n	double earth_r = pow(EARTH_MAJOR, 2)\r\n					 / sqrt(pow(EARTH_MAJOR * cos(lat), 2) + pow(EARTH_MINOR * sin(lat), 2));\r\n	ecef.x() = (earth_r + alt) * cos(lat) * cos(lon);\r\n	ecef.y() = (earth_r + alt) * cos(lat) * sin(lon);\r\n	ecef.z() = (pow(EARTH_MINOR / EARTH_MAJOR, 2) * earth_r + alt) * sin(lat);\r\n	\r\n	return ecef;\r\n}\r\n\r\nEigen::Vector3d gpsTools::ECEF2ENU(const Eigen::Vector3d &ecef) {\r\n	double lat = deg2rad(lla_origin_.x());\r\n	double lon = deg2rad(lla_origin_.y());\r\n	\r\n	Eigen::Vector3d t = -LLA2ECEF(lla_origin_);\r\n	Eigen::Matrix3d r;\r\n	r << -sin(lon), cos(lon), 0,\r\n			-cos(lon) * sin(lat), -sin(lat) * sin(lon), cos(lat),\r\n			cos(lon) * cos(lat), sin(lon) * cos(lat), sin(lat);\r\n	\r\n	Eigen::Vector3d enu;\r\n	enu = ecef + t;\r\n	enu = r * enu;\r\n	return enu;\r\n}\r\n\r\n//这俩函数自己稍微改一下\r\nstatic inline double deg2rad(const double &deg) {\r\n		return deg * DEG_TO_RAD;\r\n};\r\nstatic inline double rad2deg(const double &rad) {\r\n    return rad / DEG_TO_RAD;\r\n}\r\n```\r\n\r\n### 3、RTK定位分析\r\n\r\n​	本节三张图即为测试结果，一图是GPS位置+IMU姿态，二图是有RTK，三图为厘米级RTK。我们的测试场地是两栋大楼之间即侧面的路段，其中无RTK的那段路为经过楼道。\r\n\r\n​	可以看到小车运动轨迹符合预期，虽然数据质量确实不太好。姿态yaw角朝车头方向，**这里惯导输出的yaw角可能会和车头有一个固定的夹角**（M_PI或者M_PI/2），需要注意。我这里面对ins输出的yaw角转为弧度之后，取M_PI/2 - yaw才拿到车头方向。\r\n\r\n![image-20200109195054318](37gnss-localizer/image-20200109195054318.png)\r\n\r\n综合分析，在园区等GPS信号不太好的情况下，组合导航就显得比较鸡肋了，但是用来作为点云定位初始化还是比较普遍的。\r\n\r\n![image-20200109195107057](37gnss-localizer/image-20200109195107057.png)\r\n\r\n## 三、致谢\r\n\r\n参考：INS550D、MD-649说明手册\r\n\r\n感谢：一清创新RAMLAB、导远电子程工、中科院自动化所飞哥、主线科技刘工、哈工大刘博等\r\n\r\n', 0, 0, 0, 1, '2021-05-09 11:43:11', 4, 1);
INSERT INTO `article` VALUES (18, '自动驾驶实战系列(六)——网格地图的动态加载', NULL, '# 自动驾驶实战系列(六)——网格地图的动态加载\r\n\r\n在第二篇中我们划分好了点云的网格地图并可视化出来，本章主要讲解点云地图的动态加载原理及实现过程，最后说明动态加载需要注意的一些问题．水平有限，难免有错误和疏漏，可在文章下方评论说明．\r\n\r\n![image-20200121102920572](39dynamic_map_loader/image-20200121102920572.png)\r\n\r\n<!-- more-->\r\n\r\n接上一篇，对点云地图进行网格划分\r\n\r\n<a href=\"http://xchu.net/2019/10/30/32pcd-divider/\"  class=\"LinkCard\">自动驾驶实战系列(二)——点云地图划分网格并可视化</a>\r\n\r\n## 一、主要思路\r\n\r\n​	要实现在定位过程中动态加载相应的网格点云，需要接收当前的GPS位置，确定当前位置的网格点云，考虑当前位置在网格的边界时，我们可以预定义一个margin距离，在当前网格周围margin范围内的网格点云均为需要加载的区域．基本的原理我在下面画了一个简图．\r\n\r\n> 举例子，当前的网格size为100米，当前汽车的XY位置为(340，210)，首先可以确定汽车当前位置所在网格左下角坐标为(300，200)，这样我们就可以很轻松得根据PCD文件名加载当前的网格点云．之后根据margin大小，以当前网格的四个顶点坐标为基准，向四周扩展margin范围，将此范围内的所有网格地图加载出来即可．如图，最多加载9块，要加载的区域是x_min-margin，x_max+margin，y_min-margin，y_max+margin\r\n\r\n## ![xy](39dynamic_map_loader/xy.jpg)二、实现过程\r\n\r\n由于这部分的工程基本上没什么难度，我将主要在代码注释里面加以说明\r\n\r\n```c++\r\nconstexpr double MARGIN_UNIT = 100; // meter\r\n\r\ngps_tools_.lla_origin_ << origin_latitude, origin_longitude, origin_altitude;//地图起点，后续lla转xyz\r\n\r\nif (grid_size == \"noupdate\") //是否动态更新\r\n    margin = -1;\r\nelse if (grid_size == \"1x1\")\r\n    margin = 0;\r\nelse if (grid_size == \"3x3\")\r\n    margin = MARGIN_UNIT * 1;\r\nelse if (grid_size == \"5x5\")\r\n    margin = MARGIN_UNIT * 2;\r\nelse if (grid_size == \"7x7\")\r\n    margin = MARGIN_UNIT * 3;\r\nelse if (grid_size == \"9x9\")\r\n    margin = MARGIN_UNIT * 4;\r\nelse {\r\n    std::cout << \"grid_size 有误...\" << std::endl;\r\n    return EXIT_FAILURE;\r\n}\r\n```\r\n\r\n读网格点云地图，并记录文件名\r\n\r\n```c++\r\nstd::string front_path;\r\n\r\ngetAllFiles(area_directory, pcd_paths); //获取pcd文件\r\nif (pcd_paths.size() == 0) {\r\n    return EXIT_FAILURE;\r\n}\r\n\r\nint pos = pcd_paths[0].find_last_of(\'/\');//获取路径前缀\r\nstd::string path_name(pcd_paths[0].substr(0, pos + 1));\r\nfront_path = path_name;\r\n\r\nif (margin < 0) {\r\n    can_download = false; //不在线下载\r\n} else {\r\n    can_download = false; //分块更新\r\n\r\n    for (const std::string &path : pcd_paths) {\r\n        int pos = path.find_last_of(\'/\');\r\n        std::string file_name(path.substr(pos + 1));\r\n        pcd_names.push_back(file_name);\r\n    }\r\n}\r\n```\r\n\r\npub和sub\r\n\r\n```c++\r\nins_pub = n.advertise<nav_msgs::Odometry>(\"/gps_odom\", 5, false);\r\npcd_pub = n.advertise<sensor_msgs::PointCloud2>(\"localmap\", 5, true);\r\nstat_pub = n.advertise<std_msgs::Bool>(\"pmap_stat\", 1, true);//加载状态\r\n\r\nstat_msg.data = false;\r\nstat_pub.publish(stat_msg);\r\n```\r\n\r\n校验一下csv文件中读取到的pcd文件是否存在\r\n\r\n```c++\r\nif (margin < 0) {\r\n    int err = 0;\r\n    publish_pcd(create_pcd(pcd_paths, &err), &err); //不分块\r\n} else {\r\n    std::cout << \"can_download... \" << std::endl;\r\n\r\n    n.param<int>(\"points_map_loader/update_rate\", update_rate, DEFAULT_UPDATE_RATE);\r\n    fallback_rate = update_rate * 2; \r\n\r\n    gnss_sub = n.subscribe(\"/novatel718d/pos\", 5, publish_gnss_pcd); //有更新\r\n    \r\n    if (can_download) {\r\n        AreaList areas = read_arealist(arealist_path); //读取csv记录的pcd文件\r\n\r\n        for (const Area &area : areas) {\r\n            for (const std::string &path : pcd_names) {\r\n                if (path == area.path) {\r\n                    // 将csv记录的并且文件夹中有的pcd文件，放进downloaded_areas中\r\n                    cache_arealist(area, downloaded_areas);\r\n                }\r\n            }\r\n    }\r\n    gnss_time = current_time = ros::Time::now();//当前时间，以gnss为准\r\n}\r\n```\r\n\r\n读取csv文件，并查找\r\n\r\n```c++\r\nstruct Area {\r\n    std::string path;\r\n    double x_min;\r\n    double y_min;\r\n    double z_min;\r\n    double x_max;\r\n    double y_max;\r\n    double z_max;\r\n};\r\n\r\ntypedef std::vector<Area> AreaList;   \r\ntypedef std::vector<std::vector<std::string>> Tbl;\r\n \r\nAreaList read_arealist(const std::string &path) {\r\n    Tbl tbl = read_csv(path);　//逐行读取\r\n\r\n    AreaList ret;　//用定义的area重新封装\r\n    for (const std::vector<std::string> &cols : tbl) {\r\n        Area area;\r\n        area.path = cols[0];\r\n        area.x_min = std::stod(cols[1]);\r\n        area.y_min = std::stod(cols[2]);\r\n        area.z_min = std::stod(cols[3]);\r\n        area.x_max = std::stod(cols[4]);\r\n        area.y_max = std::stod(cols[5]);\r\n        area.z_max = std::stod(cols[6]);\r\n        ret.push_back(area);\r\n    }\r\n    return ret;\r\n}\r\n\r\nTbl read_csv(const std::string &path) {//逐行读取csv文件\r\n    std::ifstream ifs(path.c_str());\r\n    std::string line;\r\n    Tbl ret;\r\n    while (std::getline(ifs, line)) {\r\n        std::istringstream iss(line);\r\n        std::string col;\r\n        std::vector<std::string> cols;\r\n        while (std::getline(iss, col, \',\'))\r\n            cols.push_back(col);\r\n        ret.push_back(cols);\r\n    }\r\n    return ret;\r\n}\r\n\r\nvoid cache_arealist(const Area &area, AreaList &areas) {\r\n    for (const Area &a : areas) {//没有的话加入\r\n        if (a.path == area.path)\r\n            return;\r\n    }\r\n    areas.push_back(area);\r\n}\r\n```\r\n\r\n最后是根据gps位置更新，进行坐标转换\r\n\r\n```c++\r\nvoid publish_gnss_pcd(const sensor_msgs::NavSatFixPtr &gps_msg) {\r\n    if (std::isnan(gps_msg->latitude + gps_msg->longitude + gps_msg->altitude)) {\r\n        ROS_INFO(\"GPS LLA NAN...\");\r\n        return;\r\n    }\r\n    if (gps_msg->status.status == 4 || gps_msg->status.status == 5 || gps_msg->status.status == 1 ||\r\n        gps_msg->status.status == 2) {\r\n\r\n        ros::Time now = ros::Time::now();//注意更新频率是否符合预定要求\r\n        if (((now - current_time).toSec() * 1000) < fallback_rate)\r\n            return;\r\n        if (((now - gnss_time).toSec() * 1000) < update_rate)\r\n            return;\r\n        gnss_time = now;\r\n\r\n        Eigen::Vector3d lla = gps_tools_.GpsMsg2Eigen(*gps_msg);\r\n        Eigen::Vector3d ecef = gps_tools_.LLA2ECEF(lla);\r\n        Eigen::Vector3d enu = gps_tools_.ECEF2ENU(ecef);\r\n        gps_tools_.gps_pos_ = enu;\r\n        gps_pos_ = enu;\r\n\r\n        geometry_msgs::Point pose;\r\n        pose.x = gps_pos_(0);\r\n        pose.y = gps_pos_(1);\r\n        pose.z = gps_pos_(2);\r\n\r\n        std::cout << \"area  lla : \" << gps_pos_(0) << \", \" << gps_pos_(1) << \", \" << gps_pos_(2)<< std::endl;\r\n        publish_pcd(create_pcd(pose));　//pub当前的网格\r\n}\r\n```\r\n\r\n根据位置去查询相应的网格地图\r\n\r\n```c++\r\nsensor_msgs::PointCloud2 create_pcd(const geometry_msgs::Point &p) {\r\n\r\n    sensor_msgs::PointCloud2 pcd, part;\r\n    std::unique_lock<std::mutex> lock(downloaded_areas_mtx);\r\n\r\n    for (const Area &area : downloaded_areas) {//遍历一下\r\n        if (is_in_area(p.x, p.y, area, margin)) { //判断当前位置在哪些网格里面\r\n            std::string pcd_name = front_path + area.path;//实际的PCD文件路径\r\n\r\n            if (pcd.width == 0)\r\n            pcl::io::loadPCDFile(pcd_name.c_str(), pcd);\r\n            else {\r\n                std::cout << \"success load: \" << area.path << std::endl;\r\n                pcl::io::loadPCDFile(pcd_name.c_str(), pcd);\r\n\r\n                pcd.width += part.width;　//所有符合条件的网格全pub出来\r\n                pcd.row_step += part.row_step;\r\n                pcd.data.insert(pcd.data.end(), part.data.begin(), part.data.end());\r\n            }\r\n        }\r\n    }\r\n    return pcd;\r\n}\r\n```\r\n\r\n判断当前位置是否在此Area里面\r\n\r\n```c++\r\nbool is_in_area(double x, double y, const Area &area, double m) {\r\n    return ((area.x_min - m) <= x && x <= (area.x_max + m) && (area.y_min - m) <= y && y <= (area.y_max + m));\r\n}\r\n```\r\n\r\n这里我们根据连续的GPS位置计算一个实时的yaw角，来大致观察车辆的运动轨迹．\r\n\r\n```c++\r\n//   pub gps odom\r\nnav_msgs::Odometry odom;\r\nodom.header.stamp = gnss_time;\r\nodom.header.frame_id = \"map\";\r\n\r\nodom.pose.pose.position.x = gps_pos_(0);\r\nodom.pose.pose.position.y = gps_pos_(1);\r\nodom.pose.pose.position.z = gps_pos_(2);\r\n\r\ndouble distance = sqrt(pow(odom.pose.pose.position.y - _prev_pose.pose.position.y, 2) + pow(odom.pose.pose.position.x - _prev_pose.pose.position.x, 2));\r\nif (distance > 0.2) {\r\n    //返回值是此点与远点连线与x轴正方向的夹角\r\n    yaw = atan2(odom.pose.pose.position.y - _prev_pose.pose.position.y,\r\n    odom.pose.pose.position.x - _prev_pose.pose.position.x);\r\n    _quat = tf::createQuaternionMsgFromYaw(yaw);\r\n    _prev_pose = odom.pose;\r\n}\r\nodom.pose.pose.orientation = _quat;\r\n\r\nodom.child_frame_id = \"base_link\";\r\nodom.twist.twist.linear.x = 0.0;\r\nodom.twist.twist.linear.y = 0.0;\r\nodom.twist.twist.angular.z = 0.0;\r\n\r\nins_pub.publish(odom);\r\n} else {\r\n	ROS_INFO(\"no rtk, map stop update...\");\r\n}\r\n```\r\n\r\n## 三、最终效果及评价\r\n\r\n![image-20200121154246788](39dynamic_map_loader/image-20200121154246788.png)\r\n\r\n**最终效果**\r\n\r\n最后看一下打印出来的log，当前车辆的LLA位置为(-174.828，-1210.92，9.50905)，加载的网格地图为300_-300_-1200.pcd，由于我这里设定的网格大小为300米，margin为100米，所有只需要加载一个网格．\r\n\r\n**总结一下**\r\n\r\n动态加载的主要作用是大地图时减少内存空间，拿IO换内存．\r\n\r\n> 比如10km*10km级别的地图，size为1km，一共100块网格，每次加载一块网格的话，地图占用内存就会减少到原来的1/100．\r\n\r\n特别需要注意，如果网格size过小，划分网格太多，频繁的加载网格，IO以及内存分配会消耗大量的资源，反而会拖慢整个定位的速度，最终得不偿失．所以我们的网格size一般是1km级别的，对大地图作用明显，小地图就没有动态加载的必要了．\r\n\r\n## 四、致谢\r\n\r\n- Autoware.AI\r\n- Autocore陈晨\r\n- 一清创新RAMLAB\r\n\r\n', 0, 0, 0, 1, '2021-05-09 11:43:45', 4, 1);
INSERT INTO `article` VALUES (20, 'Kmeans算法实例', NULL, '\r\n> 上一篇文章讲解了[数据挖掘环境的配置](https://mp.weixin.qq.com/s?__biz=MzUzOTczMTQyOA==&mid=2247483674&idx=1&sn=97a4e277bd69caf303aa8c10a594bed1&chksm=fac2b591cdb53c87cc213c7083068bf72ed40b6ca32e92a0a9fae22520f8174bff137c6c4a76#rd)，那这次就从一个小的实战开始吧。这次要学习的是KMeans算法，要挑战的是sofasofa上的一个竞赛（交通事故理赔审核预测）。现在开始吧\r\n\r\n# K-means\r\n### 介绍\r\nK-Means是基于划分的聚类方法，他是数据挖掘十大算法之一。基于划分的方法是将样本集组成的矢量空间划分为多个区域，每个区域都存在一个样本中心，通过建立映射关系，可以将所有样本分类到其相应的中心。\r\n![kmeans](http://ox5bam95j.bkt.clouddn.com/74656887.jpg)\r\n假设有样本集合D={Xj}，KMeans算法的目标是将数据划分为K类：S={S1,S2,...Sk}，并且使划分后的K个子集合满足类内误差平方和最小。\r\n目标函数：![目标函数](http://ox5bam95j.bkt.clouddn.com/TIM%E5%9B%BE%E7%89%8720180521195832.jpg)\r\n其中 ![](http://ox5bam95j.bkt.clouddn.com/TIM%E5%9B%BE%E7%89%8720180521195823.jpg)\r\nCi即划分后的子集合的中心。\r\n\r\n### 求解步骤\r\n求解目标函数是一个NP-hard问题，无法保证得到的就是全局最优解。在经典K-Means聚类算法中采取迭代优化策略，一般包含以下四个步骤\r\n- 1.初始化聚类中心\r\n- 2.分配个样本xj到相近的聚类集合，依据是（p!=j）![](http://ox5bam95j.bkt.clouddn.com/TIM%E5%9B%BE%E7%89%8720180521195836.jpg)\r\n- 3.根据步骤二结果，更新聚类中心。![](http://ox5bam95j.bkt.clouddn.com/TIM%E5%9B%BE%E7%89%8720180521195839.jpg)\r\n- 4.若达到最大迭代步数或两次迭代差小于设定的阈值则算法结束，否则重复步骤2。\r\n\r\n![迭代过程](http://ox5bam95j.bkt.clouddn.com/K-means_convergence.gif)\r\n### 算法改进\r\n经典的K-means算法在初始化聚类中心时采用的是随机采样的方式，不能保证得到期望的聚类结果，可以选择重复训练多个模型，选取其中表现最好的。但有没有更好的方法呢？David Arthur提出的K-means++算法能够有效的产生初始化的聚类中心。<br>\r\n首先随机初始化一个聚类中心C1，然后通过迭代计算最大概率值X*，将其加入到中心点中，重复该过程，直到选择k个中心。![](http://ox5bam95j.bkt.clouddn.com/TIM%E5%9B%BE%E7%89%8720180521201847.jpg)\r\n\r\n# 交通事故理赔审核预测\r\n> SofaSofa是专门为数据挖掘新人准备练手比赛的地方，这的比赛都会提供几个标杆模型的代码给你参考，新手想要快速入门可以多去这个网站上看看。\r\n\r\n### 赛题\r\n这个比赛的链接：http://sofasofa.io/competition.php?id=2\r\n- 任务类型：二元分类\r\n- 背景介绍：在交通摩擦（事故）发生后，理赔员会前往现场勘察、采集信息，这些信息往往影响着车主是否能够得到保险公司的理赔。训练集数据包括理赔人员在现场对该事故方采集的36条信息，信息已经被编码，以及该事故方最终是否获得理赔。我们的任务是根据这36条信息预测该事故方没有被理赔的概率。 \r\n- 数据介绍：\r\n![](http://ox5bam95j.bkt.clouddn.com/TIM%E6%88%AA%E5%9B%BE20180521202537.jpg)\r\n\r\n- 评价方法：Precision-Recall AUC\r\n\r\n### 代码\r\n在官方下载好数据集，在本地解压。打开jupyter notebook开始动手。\r\n首先导入必要的包\r\n``` Python\r\nimport pandas as pd\r\nimport numpy as np\r\nimport os\r\nimport matplotlib.pyplot as plt\r\n%matplotlib inline\r\n```\r\n读入数据集\r\n``` Python\r\nhomePath = \"data\"\r\ntrainPath = os.path.join(homePath, \"train.csv\")\r\ntestPath = os.path.join(homePath, \"test.csv\")\r\nsubmitPath = os.path.join(homePath, \"sample_submit.csv\")\r\ntrainData = pd.read_csv(trainPath)\r\ntestData = pd.read_csv(testPath)\r\nsubmitData = pd.read_csv(submitPath)\r\n```\r\n参照数据说明，CaseID这列是没有意义的编号，因此这里将他丢弃。\r\n- ~drop()函数：`axis`指沿着哪个轴，0为行，1为列；`inplace`指是否在原数据上直接操作\r\n``` Python\r\n# 去掉没有意义的一列\r\ntrainData.drop(\"CaseId\", axis=1, inplace=True)\r\ntestData.drop(\"CaseId\", axis=1, inplace=True)\r\n```\r\n快速了解数据\r\n- ~head()：默认显示前5行数据，可指定显示多行，例如.head(50)显示前50行\r\n``` Python\r\ntrainData.head()\r\n```\r\n![](http://ox5bam95j.bkt.clouddn.com/TIM%E6%88%AA%E5%9B%BE20180521204059.jpg)\r\n显示数据简略信息，可以每列有多少非空的值，以及每列数据对应的数据类型。\r\n``` Python\r\ntrainData.info()\r\n```\r\n![](http://ox5bam95j.bkt.clouddn.com/TIM%E6%88%AA%E5%9B%BE20180521204325.jpg)\r\n以图的形式，快速了解数据\r\n- ~hist():绘制直方图，参数`figsize`可指定输出图片的尺寸。\r\n- 关于绘图可参考我之前的一篇文章，[一文教会你使用Matplotlib绘图](https://mp.weixin.qq.com/s?__biz=MzUzOTczMTQyOA==&mid=2247483654&idx=1&sn=39c1b07182e8dec43a3512626213a5e2&chksm=fac2b58dcdb53c9b6e6f392b4c493ba5eb98e0cf25bd8fe0b1aa9bbbc2c37644c9674a2e9d98#rd)\r\n``` Python\r\ntrainData.hist(figsize=(20, 20))\r\n```\r\n![](http://ox5bam95j.bkt.clouddn.com/shujutu.png)\r\n想要了解特征之间的相关性，可计算相关系数矩阵。然后可对某个特征来排序。\r\n``` Python\r\ncorr_matrix = trainData.corr()\r\ncorr_matrix[\"Evaluation\"].sort_values(ascending=False) # ascending=False 降序排列\r\n```\r\n![](http://ox5bam95j.bkt.clouddn.com/TIM%E6%88%AA%E5%9B%BE20180521205257.jpg)\r\n从训练集中分离标签\r\n``` Python\r\ny = trainData[\'Evaluation\']\r\ntrainData.drop(\"Evaluation\", axis=1, inplace=True)\r\n```\r\n使用K-Means训练模型\r\n-  KMeans()：`n_clusters`指要预测的有几个类；`init`指初始化中心的方法，默认使用的是`k-means++`方法，而非经典的K-means方法的随机采样初始化，当然你可以设置为`random`使用随机初始化；`n_jobs`指定使用CPU核心数，-1为使用全部CPU。\r\n``` Python\r\nfrom sklearn.cluster import KMeans\r\nest = KMeans(n_clusters=2, init=\"k-means++\", n_jobs=-1)\r\nest.fit(trainData, y)\r\ny_pred = est.predict(testData)\r\n```\r\n保存预测的结果\r\n``` Python\r\nsubmitData[\'Evaluation\'] = y_pred\r\nsubmitData.to_csv(\"submit_data.csv\", index=False)\r\n```\r\n现在你可以在运行目录找到这个文件，在比赛网站上可提交查看实际分数。\r\n\r\n# 标杆模型：随机森林\r\n使用K-means可能得到的结果没那么理想。在官网上，举办方给出了两个标杆模型，效果最好的是随机森林。以下是代码，读者可以自己测试。\r\n``` Python\r\n# -*- coding: utf-8 -*-\r\nimport pandas as pd\r\nfrom sklearn.ensemble import RandomForestClassifier\r\n\r\n# 读取数据\r\ntrain = pd.read_csv(\"data/train.csv\")\r\ntest = pd.read_csv(\"data/test.csv\")\r\nsubmit = pd.read_csv(\"data/sample_submit.csv\")\r\n\r\n# 删除id\r\ntrain.drop(\'CaseId\', axis=1, inplace=True)\r\ntest.drop(\'CaseId\', axis=1, inplace=True)\r\n\r\n# 取出训练集的y\r\ny_train = train.pop(\'Evaluation\')\r\n\r\n# 建立随机森林模型\r\nclf = RandomForestClassifier(n_estimators=100, random_state=0)\r\nclf.fit(train, y_train)\r\ny_pred = clf.predict_proba(test)[:, 1]\r\n\r\n# 输出预测结果至my_RF_prediction.csv\r\nsubmit[\'Evaluation\'] = y_pred\r\nsubmit.to_csv(\'my_RF_prediction.csv\', index=False)\r\n```\r\n# 总结\r\nK-means算法是数据挖掘的十大经典算法之一，但实际中如果想要得到满意的效果，还是非常难的，以后会讲到集成学习，使弱学习器进阶为强学习器。\r\n\r\n\r\n> 关于数据挖掘的更多内容，我将持续更新在该项目，欢迎感兴趣的朋友赏个star：https://github.com/wmpscc/DataMiningNotesAndPractice\r\n\r\n', 3, 0, 0, 0, '2021-05-10 14:03:15', 0, 1);
INSERT INTO `article` VALUES (21, 'Matplotlib介绍', NULL, '> 整理翻译自[该项目](https://github.com/ageron/handson-ml/blob/master/tools_matplotlib.ipynb)\r\n## Matplotlib\r\n可能还有小伙伴不知道`Matplotlib`是什么，下面是维基百科的介绍。\r\n> Matplotlib 是Python编程语言的一个绘图库及其数值数学扩展 NumPy。它为利用通用的图形用户界面工具包，如Tkinter, wxPython, Qt或GTK+向应用程序嵌入式绘图提供了面向对象的应用程序接口。\r\n\r\n简单说就是画图的工具包。本文将教会你如何使用`Matplotlib`绘图，如果你没有`Python`基础也没关系，依葫芦画瓢也完全OK的。关于如何安装Python以及Matplotlib，文末有链接。\r\n## 绘制第一个图\r\n\r\n- 如果给`plot`函数一个一维数组，则将该数组作为纵轴坐标，并且将数组中的每个数据点索引作为水平坐标\r\n``` python\r\nimport matplotlib.pyplot as plt\r\nplt.plot([1, 2, 4, 9, 5, 3])\r\nplt.show()\r\n```\r\n![1](http://ox5bam95j.bkt.clouddn.com/1.png)\r\n\r\n- 如果提供两个数组，则将其分别作为x轴和y轴\r\n``` Python\r\nplt.plot([-3, -2, 5, 0], [1, 6, 4, 3])\r\nplt.show()\r\n```\r\n![2](http://ox5bam95j.bkt.clouddn.com/2.png)\r\n\r\n- 坐标轴会自动匹配数据的范围，不过我们可以调用`axis`函数来改变每个轴的范围`[xmin, xmax, ymin, ymax]`\r\n``` Python\r\nplt.plot([-3, -2, 5, 0], [1, 6, 4, 3])\r\nplt.axis([-4, 6, 0, 7])\r\nplt.show()\r\n```\r\n![3](http://ox5bam95j.bkt.clouddn.com/3.png)\r\n\r\n\r\n- 我们用NumPy\'s的`linspace`函数在范围[-2, 2]内创建包含500个浮点数的数组`x`，计算数组`x`的平方作为数组`y`\r\n``` Python\r\nimport numpy as np\r\nx = np.linspace(-2, 2, 500)\r\ny = x**2\r\n\r\nplt.plot(x, y)\r\nplt.show()\r\n```\r\n![4](http://ox5bam95j.bkt.clouddn.com/4.png)\r\n\r\n- 添加标题，x、y轴标签，并绘制网格\r\n``` Python\r\nplt.plot(x, y)\r\nplt.title(\"Square function\")\r\nplt.xlabel(\"x\")\r\nplt.ylabel(\"y = x**2\")\r\nplt.grid(True)\r\nplt.show()\r\n```\r\n![5](http://ox5bam95j.bkt.clouddn.com/5.png)\r\n\r\n## 线条样式和颜色\r\n- 默认情况下,matplotlib在连续的点之间绘制一条线。\r\n``` Python\r\nplt.plot([0, 100, 100, 0, 0, 100, 50, 0, 100], [0, 0, 100, 100, 0, 100, 130, 100, 0])\r\nplt.axis([-10, 110, -10, 140])\r\nplt.show()\r\n```\r\n![6](http://ox5bam95j.bkt.clouddn.com/6.png)\r\n\r\n- 可在第三个参数更改线条的样式和颜色，比如“g--”表示“绿色虚线”\r\n``` Python\r\nplt.plot([0, 100, 100, 0, 0, 100, 50, 0, 100], [0, 0, 100, 100, 0, 100, 130, 100, 0], \"g--\")\r\nplt.axis([-10, 110, -10, 140])\r\nplt.show()\r\n```\r\n![7](http://ox5bam95j.bkt.clouddn.com/7.png)\r\n\r\n- 你可以绘制多条线在同一个图上，仅仅通过重复`x1, y1, [style1], x2, y2, [style2], ...`\r\n``` python\r\nplt.plot([0, 100, 100, 0, 0], [0, 0, 100, 100, 0], \"r-\", [0, 100, 50, 0, 100], [0, 100, 130, 100, 0], \"g--\")\r\nplt.axis([-10, 110, -10, 140])\r\nplt.show()\r\n```\r\n![8](http://ox5bam95j.bkt.clouddn.com/8.png)\r\n\r\n\r\n- 也可以在`show`之前`plot`多次\r\n``` python\r\nplt.plot([0, 100, 100, 0, 0], [0, 0, 100, 100, 0], \"r-\")\r\nplt.plot([0, 100, 50, 0, 100], [0, 100, 130, 100, 0], \"g--\")\r\nplt.axis([-10, 110, -10, 140])\r\nplt.show()\r\n```\r\n![9](http://ox5bam95j.bkt.clouddn.com/9.png)\r\n\r\n- 你也可以绘制点而不只是绘制直线\r\n``` python\r\nx = np.linspace(-1.4, 1.4, 30)\r\nplt.plot(x, x, \'g--\', x, x**2, \'r:\', x, x**3, \'b^\')\r\nplt.show()\r\n```\r\n![10](http://ox5bam95j.bkt.clouddn.com/10.png)\r\n#### 接受以下格式字符来控制线条样式或标记\r\ncharacter	| description\r\n-------|-------\r\n\'-\'	| solid line style\r\n\'--\'	| dashed line style\r\n\'-.\'	| dash-dot line style\r\n\':\'	| dotted line style\r\n\'.\'	| point marker\r\n\',\'	| pixel marker\r\n\'o\'	| circle marker\r\n\'v\'	| triangle_down marker\r\n\'^\'	| triangle_up marker\r\n\'<\'	| triangle_left marker\r\n\'>\'	| triangle_right marker\r\n\'1\'	| tri_down marker\r\n\'2\'	| tri_up marker\r\n\'3\'	| tri_left marker\r\n\'4\'	| tri_right marker\r\n\'s\'	| square marker\r\n\'p\'	| pentagon marker\r\n\'*\'	| star marker\r\n\'h\'	| hexagon1 marker\r\n\'H\'	| hexagon2 marker\r\n\'+\'	| plus marker\r\n\'x\'	| x marker\r\n\'D\'	| diamond marker\r\n\'d\'	| thin_diamond marker\r\n\'|\'	| vline marker\r\n\'_\'	| hline marker\r\n\r\n#### 支持以下颜色缩写\r\n|character |	color|\r\n|------|-------|\r\n|‘b’	| blue|\r\n|‘g’	| green|\r\n|‘r’	| red|\r\n|‘c’	| cyan|\r\n|‘m’	| magenta|\r\n|‘y’	| yellow|\r\n|‘k’	| black|\r\n|‘w’	| white|\r\n\r\n\r\n- `plot`函数会返回一个`Line2D`对象列表，你可以额外设置一些属性，例如线的宽度，虚线风格等等。\r\n``` Python\r\nx = np.linspace(-1.4, 1.4, 30)\r\nline1, line2, line3 = plt.plot(x, x, \'g--\', x, x**2, \'r:\', x, x**3, \'b^\')\r\nline1.set_linewidth(3.0)\r\nline1.set_dash_capstyle(\"round\")\r\nline3.set_alpha(0.2)\r\nplt.show()\r\n```\r\n![11](http://ox5bam95j.bkt.clouddn.com/11.png)\r\n\r\n#### `Line2D`属性\r\n|Property	| Value Type|\r\n|-------|-----|\r\n|alpha	| float|\r\n|animated |	[True / False]|\r\n|antialiased or aa |	[True / False]|\r\n|clip_box	| a matplotlib.transform.Bbox instance|\r\n|clip_on |	[True | False]|\r\n|clip_path |	a Path instance and a Transform instance, a Patch|\r\n|color or c |	any matplotlib color|\r\n|contains |	the hit testing function|\r\n|dash_capstyle |	[\'butt\' / \'round\' / \'projecting\']|\r\n|dash_joinstyle |	[\'miter\' / \'round\' / \'bevel\']|\r\n|dashes |	sequence of on/off ink in points|\r\n|data	| (np.array xdata, np.array ydata)|\r\n|figure	| a matplotlib.figure.Figure instance|\r\n|label	| any string|\r\n|linestyle or ls |	[ \'-\' / \'--\' / \'-.\' / \':\' / \'steps\' / ...]|\r\n|linewidth or lw	| float value in points|\r\n|lod	| [True / False]|\r\n|marker	| [ \'+\' / \',\' / \'.\' / \'1\' / \'2\' / \'3\' / \'4\' ]|\r\n|markeredgecolor or mec	| any matplotlib color|\r\n|markeredgewidth or mew	| float value in points|\r\n|markerfacecolor or mfc	| any matplotlib color|\r\n|markersize or ms	| float|\r\n|markevery	| [ None / integer / (startind, stride) ]|\r\n|picker	| used in interactive line selection|\r\n|pickradius	| the line pick selection radius|\r\n|solid_capstyle	| [\'butt\' / \'round\' / \'projecting\']|\r\n|solid_joinstyle	| [\'miter\' / \'round\' / \'bevel\']|\r\n|transform	| a matplotlib.transforms.Transform instance|\r\n|visible	| [True / False]|\r\n|xdata	| np.array|\r\n|ydata	| np.array|\r\n|zorder	| any number|\r\n\r\n## 保存图像\r\n\r\n- 可使用savefig函数保存图像\r\n``` python\r\nsavefig(fname, dpi=None, facecolor=\'w\', edgecolor=\'w\',\r\n        orientation=\'portrait\', papertype=None, format=None,\r\n        transparent=False, bbox_inches=None, pad_inches=0.1,\r\n        frameon=None)\r\n```\r\n参数\r\n- fname:&nbsp; 包含文件名的路径字符串\r\n- dpi: [ None | scalar > 0 | ‘figure’]\r\n- format:&nbsp; 文件扩展名，大多数后端支持` png, pdf, ps, eps and svg`\r\n- transparent:&nbsp; 如果为True则轴部分的背景透明。\r\n\r\n示例\r\n``` Python\r\nx = np.linspace(-1.4, 1.4, 30)\r\nplt.plot(x, x**2)\r\nplt.savefig(\"my_square_function.png\", transparent=True)\r\n```\r\n![12](http://ox5bam95j.bkt.clouddn.com/12.png)\r\n\r\n## 组合图\r\n- 一个图可能需要包含多个子图，那么如何操作呢。要创建子图其实只需调用子图函数，并制定图中的行数和列数，以及要绘制的子图的索引（从1开始，然后从左到右，从上到下）。注意,pyplot会跟踪当前活动的子图（您可以调用`plt.gca()`来获得引用，可以借此添加额外属性），因此当您调用绘图函数时，它会绘制活动的子图。\r\n- 注意：`subplot(224)`是`subplot(2, 2, 4)`的缩写。\r\n``` python\r\nx = np.linspace(-1.4, 1.4, 30)\r\nplt.subplot(2, 2, 1)  # 2 rows, 2 columns, 1st subplot = top left\r\nplt.plot(x, x)\r\nplt.subplot(2, 2, 2)  # 2 rows, 2 columns, 2nd subplot = top right\r\nplt.plot(x, x**2)\r\nplt.subplot(2, 2, 3)  # 2 rows, 2 columns, 3rd subplot = bottow left\r\nplt.plot(x, x**3)\r\nplt.subplot(224)  # 2 rows, 2 columns, 4th subplot = bottom right\r\nplt.plot(x, x**4)\r\nplt.show()\r\n```\r\n![13](http://ox5bam95j.bkt.clouddn.com/13.png)\r\n\r\n- 创建跨多个网格单元的子图也很容易\r\n``` Python\r\nplt.subplot(2, 2, 1)  # 2 rows, 2 columns, 1st subplot = top left\r\nplt.plot(x, x)\r\nplt.subplot(2, 2, 2)  # 2 rows, 2 columns, 2nd subplot = top right\r\nplt.plot(x, x**2)\r\nplt.subplot(2, 1, 2)  # 2 rows, *1* column, 2nd subplot = bottom\r\nplt.plot(x, x**3)\r\nplt.show()\r\n```\r\n![14](http://ox5bam95j.bkt.clouddn.com/14.png)\r\n\r\n- 如果你需要更复杂的子图定位，你可以使用`subplot2grid`，你可以指定格子行数和列数，然后在格子上绘制子图(左上 = (0, 0))，并且可以指定它能跨越多少行和多少列。\r\n``` Python\r\nplt.subplot2grid((3,3), (0, 0), rowspan=2, colspan=2)\r\nplt.plot(x, x**2)\r\nplt.subplot2grid((3,3), (0, 2))\r\nplt.plot(x, x**3)\r\nplt.subplot2grid((3,3), (1, 2), rowspan=2)\r\nplt.plot(x, x**4)\r\nplt.subplot2grid((3,3), (2, 0), colspan=2)\r\nplt.plot(x, x**5)\r\nplt.show()\r\n```\r\n![15](http://ox5bam95j.bkt.clouddn.com/15.png)\r\n- 如果需要更灵活的子图定位，[看这里](https://matplotlib.org/users/gridspec.html)\r\n\r\n\r\n## 绘制文本\r\n- 你可以调用`call`在图像任意位置添加文本。仅需指定坐标选择一些额外属性。关于TeX方程表达式的细节[看这里](https://matplotlib.org/users/mathtext.html)\r\n``` Python\r\nx = np.linspace(-1.5, 1.5, 30)\r\npx = 0.8\r\npy = px**2\r\n\r\nplt.plot(x, x**2, \"b-\", px, py, \"ro\")\r\n\r\nplt.text(0, 1.5, \"Square function\\n$y = x^2$\", fontsize=20, color=\'blue\', horizontalalignment=\"center\")\r\nplt.text(px - 0.08, py, \"Beautiful point\", ha=\"right\", weight=\"heavy\") # ha是horizontalalignment的别名。\r\nplt.text(px, py, \"x = %0.2f\\ny = %0.2f\"%(px, py), rotation=50, color=\'gray\')\r\n\r\nplt.show()\r\n```\r\n![20](http://ox5bam95j.bkt.clouddn.com/20.png)\r\n\r\n- 图像元素的注释使用非常频繁，`annotate`函数使得它非常简单，只需指定兴趣点的位置、文本的位置，加上文字和箭头的一些额外属性就能完成。\r\n``` Python\r\nplt.plot(x, x**2, px, py, \"ro\")\r\nplt.annotate(\"Beautiful point\", xy=(px, py), xytext=(px-1.3,py+0.5),\r\n                           color=\"green\", weight=\"heavy\", fontsize=14,\r\n                           arrowprops={\"facecolor\": \"lightgreen\"})\r\nplt.show()\r\n```\r\n![21](http://ox5bam95j.bkt.clouddn.com/21.png)\r\n\r\n- 你可以使用`bbox`属性在文本周围加上框。\r\n``` Python\r\nplt.plot(x, x**2, px, py, \"ro\")\r\n\r\nbbox_props = dict(boxstyle=\"rarrow,pad=0.3\", ec=\"b\", lw=2, fc=\"lightblue\")\r\nplt.text(px-0.2, py, \"Beautiful point\", bbox=bbox_props, ha=\"right\")\r\n\r\nbbox_props = dict(boxstyle=\"round4,pad=1,rounding_size=0.2\", ec=\"black\", fc=\"#EEEEFF\", lw=5)\r\nplt.text(0, 1.5, \"Square function\\n$y = x^2$\", fontsize=20, color=\'black\', ha=\"center\", bbox=bbox_props)\r\n\r\nplt.show()\r\n```\r\n![22](http://ox5bam95j.bkt.clouddn.com/22.png)\r\n\r\n- 如果为了好玩可以绘制漫画风格的图(xkcd-style)，只需在`with plt.xkcd()`内写代码就好。\r\n``` Python\r\nwith plt.xkcd():\r\n    plt.plot(x, x**2, px, py, \"ro\")\r\n\r\n    bbox_props = dict(boxstyle=\"rarrow,pad=0.3\", ec=\"b\", lw=2, fc=\"lightblue\")\r\n    plt.text(px-0.2, py, \"Beautiful point\", bbox=bbox_props, ha=\"right\")\r\n\r\n    bbox_props = dict(boxstyle=\"round4,pad=1,rounding_size=0.2\", ec=\"black\", fc=\"#EEEEFF\", lw=5)\r\n    plt.text(0, 1.5, \"Square function\\n$y = x^2$\", fontsize=20, color=\'black\', ha=\"center\", bbox=bbox_props)\r\n\r\n    plt.show()\r\n```\r\n![23](http://ox5bam95j.bkt.clouddn.com/23.png)\r\n\r\n## 图例\r\n- 添加图例最简单的方法是在对应位置添加标签，然后调用`legend`函数\r\n``` Python\r\nx = np.linspace(-1.4, 1.4, 50)\r\nplt.plot(x, x**2, \"r--\", label=\"Square function\")\r\nplt.plot(x, x**3, \"g-\", label=\"Cube function\")\r\nplt.legend(loc=\"best\")\r\nplt.grid(True)\r\nplt.show()\r\n```\r\n![24](http://ox5bam95j.bkt.clouddn.com/24.png)\r\n\r\n## 非线性尺度\r\n- Matplotlib支持非线性尺度，例如对数或logit尺度\r\n``` Python\r\nx = np.linspace(0.1, 15, 500)\r\ny = x**3/np.exp(2*x)\r\n\r\nplt.figure(1)\r\nplt.plot(x, y)\r\nplt.yscale(\'linear\')\r\nplt.title(\'linear\')\r\nplt.grid(True)\r\n\r\nplt.figure(2)\r\nplt.plot(x, y)\r\nplt.yscale(\'log\')\r\nplt.title(\'log\')\r\nplt.grid(True)\r\n\r\nplt.figure(3)\r\nplt.plot(x, y)\r\nplt.yscale(\'logit\')\r\nplt.title(\'logit\')\r\nplt.grid(True)\r\n\r\nplt.figure(4)\r\nplt.plot(x, y - y.mean())\r\nplt.yscale(\'symlog\', linthreshy=0.05)\r\nplt.title(\'symlog\')\r\nplt.grid(True)\r\n\r\nplt.show()\r\n```\r\n![25](http://ox5bam95j.bkt.clouddn.com/25.png)\r\n![26](http://ox5bam95j.bkt.clouddn.com/26.png)\r\n![27](http://ox5bam95j.bkt.clouddn.com/27.png)\r\n![28](http://ox5bam95j.bkt.clouddn.com/28.png)\r\n\r\n## Ticks and tickers 刻度和刻度控制器\r\n- \"ticks\"是刻度的位置 (例如 (-1, 0, 1))，\"tick lines\"是在这些位置绘制的小线条(刻度线)，\"tick labels\"实在刻度线旁边绘制的标签(刻度线标签)。\"tickers\" 是决定在哪能放置刻度的对象，默认的tickers通常在合理的距离放置5到8个刻度。但有时候你需要控制它，幸运的是，matplotlib可以让你完全控制刻度。\r\n``` Python\r\nx = np.linspace(-2, 2, 100)\r\n\r\nplt.figure(1, figsize=(15,10))\r\nplt.subplot(131)\r\nplt.plot(x, x**3)\r\nplt.grid(True)\r\nplt.title(\"Default ticks\")\r\n\r\nax = plt.subplot(132)\r\nplt.plot(x, x**3)\r\nax.xaxis.set_ticks(np.arange(-2, 2, 1))\r\nplt.grid(True)\r\nplt.title(\"Manual ticks on the x-axis\")\r\n\r\nax = plt.subplot(133)\r\nplt.plot(x, x**3)\r\nplt.minorticks_on()\r\nax.tick_params(axis=\'x\', which=\'minor\', bottom=\'off\')\r\nax.xaxis.set_ticks([-2, 0, 1, 2])\r\nax.yaxis.set_ticks(np.arange(-5, 5, 1))\r\nax.yaxis.set_ticklabels([\"min\", -4, -3, -2, -1, 0, 1, 2, 3, \"max\"])\r\nplt.title(\"Manual ticks and tick labels\\n(plus minor ticks) on the y-axis\")\r\n\r\n\r\nplt.grid(True)\r\n\r\nplt.show()\r\n```\r\n![29](http://ox5bam95j.bkt.clouddn.com/29.png)\r\n\r\n## 极坐标投影\r\n- 绘制极坐标图，只需在创建子图时，设定\"projection\"属性为\"polar\"即可。\r\n``` Python\r\nradius = 1\r\ntheta = np.linspace(0, 2*np.pi*radius, 1000)\r\n\r\nplt.subplot(111, projection=\'polar\')\r\nplt.plot(theta, np.sin(5*theta), \"g-\")\r\nplt.plot(theta, 0.5*np.cos(20*theta), \"b-\")\r\nplt.show()\r\n```\r\n![30](http://ox5bam95j.bkt.clouddn.com/30.png)\r\n\r\n## 3D投影\r\n- 绘制3D图像非常直接，你需要导入`Axes3D`，以注册`3d`投影。然后设定`projection`属性为`3d`。它将返回一个`Axes3DSubplot`对象，你可以调用`plot_surface`，给定x,y和z坐标加额外的属性来绘制。\r\n``` Python\r\nfrom mpl_toolkits.mplot3d import Axes3D\r\n\r\nx = np.linspace(-5, 5, 50)\r\ny = np.linspace(-5, 5, 50)\r\nX, Y = np.meshgrid(x, y)\r\nR = np.sqrt(X**2 + Y**2)\r\nZ = np.sin(R)\r\n\r\nfigure = plt.figure(1, figsize = (12, 4))\r\nsubplot3d = plt.subplot(111, projection=\'3d\')\r\nsurface = subplot3d.plot_surface(X, Y, Z, rstride=1, cstride=1, cmap=matplotlib.cm.coolwarm, linewidth=0.1)\r\nplt.show()\r\n```\r\n![31](http://ox5bam95j.bkt.clouddn.com/31.png)\r\n\r\n- 显示相同数据的另外一种方法是用等高线图\r\n``` Python\r\nplt.contourf(X, Y, Z, cmap=matplotlib.cm.coolwarm)\r\nplt.colorbar()\r\nplt.show()\r\n```\r\n![32](http://ox5bam95j.bkt.clouddn.com/32.png)\r\n\r\n## 散点图\r\n- 提供x和y的坐标就可以绘制散点图。\r\n``` Python\r\nfrom numpy.random import rand\r\nx, y = rand(2, 100)\r\nplt.scatter(x, y)\r\nplt.show()\r\n```\r\n![33](http://ox5bam95j.bkt.clouddn.com/33.png)\r\n\r\n- 你也可以提供每个点的比例\r\n``` Python\r\nx, y, scale = rand(3, 100)\r\nscale = 500 * scale ** 5\r\nplt.scatter(x, y, s=scale)\r\nplt.show()\r\n```\r\n![34](http://ox5bam95j.bkt.clouddn.com/34.png)\r\n\r\n- 还可以设置些额外的属性，例如填充颜色、边缘颜色、透明度。\r\n``` Python\r\nfor color in [\'red\', \'green\', \'blue\']:\r\n    n = 100\r\n    x, y = rand(2, n)\r\n    scale = 500.0 * rand(n) ** 5\r\n    plt.scatter(x, y, s=scale, c=color, alpha=0.3, edgecolors=\'blue\')\r\n\r\nplt.grid(True)\r\n\r\nplt.show()\r\n```\r\n![35](http://ox5bam95j.bkt.clouddn.com/35.png)\r\n\r\n## 直线（工具函数）\r\n- 创建一个工具函数来画图通常会更方便，该函数会在给定斜率和截距的情况下在图上绘制一条看似无限长的线。\r\n``` Python\r\nfrom numpy.random import randn\r\n\r\ndef plot_line(axis, slope, intercept, **kargs):\r\n    xmin, xmax = axis.get_xlim()\r\n    plt.plot([xmin, xmax], [xmin*slope+intercept, xmax*slope+intercept], **kargs)\r\n\r\nx = randn(1000)\r\ny = 0.5*x + 5 + randn(1000)*2\r\nplt.axis([-2.5, 2.5, -5, 15])\r\nplt.scatter(x, y, alpha=0.2)\r\nplt.plot(1, 0, \"ro\")\r\nplt.vlines(1, -5, 0, color=\"red\")\r\nplt.hlines(0, -2.5, 1, color=\"red\")\r\nplot_line(axis=plt.gca(), slope=0.5, intercept=5, color=\"magenta\")\r\nplt.grid(True)\r\nplt.show()\r\n```\r\n![36](http://ox5bam95j.bkt.clouddn.com/36.png)\r\n\r\n## 直方图\r\n``` Python\r\ndata = [1, 1.1, 1.8, 2, 2.1, 3.2, 3, 3, 3, 3]\r\nplt.subplot(211)\r\nplt.hist(data, bins = 10, rwidth=0.8)\r\n\r\nplt.subplot(212)\r\nplt.hist(data, bins = [1, 1.5, 2, 2.5, 3], rwidth=0.95)\r\nplt.xlabel(\"Value\")\r\nplt.ylabel(\"Frequency\")\r\n\r\nplt.show()\r\n```\r\n![37](http://ox5bam95j.bkt.clouddn.com/37.png)\r\n\r\n``` Python\r\ndata1 = np.random.randn(400)\r\ndata2 = np.random.randn(500) + 3\r\ndata3 = np.random.randn(450) + 6\r\ndata4a = np.random.randn(200) + 9\r\ndata4b = np.random.randn(100) + 10\r\n\r\nplt.hist(data1, bins=5, color=\'g\', alpha=0.75, label=\'bar hist\') # default histtype=\'bar\'\r\nplt.hist(data2, color=\'b\', alpha=0.65, histtype=\'stepfilled\', label=\'stepfilled hist\')\r\nplt.hist(data3, color=\'r\', histtype=\'step\', label=\'step hist\')\r\nplt.hist((data4a, data4b), color=(\'r\',\'m\'), alpha=0.55, histtype=\'barstacked\', label=(\'barstacked a\', \'barstacked b\'))\r\n\r\nplt.xlabel(\"Value\")\r\nplt.ylabel(\"Frequency\")\r\nplt.legend()\r\nplt.grid(True)\r\nplt.show()\r\n```\r\n![38](http://ox5bam95j.bkt.clouddn.com/38.png)\r\n\r\n## 图像\r\n- 读取图像；仅需导入`matplotlib.image`moudle，再调用`imread`函数(传入文件名)，它将以NumPy\'s数组形式返回图像数据。\r\n``` Python\r\nimport matplotlib.image as mpimg\r\n\r\nimg = mpimg.imread(\'my_square_function.png\')\r\nprint(img.shape, img.dtype)\r\n# Out:(288, 432, 4) float32\r\n```\r\n- 生成图像也很简单\r\n``` Python\r\nimg = np.arange(100*100).reshape(100, 100)\r\nprint(img)\r\nplt.imshow(img)\r\nplt.show()\r\n```\r\n![41](http://ox5bam95j.bkt.clouddn.com/41.png)\r\n- 由于我们没有提供RGB等级，`imshow`函数自动将值映射到颜色渐变。默认情况，颜色渐变从蓝色(低值)变为红色(高值)，但你可以选择其他颜色映射。例如：\r\n``` Python\r\nplt.imshow(img, cmap=\"hot\")\r\nplt.show()\r\n```\r\n![42](http://ox5bam95j.bkt.clouddn.com/42.png)\r\n\r\n- 你也可以直接产生RGB图像\r\n``` Python\r\nimg = np.empty((20,30,3))\r\nimg[:, :10] = [0, 0, 0.6]\r\nimg[:, 10:20] = [1, 1, 1]\r\nimg[:, 20:] = [0.6, 0, 0]\r\nplt.imshow(img)\r\nplt.show() \r\n```\r\n![43](http://ox5bam95j.bkt.clouddn.com/43.png)\r\n\r\n- 由于img数组非常小（20x30），所以当imshow函数显示它时，它会将图像增大图像的大小。 默认情况下，它使用双线性插值来填充所添加的像素。 这就是边缘看起来模糊的原因。 您可以选择另一种插值算法，例如复制最近像素的颜色：\r\n``` Python\r\nplt.imshow(img, interpolation=\"nearest\")\r\nplt.show()\r\n```\r\n![44](http://ox5bam95j.bkt.clouddn.com/44.png)\r\n\r\n\r\n## 动画\r\n### 绘制\r\n- `FuncAnimation`构造函数接受一个图形，一个更新函数和可选参数。 我们指定我们需要一个100帧长的动画，每帧之间有20ms。 在每次迭代中，FuncAnimation调用我们的更新函数，并将帧号传递给`num`（在我们的例子中是从0到99），接着是我们用`fargs`指定额外的参数。\r\n- 我们的更新函数简单地将行数据设置为第一个数据点（所以数据将逐渐绘制），并且为了好玩，我们还为每个数据点添加一个小的随机数，这样该行似乎在摆动。\r\n``` Python\r\nimport matplotlib.animation as animation\r\n\r\nx = np.linspace(-1, 1, 100)\r\ny = np.sin(x**2*25)\r\ndata = np.array([x, y])\r\n\r\nfig = plt.figure()\r\nline, = plt.plot([], [], \"r-\") # start with an empty plot\r\nplt.axis([-1.1, 1.1, -1.1, 1.1])\r\nplt.plot([-0.5, 0.5], [0, 0], \"b-\", [0, 0], [-0.5, 0.5], \"b-\", 0, 0, \"ro\")\r\nplt.grid(True)\r\nplt.title(\"Marvelous animation\")\r\n\r\n# this function will be called at every iteration\r\ndef update_line(num, data, line):\r\n    line.set_data(data[..., :num] + np.random.rand(2, num) / 25)  # we only plot the first `num` data points.\r\n    return line,\r\n\r\nline_ani = animation.FuncAnimation(fig, update_line, frames=100, fargs=(data, line), interval=67)\r\nplt.show()\r\n```\r\n\r\n### 保存\r\n- Matplotlib依靠第三方库来编写视频，如FFMPEG或mencoder。 在这个例子中，我们将使用FFMPEG，所以一定要先安装它。\r\n``` Python\r\nWriter = animation.writers[\'ffmpeg\']\r\nwriter = Writer(fps=15, metadata=dict(artist=\'Me\'), bitrate=1800)\r\nline_ani.save(\'my_wiggly_animation.mp4\', writer=writer)\r\n```\r\n\r\n## 更多\r\n[Matplotlib](https://matplotlib.org/gallery.html)官网\r\n\r\n[安装Python以及Matplotlib](http://blog.csdn.net/sinat_28224453/article/details/51462935)\r\n\r\n', 1, 2, 0, 1, '2021-05-10 14:03:53', 0, 1);
INSERT INTO `article` VALUES (22, 'Numpy学习笔记', NULL, '本文是我在学习过程中收集的numpy方法，并做了记录。\r\n\r\n## NumPy 方法\r\n### np.ceil(x, y)           限制元素范围\r\n- x 输入的数据\r\n- y float型，每个元素的上限\r\n``` Python\r\nhousing[\"income_cat\"] = np.ceil(housing[\"median_income\"] / 1.5)     # 每个元素都除1.5\r\n```\r\n\r\n### permutation(x) 随机生成一个排列或返回一个range\r\n如果x是一个多维数组，则只会沿着它的第一个索引进行混洗。\r\n``` Python\r\nimport numpy as np\r\n\r\nshuffle_index = np.random.permutation(60000)\r\nX_train, y_train = X_train[shuffle_index], y_train[shuffle_index]\r\n```\r\n### numpy.argmax() 返回沿轴的最大值的索引\r\n返回沿轴的最大值的索引。\r\n``` Python\r\n# some_digit_scores 内容\r\n# array([[-311402.62954431, -363517.28355739, -446449.5306454 ,\r\n#         -183226.61023518, -414337.15339485,  161855.74572176,\r\n#         -452576.39616343, -471957.14962573, -518542.33997148,\r\n#         -536774.63961222]])\r\nnp.argmax(some_digit_scores)\r\n# Out\r\n# 5\r\n```\r\n- a : array_like;   输入数组\r\n- axis : int, optional;   默认情况下，索引是放在平面数组中，否则沿着指定的轴。\r\n- out : array, optional;    如果提供，结果将被插入到这个数组中。它应该是适当的形状和dtype。\r\n\r\n\r\n### np.linalg.inv()&nbsp;计算矩阵的逆\r\n``` Python\r\nX_b = np.c_[np.ones((100, 1)), X]  # add x0 = 1 to each instance\r\ntheta_best = np.linalg.inv(X_b.T.dot(X_b)).dot(X_b.T).dot(y)\r\n```\r\n- a : (..., M, M) array_like；被求逆的矩阵\r\n\r\n### numpy.dot(a, b, out=None)&nbsp;计算两个数组的点积\r\n``` Python\r\n>>> np.dot(3, 4)\r\n12\r\n\r\n# Neither argument is complex-conjugated:\r\n>>> np.dot([2j, 3j], [2j, 3j])\r\n(-13+0j)\r\n\r\n# For 2-D arrays it is the matrix product:\r\n>>> a = [[1, 0], [0, 1]]\r\n>>> b = [[4, 1], [2, 2]]\r\n>>> np.dot(a, b)\r\narray([[4, 1],\r\n       [2, 2]])\r\n\r\n>>> a = np.arange(3*4*5*6).reshape((3,4,5,6))\r\n>>> b = np.arange(3*4*5*6)[::-1].reshape((5,4,6,3))\r\n>>> np.dot(a, b)[2,3,2,1,2,2]\r\n499128\r\n>>> sum(a[2,3,2,:] * b[1,2,:,2])\r\n499128\r\n```\r\n- a : array_like；First argument.\r\n- b : array_like；Second argument.\r\n\r\n### numpy.ndarray.T()&nbsp;计算矩阵的转置\r\n与`self.transpose()`相同，如果`self.ndim < 2`则返回它自身。\r\n``` Python\r\n>>> x = np.array([[1.,2.],[3.,4.]])\r\n>>> x\r\narray([[ 1.,  2.],\r\n       [ 3.,  4.]])\r\n>>> x.T\r\narray([[ 1.,  3.],\r\n       [ 2.,  4.]])\r\n>>> x = np.array([1.,2.,3.,4.])\r\n>>> x\r\narray([ 1.,  2.,  3.,  4.])\r\n>>> x.T\r\narray([ 1.,  2.,  3.,  4.])\r\n```\r\n\r\n### numpy.random.seed()&nbsp;生成器种子\r\n该方法由` RandomState`初始化，它可以被重新设置。\r\n``` Python\r\nnp.random.seed(42)\r\ntheta = np.random.randn(2,1)  # random initialization\r\n```\r\n- seed : int or array_like, optional；必须为32位无符号整数。\r\n\r\n\r\n### numpy.random.randn()&nbsp;从标准正太分布返回样本\r\n``` Python\r\n>>> theta = np.random.randn(2,1)\r\narray([[ 4.21509616],\r\n       [ 2.77011339]])\r\n```\r\n###### 参数\r\n- d0, d1, ..., dn : int, optional；返回的数组维度，应该都是正值。如果没有给出，将返回一个Python float值。\r\n\r\n###### 返回值\r\n- Z : ndarray or float；一个经过标准正态分布抽样的，`(d0, d1, ..., dn)`维度的浮点数组。\r\n\r\n### numpy.array()&nbsp;创建一个数组\r\n``` Python\r\ntheta_path_bgd = np.array(theta_path_bgd)\r\ntheta_path_sgd = np.array(theta_path_sgd)\r\ntheta_path_mgd = np.array(theta_path_mgd)\r\n```\r\n- object : array_like\r\n- dtype : data-type, optional\r\n\r\n### numpy.random.rand()&nmbsp;生成给定shap的随机值\r\n``` Python\r\nm = 100\r\nX = 6 * np.random.rand(m, 1) - 3\r\ny = 0.5 * X**2 + X + 2 + np.random.randn(m, 1)\r\n```\r\n``` Python\r\n>>> np.random.rand(3,2)\r\narray([[ 0.14022471,  0.96360618],  #random\r\n       [ 0.37601032,  0.25528411],  #random\r\n       [ 0.49313049,  0.94909878]]) #random\r\n```\r\n- d0, d1, ..., dn : int, optional；返回的数组维度，必须是正值。如果为空，则返回一个Python float值。\r\n\r\n### numpy.linspace()&nbsp;在指定区间返回间隔均匀的样本[start, stop]\r\n``` Python\r\nX_new=np.linspace(-3, 3, 100).reshape(100, 1)\r\nX_new_poly = poly_features.transform(X_new)\r\ny_new = lin_reg.predict(X_new_poly)\r\nplt.plot(X, y, \"b.\")\r\nplt.plot(X_new, y_new, \"r-\", linewidth=2, label=\"Predictions\")\r\nplt.xlabel(\"$x_1$\", fontsize=18)\r\nplt.ylabel(\"$y$\", rotation=0, fontsize=18)\r\nplt.legend(loc=\"upper left\", fontsize=14)\r\nplt.axis([-3, 3, 0, 10])\r\nsave_fig(\"quadratic_predictions_plot\")\r\nplt.show()\r\n```\r\n- start : scalar；序列的起始值\r\n- stop : scalar；序列的结束值\r\n- num : int, optional；要生成的样本数量，默认为50个。\r\n- endpoint : bool, optional；若为True则包括结束值，否则不包括结束值，即[start, stop)区间。默认为True。\r\n- dtype : dtype, optional；输出数组的类型，若未给出则从输入数据推断类型。\r\n\r\n### meshgrid()&nbsp; 从坐标向量返回坐标矩阵\r\n``` Python\r\n>>> nx, ny = (3, 2)\r\n>>> x = np.linspace(0, 1, nx)\r\n>>> y = np.linspace(0, 1, ny)\r\n>>> xv, yv = np.meshgrid(x, y)\r\n>>> xv\r\narray([[ 0. ,  0.5,  1. ],\r\n       [ 0. ,  0.5,  1. ]])\r\n>>> yv\r\narray([[ 0.,  0.,  0.],\r\n       [ 1.,  1.,  1.]])\r\n>>> xv, yv = np.meshgrid(x, y, sparse=True)  # make sparse output arrays\r\n>>> xv\r\narray([[ 0. ,  0.5,  1. ]])\r\n>>> yv\r\narray([[ 0.],\r\n       [ 1.]])\r\n```\r\n- x1, x2,..., xn : array_like；代表网格坐标的一维数组。\r\n- indexing : {‘xy’, ‘ij’}, optional；输出的笛卡儿（\'xy\'，默认）或矩阵（\'ij\'）索引。\r\n- sparse : bool, optional；如果为True则返回稀疏矩阵以减少内存，默认为False。\r\n### norm()&nbsp; 矩阵或向量范数\r\n``` Python\r\nt1a, t1b, t2a, t2b = -1, 3, -1.5, 1.5\r\n\r\n# ignoring bias term\r\nt1s = np.linspace(t1a, t1b, 500)\r\nt2s = np.linspace(t2a, t2b, 500)\r\nt1, t2 = np.meshgrid(t1s, t2s)\r\nT = np.c_[t1.ravel(), t2.ravel()]\r\nXr = np.array([[-1, 1], [-0.3, -1], [1, 0.1]])\r\nyr = 2 * Xr[:, :1] + 0.5 * Xr[:, 1:]\r\n\r\nJ = (1/len(Xr) * np.sum((T.dot(Xr.T) - yr.T)**2, axis=1)).reshape(t1.shape)\r\n\r\nN1 = np.linalg.norm(T, ord=1, axis=1).reshape(t1.shape)\r\nN2 = np.linalg.norm(T, ord=2, axis=1).reshape(t1.shape)\r\n\r\nt_min_idx = np.unravel_index(np.argmin(J), J.shape)\r\nt1_min, t2_min = t1[t_min_idx], t2[t_min_idx]\r\n\r\nt_init = np.array([[0.25], [-1]])\r\n```\r\n- x : array_like；输入的数组，如果`axis`是None，则`x`必须是1-D或2-D。\r\n- ord : {non-zero int, inf, -inf, ‘fro’, ‘nuc’}, optional；范数的顺序，inf表示numpy的inf对象。\r\n- axis : {int, 2-tuple of ints, None}, optional\r\n- keepdims : bool, optional\r\n\r\n以下范数可以被计算：\r\n| ord |	norm for matrices |	norm for vectors|\r\n|--|--|--|\r\n|None	| Frobenius norm | 	2-norm|\r\n|‘fro’	| Frobenius norm |	–|\r\n|‘nuc’	| nuclear norm	| –|\r\n|inf	| max(sum(abs(x), axis=1)) |	max(abs(x))|\r\n|-inf	| min(sum(abs(x), axis=1))	| min(abs(x))|\r\n|0	| –	| sum(x != 0)|\r\n|1	| max(sum(abs(x), axis=0)) |	as below|\r\n|-1	| min(sum(abs(x), axis=0))	| as below|\r\n|2	| 2-norm (largest sing. value)	| as below|\r\n|-2	| smallest singular value	| as below|\r\n|other |	–	| sum(abs(x)**ord)**(1./ord)|\r\n\r\n对于`ord <= 0`的值，它严格来说不是数学规范的范数，但它作为数值目的任然有用。\r\n### unravel_index()&nbsp; 将平面索引或平面索引数组转换为坐标数组的元组\r\n``` Python\r\n>>> np.unravel_index([22, 41, 37], (7,6))\r\n(array([3, 6, 6]), array([4, 5, 1]))\r\n>>> np.unravel_index([31, 41, 13], (7,6), order=\'F\')\r\n(array([3, 6, 6]), array([4, 5, 1]))\r\n\r\n>>> np.unravel_index(1621, (6,7,8,9))\r\n(3, 1, 4, 1)\r\n```\r\n- indices : array_like；一个整数数组，其元素是索引到维数组dims的平坦版本中。\r\n- dims : tuple of ints；用于分解索引的数组的形状。\r\n- order : {‘C’, ‘F’}, optional；决定`indices`应该按row-major (C-style) or column-major (Fortran-style) 顺序。\r\n\r\n### mean()&nbsp; 计算沿指定轴的算术平均值\r\n``` Python\r\n>>> a = np.array([[1, 2], [3, 4]])\r\n>>> np.mean(a)\r\n2.5\r\n>>> np.mean(a, axis=0)\r\narray([ 2.,  3.])\r\n>>> np.mean(a, axis=1)\r\narray([ 1.5,  3.5])\r\n\r\n\r\n>>> a = np.zeros((2, 512*512), dtype=np.float32)\r\n>>> a[0, :] = 1.0\r\n>>> a[1, :] = 0.1\r\n>>> np.mean(a)\r\n0.54999924\r\n```\r\n- a : array_like；包含要求平均值的数组，如果不是数组，则尝试进行转换。\r\n- axis : None or int or tuple of ints, optional；计算平均值的轴，默认计算扁平数组。\r\n- dtype : data-type, optional；用于计算平均值的类型。\r\n- out : ndarray, optional\r\n\r\n', 1, 1, 0, 1, '2021-05-10 14:04:21', 0, 1);
INSERT INTO `article` VALUES (23, 'Pandas学习笔记', NULL, '## Pandas 方法\r\n### pd.read_csv(csv_path)   读入csv文件\r\n读入csv文件，一般用于返回~\r\n### ~head()                 获取前五行数据\r\n供快速参考。\r\n### ~info()                 迅速获取数据描述\r\n获取总行数、每个属性的类型、非空值的数量。\r\n### ~value_counts()         获取每个值出现的次数\r\n\r\n``` Python\r\nhousing[\"ocean_proximity\"].value_counts()\r\n\r\n# 输出\r\n<1H OCEAN     9136\r\nINLAND        6551\r\nNEAR OCEAN    2658\r\nNEAR BAY      2290\r\nISLAND           5\r\nName: ocean_proximity, dtype: int64\r\n```\r\n### pd.set_option()         设置指定的值\r\n[详细内容](http://python.usyiyi.cn/documents/Pandas_0j2/generated/pandas.set_option.html)\r\n\r\n设置最大输出行数\r\n``` Python\r\npd.set_option(\'max_rows\', 7) \r\n```\r\n\r\n\r\n### ~describe()             简要显示数据的数字特征\r\n例如：总数、平均值、标准差、最大值最小值、25%/50%/75%值\r\n\r\n### ~hist()                 以直方图形式绘制所有属性\r\nhist()方法依赖于Matplotlib，而Matplotlib又依赖于一个用户指定的图形后端去在你的屏幕上绘制。在Jupyter notebook中可用“%matplotlib inline”告诉Jupyter安装 Matplotlib使用时，使用Jupyter拥有的后端。\r\n\r\nJupyter中，show()方法是可选的，因为如果有图形需要输出，它会自动绘制。\r\n``` Python\r\n%matplotlib inline  # only in a Jupyter notebook\r\nimport matplotlib.pyplot as plt\r\nhousing.hist(bins=50, figsize=(20,15))\r\nsave_fig(\"attribute_histogram_plots\")\r\nplt.show()\r\n```\r\n\r\n### ~loc[]                  纯粹基于标签位置的索引器\r\n\r\n``` Python\r\nstrat_train_set = housing.loc[train_index]\r\nstrat_test_set = housing.loc[test_index]\r\n```\r\n\r\n### ~where()                通过判断自身的值来修改自身对应的值\r\n``` Python\r\nhousing[\"income_cat\"].where(housing[\"income_cat\"] < 5, 5.0, inplace=True)\r\n```\r\n- cond 如果为True则保持原始值，若为False则使用第二个参数other替换值。\r\n- other 替换的目标值\r\n- inplace 是否在数据上执行操作\r\n\r\n### pandas.DataFrame()      Pandas表格\r\n具有标签轴，且算术运算在行和列标签上对齐。\r\n``` Python\r\ncompare_props = pd.DataFrame({\r\n    \"Overall\": income_cat_proportions(housing),\r\n    \"Stratified\": income_cat_proportions(strat_test_set),\r\n    \"Random\": income_cat_proportions(test_set),\r\n}).sort_index()\r\ncompare_props[\"Rand. %error\"] = 100 * compare_props[\"Random\"] / compare_props[\"Overall\"] - 100\r\ncompare_props[\"Strat. %error\"] = 100 * compare_props[\"Stratified\"] / compare_props[\"Overall\"] - 100\r\n```\r\n\r\n### ~drop()\r\n返回删除了请求轴标签的新对象。\r\n``` Python\r\nfor set_ in (strat_train_set, strat_test_set):\r\n    set_.drop(\"income_cat\", axis=1, inplace=True)\r\n```\r\n- labels 索引或列标签\r\n- axis 从索引(0)，还是列(1)中删除\r\n- inplace 若为True则在原数据执行操作\r\n\r\n### ~corr()                 计算相关系数\r\n- method： 可选 {‘pearson’, ‘kendall’, ‘spearman’}\r\n  - pearson : standard correlation coefficient\r\n  - kendall : Kendall Tau correlation coefficient\r\n  - spearman : Spearman rank correlation\r\n- min_periods： Minimum number of observations required per pair of columns to have a valid result. Currently only available for pearson and spearman correlation\r\n\r\n``` Python\r\n# 计算标准相关系数\r\ncorr_matrix = housing.corr()\r\ncorr_matrix[\"median_house_value\"].sort_values(ascending=False)\r\n\r\n#输出：\r\n# median_house_value    1.000000\r\n# median_income         0.687160\r\n# total_rooms           0.135097\r\n# housing_median_age    0.114110\r\n# households            0.064506\r\n# total_bedrooms        0.047689\r\n# population           -0.026920\r\n# longitude            -0.047432\r\n# latitude             -0.142724\r\n# Name: median_house_value, dtype: float64\r\n\r\n```\r\n### scatter_matrix()        通过绘图比较相关性\r\n``` Python\r\nfrom pandas.plotting import scatter_matrix\r\n\r\nattributes = [\"median_house_value\", \"median_income\", \"total_rooms\",\r\n              \"housing_median_age\"]\r\nscatter_matrix(housing[attributes], figsize=(12, 8))\r\nsave_fig(\"scatter_matrix_plot\")\r\n```\r\n\r\n### ~dropna()               返回略去丢失数据部分后的剩余数据\r\nReturn object with labels on given axis omitted where alternately any or all of the data are missing\r\n``` Python\r\nsample_incomplete_rows.dropna(subset=[\"total_bedrooms\"])\r\n```\r\n\r\n### ~fillna()               用指定的方法填充\r\n``` Python\r\n# 用中位数填充\r\nmedian = housing[\"total_bedrooms\"].median()\r\nsample_incomplete_rows[\"total_bedrooms\"].fillna(median, inplace=True)\r\n```\r\n### ~factorize()            将数据转换为数值类型特征\r\n``` Python\r\nhousing_cat = housing[\'ocean_proximity\']\r\nhousing_cat.head(10)\r\n# 输出\r\n# 17606     <1H OCEAN\r\n# 18632     <1H OCEAN\r\n# 14650    NEAR OCEAN\r\n# 3230         INLAND\r\n# 3555      <1H OCEAN\r\n# 19480        INLAND\r\n# 8879      <1H OCEAN\r\n# 13685        INLAND\r\n# 4937      <1H OCEAN\r\n# 4861      <1H OCEAN\r\n# Name: ocean_proximity, dtype: object\r\n\r\nhousing_cat_encoded, housing_categories = housing_cat.factorize()\r\nhousing_cat_encoded[:10]\r\n# 输出\r\n# array([0, 0, 1, 2, 0, 2, 0, 2, 0, 0], dtype=int64)\r\n```', 0, 0, 0, 1, '2021-05-10 14:04:54', 0, 1);
INSERT INTO `article` VALUES (24, '数据挖掘前的预处理', NULL, '> 记录实战过程中在数据预处理环节用到的方法\r\n\r\n# 数据预处理\r\n\r\n\r\n## 常用方法\r\n#### 生成随机数序列\r\n``` Python\r\nrandIndex = random.sample(range(trainSize, len(trainData_copy)), 5*trainSize)\r\n```\r\n#### 计算某个值出现的次数\r\n``` Python\r\ntitleSet = set(titleData)\r\nfor i in titleSet:\r\n    count = titleData.count(i)\r\n```\r\n用文本出现的次数替换非空的地方。词袋模型 Word Count\r\n``` Python\r\ntitleData = allData[\'title\']\r\ntitleSet = set(list(titleData))\r\ntitle_counts = titleData.value_counts()\r\nfor i in titleSet:\r\n    if isNaN(i):\r\n        continue\r\n    count = title_counts[i]\r\n    titleData.replace(i, count, axis=0, inplace=True)\r\ntitle = pd.DataFrame(titleData)\r\nallData[\'title\'] = title\r\n```\r\n#### 判断值是否为NaN\r\n``` Python\r\ndef isNaN(num):\r\n    return num != num\r\n```\r\n#### Matplotlib在jupyter中显示图像\r\n``` \r\n%matplotlib inline\r\n```\r\n#### 处理日期\r\n``` Python\r\nbirth = trainData[\'birth_date\']\r\nbirthDate = pd.to_datetime(birth)\r\nend = pd.datetime(2018, 1, 1)\r\n# 计算天数\r\nbirthDay = end - birthDate\r\nbirthDay.astype(\'timedelta64[D]\')\r\n# timedelta64 转到 int64\r\ntrainData[\'birth_date\'] = birthDay.dt.days\r\n```\r\n\r\n#### 计算多列数的平均值等\r\n``` Python\r\ntrainData[\'operate_able\'] = trainData.iloc[ : , 20:53].mean(axis=1)\r\ntrainData[\'local_able\'] = trainData.iloc[ : , 53:64].mean(axis=1)\r\n```\r\n### 数据分列（对列进行one-hot）\r\n``` Python\r\ntrain_test = pd.get_dummies(train_test,columns=[\"Embarked\"])\r\ntrain_test = pd.get_dummies(train_test,columns = [\'SibSp\',\'Parch\',\'SibSp_Parch\']) \r\n```\r\n### 正则提取指定内容\r\ndf[\'Name].str.extract()是提取函数,配合正则一起使用\r\n``` Python\r\ntrain_test[\'Name1\'] = train_test[\'Name\'].str.extract(\'.+,(.+)\').str.extract( \'^(.+?)\\.\').str.strip()\r\n```\r\n### 根据数据是否缺失进行处理\r\n``` Python\r\ntrain_test.loc[train_test[\"Age\"].isnull() ,\"age_nan\"] = 1\r\ntrain_test.loc[train_test[\"Age\"].notnull() ,\"age_nan\"] = 0\r\n```\r\n\r\n### 按区间分割-数据离散化\r\n返回x所属区间的索引值，半开区间\r\n``` Python\r\n#将年龄划分四个阶段10以下,10-18,18-30,30-50,50以上\r\ntrain_test[\'Age\'] = pd.cut(train_test[\'Age\'], bins=[0,10,18,30,50,100],labels=[1,2,3,4,5])\r\n```\r\n\r\n\r\n\r\n## Numpy部分\r\n#### where索引列表\r\n``` Python\r\ndelLocal = np.array(np.where(np.array(trainData[\'acc_now_delinq\']) == 1))\r\n```\r\n#### permutation(x) 随机生成一个排列或返回一个range\r\n如果x是一个多维数组，则只会沿着它的第一个索引进行混洗。\r\n``` Python\r\nimport numpy as np\r\n\r\nshuffle_index = np.random.permutation(60000)\r\nX_train, y_train = X_train[shuffle_index], y_train[shuffle_index]\r\n```\r\n#### numpy.argmax() 返回沿轴的最大值的`索引`\r\n返回沿轴的最大值的索引。\r\n``` Python\r\nnp.argmax(some_digit_scores)\r\n```\r\n- a : array_like;   输入数组\r\n- axis : int, optional;   默认情况下，索引是放在平面数组中，否则沿着指定的轴。\r\n- out : array, optional;    如果提供，结果将被插入到这个数组中。它应该是适当的形状和dtype。\r\n#### numpy.dot(a, b, out=None)&nbsp;计算两个数组的点积\r\n``` Python\r\n>>> np.dot(3, 4)\r\n```\r\n#### numpy.random.randn()&nbsp;从标准正太分布返回样本\r\n``` Python\r\n>>> np.random.seed(42) # 可设置随机数种子\r\n>>> theta = np.random.randn(2,1)\r\narray([[ 4.21509616],\r\n       [ 2.77011339]])\r\n```\r\n参数\r\n- d0, d1, ..., dn : int, optional；返回的数组维度，应该都是正值。如果没有给出，将返回一个Python float值。\r\n\r\n### numpy.linspace()&nbsp;在指定区间返回间隔均匀的样本[start, stop]\r\n``` Python\r\nX_new=np.linspace(-3, 3, 100).reshape(100, 1)\r\nX_new_poly = poly_features.transform(X_new)\r\ny_new = lin_reg.predict(X_new_poly)\r\nplt.plot(X, y, \"b.\")\r\nplt.plot(X_new, y_new, \"r-\", linewidth=2, label=\"Predictions\")\r\nplt.xlabel(\"$x_1$\", fontsize=18)\r\nplt.ylabel(\"$y$\", rotation=0, fontsize=18)\r\nplt.legend(loc=\"upper left\", fontsize=14)\r\nplt.axis([-3, 3, 0, 10])\r\nsave_fig(\"quadratic_predictions_plot\")\r\nplt.show()\r\n```\r\n- start : scalar；序列的起始值\r\n- stop : scalar；序列的结束值\r\n- num : int, optional；要生成的样本数量，默认为50个。\r\n- endpoint : bool, optional；若为True则包括结束值，否则不包括结束值，即[start, stop)区间。默认为True。\r\n- dtype : dtype, optional；输出数组的类型，若未给出则从输入数据推断类型。\r\n\r\n\r\n\r\n\r\n## Pandas部分\r\n#### Jupyter notebook中设置最大显示行列数\r\n``` Python\r\npd.set_option(\'display.max_columns\', 64)\r\npd.set_option(\'display.max_rows\', 1000000)\r\n```\r\n\r\n#### 读入数据\r\n``` Python\r\nhomePath = \'game\'\r\ntrainPath = os.path.join(homePath, \'train.csv\')\r\ntestPath = os.path.join(homePath, \'test.csv\')\r\ntrainData = pd.read_csv(trainPath)\r\ntestData = pd.read_csv(testPath)\r\n```\r\n\r\n#### 数据简单预览\r\n- ~head()\r\n获取前五行数据，供快速参考。\r\n- ~info()\r\n获取总行数、每个属性的类型、非空值的数量。\r\n- ~value_counts()\r\n获取每个值出现的次数\r\n- ~hist()\r\n直方图的形式展示数值型数据\r\n- ~describe()\r\n简要显示数据的数字特征；例如：总数、平均值、标准差、最大值最小值、25%/50%/75%值\r\n\r\n#### 拷贝数据\r\n``` Python\r\nmthsMajorTest = fullData.copy()\r\n```\r\n#### 数据相关性\r\n- 计算相关性矩阵\r\n``` Python\r\ncorrMatrix = trainData.corr()\r\ncorrMatrix[\'acc_now_delinq\'].sort_values(ascending=False) # 降序排列\r\n```\r\n- 相关系数矩阵图\r\n``` Python\r\nimport numpy\r\ncorrelations = data.corr()  #计算变量之间的相关系数矩阵\r\n# plot correlation matrix\r\nfig = plt.figure() #调用figure创建一个绘图对象\r\nax = fig.add_subplot(111)\r\ncax = ax.matshow(correlations, vmin=-1, vmax=1)  #绘制热力图，从-1到1\r\nfig.colorbar(cax)  #将matshow生成热力图设置为颜色渐变条\r\nticks = numpy.arange(0,9,1) #生成0-9，步长为1\r\nax.set_xticks(ticks)  #生成刻度\r\nax.set_yticks(ticks)\r\nax.set_xticklabels(names) #生成x轴标签\r\nax.set_yticklabels(names)\r\nplt.show()\r\n```\r\n颜色越深表明二者相关性越强\r\n\r\n#### 删除某列\r\n``` Python\r\ntrainData.drop(\'acc_now_delinq\', axis=1, inplace=True)\r\n```\r\n``` Python\r\n# 此方法并不会从内存中释放内存\r\ndel fullData[\'member_id\']\r\n```\r\n#### 列表类型转换\r\n``` Python\r\ntermData = list(map(int, termData))\r\n```\r\n#### 替换数据\r\n``` Python\r\ngradeData.replace([\'A\',\'B\',\'C\',\'D\',\'E\',\'F\',\'G\'], [7,6,5,4,3,2,1],inplace=True)\r\n```\r\n\r\n#### 数据集合并\r\n``` Python\r\nallData = trainData.append(testData)\r\n```\r\n``` Python\r\nallData = pd.concat([trainData, testData], axis=0, ignore_index=True)\r\n```\r\n\r\n#### 分割\r\n``` Python\r\ntermData = termData.str.split(\' \', n=2, expand=True)[1]\r\n```\r\n\r\n#### ~where() 相当于三目运算符( ? : )\r\n通过判断自身的值来修改自身对应的值，相当于三目运算符( ? : )\r\n``` Python\r\nhousing[\"income_cat\"].where(housing[\"income_cat\"] < 5, 5.0, inplace=True)\r\n```\r\n- cond 如果为True则保持原始值，若为False则使用第二个参数other替换值。\r\n- other 替换的目标值\r\n- inplace 是否在数据上执行操作\r\n#### np.ceil(x, y) 限制元素范围\r\n- x 输入的数据\r\n- y float型，每个元素的上限\r\n``` Python\r\nhousing[\"income_cat\"] = np.ceil(housing[\"median_income\"] / 1.5)     # 每个元素都除1.5\r\n```\r\n#### ~loc[]                  纯粹基于标签位置的索引器\r\n\r\n``` Python\r\nstrat_train_set = housing.loc[train_index]\r\nstrat_test_set = housing.loc[test_index]\r\n```\r\n\r\n#### ~dropna()               返回略去丢失数据部分后的剩余数据\r\nReturn object with labels on given axis omitted where alternately any or all of the data are missing\r\n``` Python\r\nsample_incomplete_rows.dropna(subset=[\"total_bedrooms\"])\r\n```\r\n\r\n#### ~fillna()               用指定的方法填充\r\n``` Python\r\n# 用中位数填充\r\nmedian = housing[\"total_bedrooms\"].median()\r\nsample_incomplete_rows[\"total_bedrooms\"].fillna(median, inplace=True)\r\n```\r\n#### 重置索引\r\n``` Python\r\nallData = subTrain.reset_index()\r\n```\r\n\r\n\r\n\r\n\r\n# 缺失值处理\r\n## Sklearn 部分\r\n#### 数据标准化\r\n``` Python\r\nfrom sklearn.preprocessing import StandardScaler\r\nss = StandardScaler()\r\nss.fit(mthsMajorTrain)\r\nmthsMajorTrain_d = ss.transform(mthsMajorTrain)\r\nmthsMajorTest_d = ss.transform(mthsMajorTest)\r\n```\r\n\r\n#### 预测缺失值\r\n``` Python\r\nfrom sklearn import linear_model\r\nlin = linear_model.BayesianRidge()\r\nlin.fit(mthsMajorTrain_d, mthsMajorTrainLabel)\r\ntrainData.loc[(trainData[\'mths_since_last_major_derog\'].isnull()), \'mths_since_last_major_derog\'] = lin.predict(mthsMajorTest_d)\r\n```\r\n#### Lightgbm提供的特征重要性\r\n``` Python\r\nimport lightgbm as lgb\r\n\r\nparams = {\r\n    \'task\': \'train\',\r\n    \'boosting_type\': \'gbdt\',\r\n    \'objective\': \'regression\',\r\n    \'metric\': {\'l2\', \'auc\'},\r\n    \'num_leaves\': 31,\r\n    \'learning_rate\': 0.05,\r\n    \'feature_fraction\': 0.9,\r\n    \'bagging_fraction\': 0.8,\r\n    \'bagging_freq\': 5,\r\n    \'verbose\': 0\r\n}\r\n\r\nlgb_train = lgb.Dataset(totTrain[:400000], totLabel[:400000])\r\nlgb_eval = lgb.Dataset(totTrain[400000:], totLabel[400000:])\r\ngbm = lgb.train(params,\r\n                lgb_train,\r\n                num_boost_round=20,\r\n                valid_sets=lgb_eval,\r\n                early_stopping_rounds=5)\r\nlgb.plot_importance(gbm, figsize=(10,10))\r\n```\r\n对于缺失值，一般手动挑选几个重要的特征，然后进行预测\r\n``` Python\r\nupFeatures = [\'revol_util\', \'revol_bal\', \'annual_inc\']  # 通过上一步挑选出的特征\r\ntotTrain = totTrain[upFeatures]\r\ntotTest = trainData.loc[(trainData[\'total_rev_hi_lim\'].isnull())][upFeatures]\r\ntotTest[\'annual_inc\'].fillna(-9999, inplace=True)\r\n\r\nfrom sklearn.preprocessing import StandardScaler\r\nss = StandardScaler()\r\nss.fit(totTrain)\r\ntrain_d = ss.transform(totTrain)\r\ntest_d = ss.transform(totTest)\r\n\r\nfrom sklearn import linear_model\r\nlin = linear_model.BayesianRidge()\r\nlin.fit(train_d, totLabel)\r\ntrainData.loc[(trainData[\'total_rev_hi_lim\'].isnull()), \'total_rev_hi_lim\'] = lin.predict(test_d)\r\n```\r\n\r\n#### 用中位数填充\r\n``` Python\r\ntrainData[\'total_acc\'].fillna(trainData[\'total_acc\'].median(), inplace=True)\r\n```\r\n\r\n#### 用均值填充\r\n``` Python\r\ntrainData[\'total_acc\'].fillna(trainData[\'total_acc\'].mean(), inplace=True)\r\n```\r\n\r\n## Imputer() 处理丢失值\r\n各属性必须是数值\r\n``` Python\r\nfrom sklearn.preprocessing import Imputer\r\n# 指定用何值替换丢失的值，此处为中位数\r\nimputer = Imputer(strategy=\"median\")\r\n\r\n# 使实例适应数据\r\nimputer.fit(housing_num)\r\n\r\n# 结果在statistics_ 变量中\r\nimputer.statistics_\r\n\r\n# 替换\r\nX = imputer.transform(housing_num)\r\nhousing_tr = pd.DataFrame(X, columns=housing_num.columns,\r\n                          index = list(housing.index.values))\r\n\r\n# 预览\r\nhousing_tr.loc[sample_incomplete_rows.index.values]\r\n```\r\n\r\n## 处理文本数据\r\n\r\n### pandas.factorize()            将输入值编码为枚举类型或分类变量\r\n``` Python\r\nhousing_cat = housing[\'ocean_proximity\']\r\nhousing_cat.head(10)\r\n# 输出\r\n# 17606     <1H OCEAN\r\n# 18632     <1H OCEAN\r\n# 14650    NEAR OCEAN\r\n# 3230         INLAND\r\n# 3555      <1H OCEAN\r\n# 19480        INLAND\r\n# 8879      <1H OCEAN\r\n# 13685        INLAND\r\n# 4937      <1H OCEAN\r\n# 4861      <1H OCEAN\r\n# Name: ocean_proximity, dtype: object\r\n\r\nhousing_cat_encoded, housing_categories = housing_cat.factorize()\r\nhousing_cat_encoded[:10]\r\n# 输出\r\n# array([0, 0, 1, 2, 0, 2, 0, 2, 0, 0], dtype=int64)\r\n```\r\n##### 参数\r\n- values : ndarray (1-d)；序列\r\n- sort : boolean, default False；根据值排序\r\n- na_sentinel : int, default -1；给未找到赋的值\r\n- size_hint : hint to the hashtable sizer\r\n\r\n##### 返回值\r\n- labels : the indexer to the original array\r\n- uniques : ndarray (1-d) or Index；当传递的值是Index或Series时，返回独特的索引。\r\n\r\n### OneHotEncoder   编码整数特征为one-hot向量\r\n返回值为稀疏矩阵\r\n``` Python\r\nfrom sklearn.preprocessing import OneHotEncoder\r\n\r\nencoder = OneHotEncoder()\r\nhousing_cat_1hot = encoder.fit_transform(housing_cat_encoded.reshape(-1,1))\r\nhousing_cat_1hot\r\n```\r\n注意`fit_transform()`期望一个二维数组，所以这里将数据reshape了。\r\n\r\n#### 处理文本特征示例\r\n``` Python\r\nhousing_cat = housing[\'ocean_proximity\']\r\nhousing_cat.head(10)\r\n# 17606     <1H OCEAN\r\n# 18632     <1H OCEAN\r\n# 14650    NEAR OCEAN\r\n# 3230         INLAND\r\n# 3555      <1H OCEAN\r\n# 19480        INLAND\r\n# 8879      <1H OCEAN\r\n# 13685        INLAND\r\n# 4937      <1H OCEAN\r\n# 4861      <1H OCEAN\r\n# Name: ocean_proximity, dtype: object\r\n\r\nhousing_cat_encoded, housing_categories = housing_cat.factorize()\r\nhousing_cat_encoded[:10]\r\n# array([0, 0, 1, 2, 0, 2, 0, 2, 0, 0], dtype=int64)\r\n\r\nhousing_categories\r\n# Index([\'<1H OCEAN\', \'NEAR OCEAN\', \'INLAND\', \'NEAR BAY\', \'ISLAND\'], dtype=\'object\')\r\n\r\nfrom sklearn.preprocessing import OneHotEncoder\r\n\r\nencoder = OneHotEncoder()\r\nprint(housing_cat_encoded.reshape(-1,1))\r\nhousing_cat_1hot = encoder.fit_transform(housing_cat_encoded.reshape(-1,1))\r\nhousing_cat_1hot\r\n# [[0]\r\n#  [0]\r\n#  [1]\r\n#  ..., \r\n#  [2]\r\n#  [0]\r\n#  [3]]\r\n# <16512x5 sparse matrix of type \'<class \'numpy.float64\'>\'\r\n# 	with 16512 stored elements in Compressed Sparse Row format>\r\n```\r\n\r\n\r\n### LabelEncoder &nbsp;标签编码\r\nLabelEncoder`是一个可以用来将标签规范化的工具类，它可以将标签的编码值范围限定在[0,n_classes-1]。简单来说就是对不连续的数字或者文本进行编号。\r\n``` Python\r\n>>> from sklearn import preprocessing\r\n>>> le = preprocessing.LabelEncoder()\r\n>>> le.fit([1, 2, 2, 6])\r\nLabelEncoder()\r\n>>> le.classes_\r\narray([1, 2, 6])\r\n>>> le.transform([1, 1, 2, 6])\r\narray([0, 0, 1, 2])\r\n>>> le.inverse_transform([0, 0, 1, 2])\r\narray([1, 1, 2, 6])\r\n```\r\n当然，它也可以用于非数值型标签的编码转换成数值标签（只要它们是可哈希并且可比较的）:\r\n``` Python\r\n\r\n>>> le = preprocessing.LabelEncoder()\r\n>>> le.fit([\"paris\", \"paris\", \"tokyo\", \"amsterdam\"])\r\nLabelEncoder()\r\n>>> list(le.classes_)\r\n[\'amsterdam\', \'paris\', \'tokyo\']\r\n>>> le.transform([\"tokyo\", \"tokyo\", \"paris\"])\r\narray([2, 2, 1])\r\n>>> list(le.inverse_transform([2, 2, 1]))\r\n[\'tokyo\', \'tokyo\', \'paris\']\r\n```\r\n\r\n### LabelBinarizer &nbsp;标签二值化\r\nLabelBinarizer 是一个用来从多类别列表创建标签矩阵的工具类:\r\n``` Python\r\n>>> from sklearn import preprocessing\r\n>>> lb = preprocessing.LabelBinarizer()\r\n>>> lb.fit([1, 2, 6, 4, 2])\r\nLabelBinarizer(neg_label=0, pos_label=1, sparse_output=False)\r\n>>> lb.classes_\r\narray([1, 2, 4, 6])\r\n>>> lb.transform([1, 6])\r\narray([[1, 0, 0, 0],\r\n       [0, 0, 0, 1]])\r\n```\r\n对于多类别是实例，可以使用:class:MultiLabelBinarizer:\r\n``` Python\r\n>>> lb = preprocessing.MultiLabelBinarizer()\r\n>>> lb.fit_transform([(1, 2), (3,)])\r\narray([[1, 1, 0],\r\n       [0, 0, 1]])\r\n>>> lb.classes_\r\narray([1, 2, 3])\r\n```', 0, 0, 0, 1, '2021-05-10 14:05:24', 0, 1);
INSERT INTO `article` VALUES (25, '机器学习算法的实现', NULL, '# 调参\r\n### GridSearchCV()  对估算器指定参数值进行详尽搜索\r\n``` Python\r\nfrom sklearn.model_selection import GridSearchCV\r\n\r\nparam_grid = [\r\n    # try 12 (3×4) combinations of hyperparameters\r\n    {\'n_estimators\': [3, 10, 30], \'max_features\': [2, 4, 6, 8]},\r\n    # then try 6 (2×3) combinations with bootstrap set as False\r\n    {\'bootstrap\': [False], \'n_estimators\': [3, 10], \'max_features\': [2, 3, 4]},\r\n  ]\r\n\r\nforest_reg = RandomForestRegressor(random_state=42)\r\n# train across 5 folds, that\'s a total of (12+6)*5=90 rounds of training\r\ngrid_search = GridSearchCV(forest_reg, param_grid, cv=5,\r\n                           scoring=\'neg_mean_squared_error\')\r\ngrid_search.fit(housing_prepared, housing_labels)\r\n\r\ngrid_search.best_params_\r\n# Out:{\'max_features\': 8, \'n_estimators\': 30}\r\n\r\ngrid_search.best_estimator_\r\n# Out:\r\n# RandomForestRegressor(bootstrap=True, criterion=\'mse\', max_depth=None,\r\n#            max_features=8, max_leaf_nodes=None, min_impurity_decrease=0.0,\r\n#            min_impurity_split=None, min_samples_leaf=1,\r\n#            min_samples_split=2, min_weight_fraction_leaf=0.0,\r\n#            n_estimators=30, n_jobs=1, oob_score=False, random_state=42,\r\n#            verbose=0, warm_start=False)\r\n```\r\n- estimator : estimator object.每个估算器需要提供一个`score`函数或填写`scoring`参数。\r\n- param_grid : dict or list of dictionaries，键作为参数名称，list作为参数的字典。或存有这样的字典的列表。\r\n- scoring : string, callable, list/tuple, dict or None, default: None，\r\n- cv : int, cross-validation generator or an iterable, optional，如果是整数，则代表KFold\r\n- refit : boolean, or string, default=True，应用已找到的最好的参数到整个数据集上。\r\n\r\n|Methods | description|\r\n|------|-------|\r\n|decision_function(X) |	Call decision_function on the estimator with the best found parameters.|\r\n|fit(X[, y, groups])	| Run fit with all sets of parameters.|\r\n|get_params([deep])	| Get parameters for this estimator.|\r\n|inverse_transform(Xt)	| Call inverse_transform on the estimator with the best found params.|\r\n|predict(X)	| Call predict on the estimator with the best found parameters.|\r\n|predict_log_proba(X)	| Call predict_log_proba on the estimator with the best found parameters.|\r\n|predict_proba(X)	| Call predict_proba on the estimator with the best found parameters.|\r\n|score(X[, y])	| Returns the score on the given data, if the estimator has been refit.|\r\n|set_params(**params)	| Set the parameters of this estimator.|\r\n|transform(X)	|Call transform on the estimator with the best found parameters.|\r\n\r\n\r\n### RandomizedSearchCV()\r\n``` Python\r\nfrom sklearn.model_selection import RandomizedSearchCV\r\nfrom scipy.stats import randint\r\n\r\nparam_distribs = {\r\n        \'n_estimators\': randint(low=1, high=200),\r\n        \'max_features\': randint(low=1, high=8),\r\n    }\r\n\r\nforest_reg = RandomForestRegressor(random_state=42)\r\nrnd_search = RandomizedSearchCV(forest_reg, param_distributions=param_distribs,\r\n                                n_iter=10, cv=5, scoring=\'neg_mean_squared_error\', random_state=42)\r\nrnd_search.fit(housing_prepared, housing_labels)\r\n```\r\n- estimator : estimator object.指定估算器对象。\r\n- param_distributions : dict，给定以参数名为键，list为参数的字典。或提供一个分布，分布必须提供一个`rvs`方法进行采样，例如来自scipy.stats.distributions的方法。\r\n- n_iter : int, default=10，采样参数设置数量。\r\n- scoring : string, callable, list/tuple, dict or None, default: None\r\n- cv : int, cross-validation generator or an iterable, optional\r\n- refit : boolean, or string default=True\r\n- random_state : int, RandomState instance or None, optional, default=None\r\n\r\n# 模型\r\n## 分类\r\n### RandomForestClassifier\r\n``` Python\r\nfrom sklearn.ensemble import RandomForestClassifier\r\nfrom sklearn.model_selection import cross_val_score\r\nrnd_clf = RandomForestClassifier(n_estimators=500, max_leaf_nodes=50, n_jobs=-1)\r\nscores = cross_val_score(rnd_clf, trainData, trainLabel,\r\n                         scoring=\"recall\", cv=10)\r\nscores.mean()\r\n```\r\n### ExtraTreesClassifier\r\n``` Python\r\nfrom sklearn.ensemble import ExtraTreesClassifier\r\nfrom sklearn.model_selection import cross_val_score\r\netr_clf = ExtraTreesClassifier(n_estimators=500, max_leaf_nodes=50, n_jobs=-1)\r\netr_score = cross_val_score(etr_clf, trainData, trainLabel, scoring=\'recall\', cv=10)\r\netr_score.mean()\r\n```\r\n### GradientBoostingClassifier\r\n``` Python\r\nfrom sklearn.ensemble import GradientBoostingClassifier\r\ngbdt = GradientBoostingClassifier(learning_rate=0.1,min_samples_leaf=2,max_depth=6,n_estimators=100)\r\n```\r\n\r\n### XGBClassifier\r\n``` Python\r\nfrom xgboost.sklearn import XGBClassifier\r\nfrom sklearn import cross_validation, metrics\r\nxgb1 = XGBClassifier(learning_rate =0.05,\r\n                     n_estimators=1000,\r\n                     max_depth=3,\r\n                     min_child_weight=1,\r\n                     gamma=0.1,\r\n                     subsample=0.8,\r\n                     colsample_bytree=0.8,\r\n                     objective= \'binary:logistic\',\r\n                     nthread=4,\r\n                     reg_alpha=0.001,\r\n                     reg_lambda=0.001,\r\n                     scale_pos_weight=1,\r\n                     seed=27)\r\nxgb1.fit(subTrain, subLabel)\r\nxgb1_pred = xgb1.predict(trainData)\r\nxgb1_pred_prob = xgb1.predict_proba(trainData)[:, 1]\r\nprint(metrics.accuracy_score(trainLabel, xgb1_pred))\r\nprint(metrics.roc_auc_score(trainLabel, xgb1_pred_prob))\r\nxgb1_f2 = calc_f2(trainLabel, xgb1_pred)\r\nprint(xgb1_f2)\r\n```\r\n\r\n### Lightgbm\r\n``` Python\r\nimport lightgbm as lgb\r\nlgb_clf = lgb.LGBMClassifier(learning_rate=0.1,\r\n                            boosting_type=\'gbdt\',\r\n                            objective=\'binary\',\r\n                            n_estimators=1000,\r\n                            metric=\'auc\',\r\n                            max_depth=3,\r\n                            num_leaves=5,\r\n                            subsample=0.7,\r\n                            colsample_bytree=0.7,\r\n                            min_data_in_leaf=450,\r\n                            feature_fraction=0.7,\r\n                            bagging_fraction=0.7,\r\n                            bagging_freq=6,\r\n                            lambda_l1=1,\r\n                            lambda_l2=0.001,\r\n                            min_gain_to_split=0.265,\r\n                            verbose=5,\r\n                            is_unbalance=True)\r\nlgb_clf.fit(subTrain, subLabel)\r\nlgb_clf_pred = lgb_clf.predict(trainData)\r\n```\r\n## 模型融合\r\n### BaggingClassifier\r\n``` Python\r\nfrom sklearn.ensemble import BaggingClassifier\r\nbag_rnd = BaggingClassifier(rnd_clf, n_estimators=10, max_samples=1000, bootstrap=True, n_jobs=-1)\r\nbag_rnd.fit(subTrain, subLabel)\r\nrnd_pred = bag_rnd.predict(trainData)\r\n```\r\n\r\n### VotingClassifier\r\n``` Python\r\nfrom sklearn.ensemble import VotingClassifier\r\nfrom xgboost.sklearn import XGBClassifier\r\nxgb = XGBClassifier(learning_rate =0.1,\r\n                     n_estimators=1000,\r\n                     max_depth=3,\r\n                     min_child_weight=1,\r\n                     gamma=0.1,\r\n                     subsample=0.8,\r\n                     colsample_bytree=0.8,\r\n                     objective= \'binary:logistic\',\r\n                     nthread=4,\r\n                     reg_alpha=0.001,\r\n                     reg_lambda=0.001,\r\n                     scale_pos_weight=1)\r\n\r\nimport lightgbm as lgb\r\nlgb_clf = lgb.LGBMClassifier(learning_rate=0.1,\r\n                            boosting_type=\'gbdt\',\r\n                            objective=\'binary\',\r\n                            n_estimators=1000,\r\n                            metric=\'auc\',\r\n                            max_depth=3,\r\n                            num_leaves=5,\r\n                            subsample=0.7,\r\n                            colsample_bytree=0.7,\r\n                            min_data_in_leaf=450,\r\n                            feature_fraction=0.7,\r\n                            bagging_fraction=0.7,\r\n                            bagging_freq=6,\r\n                            lambda_l1=1,\r\n                            lambda_l2=0.001,\r\n                            min_gain_to_split=0.265,\r\n                            verbose=5,\r\n                            is_unbalance=True)\r\n\r\nfrom sklearn.ensemble import GradientBoostingClassifier\r\ngbdt = GradientBoostingClassifier(learning_rate=0.05, min_samples_split=320, min_samples_leaf=7, max_depth=7, \r\n                                 max_features=\'sqrt\', subsample=0.7, random_state=10)\r\n\r\nvot = VotingClassifier(estimators=[(\'xgb\', xgb), (\'lgb\', lgb_clf)], voting=\'soft\')\r\nvot.fit(trainData, trainLabel)\r\nvot_pred = vot.predict(testData)\r\nvot_pred = pd.DataFrame(vot_pred)\r\nsubmData[\'acc_now_delinq\'] = vot_pred\r\nsubmData.to_csv(os.path.join(homePath, \'submit.csv\'), index=False)\r\n```\r\n\r\n### StackingClassifier\r\n``` Python\r\nfrom sklearn.ensemble import RandomForestClassifier\r\nrnd_clf = RandomForestClassifier(n_estimators=110, min_samples_split=90, min_samples_leaf=15,max_depth=10,oob_score=True,max_features=10)\r\n\r\nfrom xgboost.sklearn import XGBClassifier\r\nxgb = XGBClassifier(learning_rate =0.05,\r\n                     n_estimators=1000,\r\n                     max_depth=3,\r\n                     min_child_weight=1,\r\n                     gamma=0.1,\r\n                     subsample=0.8,\r\n                     colsample_bytree=0.8,\r\n                     objective= \'binary:logistic\',\r\n                     nthread=4,\r\n                     reg_alpha=0.001,\r\n                     reg_lambda=0.001,\r\n                     scale_pos_weight=1)\r\n\r\nimport lightgbm as lgb\r\nlgb_clf = lgb.LGBMClassifier(learning_rate=0.1,\r\n                            boosting_type=\'gbdt\',\r\n                            objective=\'binary\',\r\n                            n_estimators=1000,\r\n                            metric=\'auc\',\r\n                            max_depth=3,\r\n                            num_leaves=5,\r\n                            subsample=0.7,\r\n                            colsample_bytree=0.7,\r\n                            min_data_in_leaf=450,\r\n                            feature_fraction=0.7,\r\n                            bagging_fraction=0.7,\r\n                            bagging_freq=6,\r\n                            lambda_l1=1,\r\n                            lambda_l2=0.001,\r\n                            min_gain_to_split=0.265,\r\n                            verbose=5,\r\n                            is_unbalance=True)\r\n\r\nfrom sklearn.ensemble import GradientBoostingClassifier\r\ngbdt = GradientBoostingClassifier(learning_rate=0.05, min_samples_split=320, min_samples_leaf=7, max_depth=7, \r\n                                 max_features=\'sqrt\', subsample=0.7)\r\n\r\n\r\nfrom mlxtend.classifier import StackingClassifier \r\nstack_clf = StackingClassifier(classifiers=[gbdt, lgb_clf, rnd_clf, xgb], meta_classifier=xgb)\r\n\r\nstack_clf.fit(trainData, trainLabel)\r\nstack_pred = stack_clf.predict(testData)\r\n```\r\n\r\n# 数据处理\r\n## 特征放缩\r\n### MinMax scaling归一化\r\n该方法更容易受离散点影响\r\n`X_std = (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0))`<br/>\r\n`X_scaled = X_std * (max - min) + min`\r\n``` Python\r\n>>> from sklearn.preprocessing import MinMaxScaler\r\n>>>\r\n>>> data = [[-1, 2], [-0.5, 6], [0, 10], [1, 18]]\r\n>>> scaler = MinMaxScaler()\r\n>>> print(scaler.fit(data))\r\nMinMaxScaler(copy=True, feature_range=(0, 1))\r\n>>> print(scaler.data_max_)\r\n[  1.  18.]\r\n>>> print(scaler.transform(data))\r\n[[ 0.    0.  ]\r\n [ 0.25  0.25]\r\n [ 0.5   0.5 ]\r\n [ 1.    1.  ]]\r\n>>> print(scaler.transform([[2, 2]]))\r\n[[ 1.5  0. ]]\r\n```\r\n- feature_range : tuple (min, max), default=(0, 1)，归一化后值的范围\r\n- copy : boolean, optional, default True，是否复制数据在新的数据上归一化\r\n\r\n### 零均值标准化\r\n``` Python\r\n>>> from sklearn.preprocessing import StandardScaler\r\n>>>\r\n>>> data = [[0, 0], [0, 0], [1, 1], [1, 1]]\r\n>>> scaler = StandardScaler()\r\n>>> print(scaler.fit(data))\r\nStandardScaler(copy=True, with_mean=True, with_std=True)\r\n>>> print(scaler.mean_)\r\n[ 0.5  0.5]\r\n>>> print(scaler.transform(data))\r\n[[-1. -1.]\r\n [-1. -1.]\r\n [ 1.  1.]\r\n [ 1.  1.]]\r\n>>> print(scaler.transform([[2, 2]]))\r\n[[ 3.  3.]]\r\n```\r\n- copy : boolean, optional, default True，是否复制数据在新的数据上执行\r\n- with_mean : boolean, True by default，若为True则在缩放前将数据居中。但在稀疏矩阵上是行不通的。\r\n- with_std : boolean, True by default，若为True，则将数据放缩到单位方差或等效于单位标准差\r\n\r\n\r\n## 处理空数据\r\n### Imputer() 处理丢失值\r\n各属性必须是数值\r\n``` Python\r\nfrom sklearn.preprocessing import Imputer\r\n# 指定用何值替换丢失的值，此处为中位数\r\nimputer = Imputer(strategy=\"median\")\r\n\r\n# 使实例适应数据\r\nimputer.fit(housing_num)\r\n\r\n# 结果在statistics_ 变量中\r\nimputer.statistics_\r\n\r\n# 替换\r\nX = imputer.transform(housing_num)\r\nhousing_tr = pd.DataFrame(X, columns=housing_num.columns,\r\n                          index = list(housing.index.values))\r\n\r\n# 预览\r\nhousing_tr.loc[sample_incomplete_rows.index.values]\r\n```\r\n\r\n## 处理文本数据\r\n\r\n### pandas.factorize()            将输入值编码为枚举类型或分类变量\r\n``` Python\r\nhousing_cat = housing[\'ocean_proximity\']\r\nhousing_cat.head(10)\r\n# 输出\r\n# 17606     <1H OCEAN\r\n# 18632     <1H OCEAN\r\n# 14650    NEAR OCEAN\r\n# 3230         INLAND\r\n# 3555      <1H OCEAN\r\n# 19480        INLAND\r\n# 8879      <1H OCEAN\r\n# 13685        INLAND\r\n# 4937      <1H OCEAN\r\n# 4861      <1H OCEAN\r\n# Name: ocean_proximity, dtype: object\r\n\r\nhousing_cat_encoded, housing_categories = housing_cat.factorize()\r\nhousing_cat_encoded[:10]\r\n# 输出\r\n# array([0, 0, 1, 2, 0, 2, 0, 2, 0, 0], dtype=int64)\r\n```\r\n##### 参数\r\n- values : ndarray (1-d)；序列\r\n- sort : boolean, default False；根据值排序\r\n- na_sentinel : int, default -1；给未找到赋的值\r\n- size_hint : hint to the hashtable sizer\r\n\r\n##### 返回值\r\n- labels : the indexer to the original array\r\n- uniques : ndarray (1-d) or Index；当传递的值是Index或Series时，返回独特的索引。\r\n\r\n### OneHotEncoder   编码整数特征为one-hot向量\r\n返回值为稀疏矩阵\r\n``` Python\r\nfrom sklearn.preprocessing import OneHotEncoder\r\n\r\nencoder = OneHotEncoder()\r\nhousing_cat_1hot = encoder.fit_transform(housing_cat_encoded.reshape(-1,1))\r\nhousing_cat_1hot\r\n```\r\n注意`fit_transform()`期望一个二维数组，所以这里将数据reshape了。\r\n\r\n#### 处理文本特征示例\r\n``` Python\r\nhousing_cat = housing[\'ocean_proximity\']\r\nhousing_cat.head(10)\r\n# 17606     <1H OCEAN\r\n# 18632     <1H OCEAN\r\n# 14650    NEAR OCEAN\r\n# 3230         INLAND\r\n# 3555      <1H OCEAN\r\n# 19480        INLAND\r\n# 8879      <1H OCEAN\r\n# 13685        INLAND\r\n# 4937      <1H OCEAN\r\n# 4861      <1H OCEAN\r\n# Name: ocean_proximity, dtype: object\r\n\r\nhousing_cat_encoded, housing_categories = housing_cat.factorize()\r\nhousing_cat_encoded[:10]\r\n# array([0, 0, 1, 2, 0, 2, 0, 2, 0, 0], dtype=int64)\r\n\r\nhousing_categories\r\n# Index([\'<1H OCEAN\', \'NEAR OCEAN\', \'INLAND\', \'NEAR BAY\', \'ISLAND\'], dtype=\'object\')\r\n\r\nfrom sklearn.preprocessing import OneHotEncoder\r\n\r\nencoder = OneHotEncoder()\r\nprint(housing_cat_encoded.reshape(-1,1))\r\nhousing_cat_1hot = encoder.fit_transform(housing_cat_encoded.reshape(-1,1))\r\nhousing_cat_1hot\r\n# [[0]\r\n#  [0]\r\n#  [1]\r\n#  ..., \r\n#  [2]\r\n#  [0]\r\n#  [3]]\r\n# <16512x5 sparse matrix of type \'<class \'numpy.float64\'>\'\r\n# 	with 16512 stored elements in Compressed Sparse Row format>\r\n```\r\n\r\n\r\n### LabelEncoder &nbsp;标签编码\r\nLabelEncoder`是一个可以用来将标签规范化的工具类，它可以将标签的编码值范围限定在[0,n_classes-1]。简单来说就是对不连续的数字或者文本进行编号。\r\n``` Python\r\n>>> from sklearn import preprocessing\r\n>>> le = preprocessing.LabelEncoder()\r\n>>> le.fit([1, 2, 2, 6])\r\nLabelEncoder()\r\n>>> le.classes_\r\narray([1, 2, 6])\r\n>>> le.transform([1, 1, 2, 6])\r\narray([0, 0, 1, 2])\r\n>>> le.inverse_transform([0, 0, 1, 2])\r\narray([1, 1, 2, 6])\r\n```\r\n当然，它也可以用于非数值型标签的编码转换成数值标签（只要它们是可哈希并且可比较的）:\r\n``` Python\r\n\r\n>>> le = preprocessing.LabelEncoder()\r\n>>> le.fit([\"paris\", \"paris\", \"tokyo\", \"amsterdam\"])\r\nLabelEncoder()\r\n>>> list(le.classes_)\r\n[\'amsterdam\', \'paris\', \'tokyo\']\r\n>>> le.transform([\"tokyo\", \"tokyo\", \"paris\"])\r\narray([2, 2, 1])\r\n>>> list(le.inverse_transform([2, 2, 1]))\r\n[\'tokyo\', \'tokyo\', \'paris\']\r\n```\r\n\r\n### LabelBinarizer &nbsp;标签二值化\r\nLabelBinarizer 是一个用来从多类别列表创建标签矩阵的工具类:\r\n``` Python\r\n>>> from sklearn import preprocessing\r\n>>> lb = preprocessing.LabelBinarizer()\r\n>>> lb.fit([1, 2, 6, 4, 2])\r\nLabelBinarizer(neg_label=0, pos_label=1, sparse_output=False)\r\n>>> lb.classes_\r\narray([1, 2, 4, 6])\r\n>>> lb.transform([1, 6])\r\narray([[1, 0, 0, 0],\r\n       [0, 0, 0, 1]])\r\n```\r\n对于多类别是实例，可以使用:class:MultiLabelBinarizer:\r\n``` Python\r\n>>> lb = preprocessing.MultiLabelBinarizer()\r\n>>> lb.fit_transform([(1, 2), (3,)])\r\narray([[1, 1, 0],\r\n       [0, 0, 1]])\r\n>>> lb.classes_\r\narray([1, 2, 3])\r\n```', 0, 0, 0, 1, '2021-05-10 14:05:52', 0, 1);
INSERT INTO `article` VALUES (54, '44', NULL, '444', 0, 0, 0, 1, '2021-05-17 15:41:36', 0, 1);
INSERT INTO `article` VALUES (55, '实时', NULL, '实时', 0, 0, 0, 1, '2021-05-17 15:43:36', 1, 1);
INSERT INTO `article` VALUES (56, '测试', NULL, '测试', 0, 0, 0, 1, '2021-05-17 15:44:18', 1, 1);
INSERT INTO `article` VALUES (57, '4', NULL, '4', 0, 0, 0, 1, '2021-05-17 15:45:02', 0, 1);
INSERT INTO `article` VALUES (58, '测试', NULL, '是', 0, 0, 0, 1, '2021-05-17 15:45:29', 0, 1);
INSERT INTO `article` VALUES (59, '自动化专业就业情况报告', NULL, '回顾下本专栏的前文，介绍了自动化学科的基本定义与学习内容、创立与发展历史、发展动力、国内外现状、与其他专业的区别、与人工智能的关系、深造问题、目前的产业发展，以及专业前辈的介绍文章，涵盖了从高考后进入专业到走出校园的全程，想了想也就剩下最后一个问题了，就业。\r\n\r\n无论本科，硕士还是读博，总有一天都要面临工作，对于自动化出来能干什么这个问题，每个学生都需要面对，只不过不同的学历层次选择不同。\r\n\r\n一、写在前面\r\n打开知乎，搜索任何一个专业的就业，生化环材除外，多看几个帖子就会发现，同样一个专业有的说我们就业随便去，都是月薪10K以上，有的说专业垃圾，出去也就3K，而如果单纯的看一个或者少数帖子，就会产生误导。\r\n\r\n谁说的对呢，其实都对，关键学校不一样，就拿自动化来说，清华大学自动化出来不缺好工作，普通的学校自动化出来，差一点的去个机械厂车间，两个人自然对专业感觉就不一样。所以网上帖子再多，不如本校学长一张就业去向表有价值。\r\n\r\n为了提供大范围的参考，本报告不涉及具体公司，有兴趣者可以查阅招聘网站信息。\r\n\r\n二、机器人行业\r\n提起自动化专业的适合就业方向，不少人第一个就说，机器人，有些高考志愿书上甚至把新设立的机器人工程专业称为最高层次的自动化专业，但很多人往往并不知道机器人相关岗位有什么。\r\n\r\n首先，随着科技的发展，分工的不断精细，对于刚入行的从业者来说，不会说让你一个人负责机器人系统的设计生产全过程，上来就当总工。分出来了许多工作，从一开始说吧。\r\n\r\n1、机器人运动控制\r\n\r\n假设交给你一个任务，让你设计一个机器人，第一步干啥呢？看看人体结构，先把大的结构敲定，用到仿生学或者机械设计相关知识，然后研究利用电机怎么让他动起来。这一个方向被称为机器人运动控制方向。\r\n\r\n这个方向要求有力学与机械知识及必要的算法能力，在相关的招聘网站上对于运动控制岗位的条件例如：\r\n\r\n推荐标准：适合于电机学相关知识扎实，具有基本的嵌入式开发能力的学生。\r\n\r\n\r\n\r\n2、环境感知与路径规划\r\n\r\n拿到了一个能动的机器人，接下来问题是怎么动，即环境感知与路径规划，最近这个大方向很火，原因也是因为机器学习带动的视觉革命，在机器学习没火之前，环境感知主要依靠传统传感器，利用多传感器融合技术，而路径规划算法的历史更早。\r\n\r\n这个方向主要依靠算法，也是目前为止机器人领域最贴近于计算机的方向，或者说就是计算机，岗位也分两种，传统感知类与视觉感知类，视觉感知类待遇相对好一些。这类与模式识别比较类似。\r\n\r\n推荐标准：适合于算法相关知识扎实的学生。一些岗位对于学历有要求。\r\n\r\n\r\n\r\n3、集群机器人\r\n\r\n设计的机器人能动了，也知道怎么动了，看样子任务完成了，此时上面下了一个新要求，举个例子，物流行业，一用就是许多台机器人，它们怎么配合？或者无人机，一群无人机怎么联动。这就是集群机器人方向。\r\n\r\n这个方向更加依靠数学，依靠算法，随着应用的机器人数量越来越多，该方向的热度逐渐上升。\r\n\r\n推荐标准：适合于数学、算法相关知识扎实的学生。对于学历有要求。\r\n\r\n\r\n\r\n4、总结\r\n\r\n不少网站上对于机器人行业的岗位还会有ROS这一类，看了看工作职能，这类岗可以划入以上三个。\r\n\r\n综上，对于机器人行业，机械电子工程出身的大佬可以考虑从事运动控制方向，自动化本科出身的也可以，自动化出身的硕博的话建议第二或第三，因为考虑到机械相关的知识需要补充，不过也不是绝对不能做第一个方向的。\r\n\r\n三、嵌入式\r\n嵌入式，这个方向与其他方向有重合，是每年自动化专业本科生毕业就业去向最多的行业，比较考验硬件能力，对各型号的单片机掌握，对基本控制算法的掌握，以后发展的方向也是硬件工程师，社会上对于嵌入式有很多培训机构，、在大学期间也可以自主学习。\r\n\r\n推荐标准：适合于硬件、基本算法相关知识扎实的学生。尤其是硬件相关知识。\r\n\r\n四、工业现场\r\n提起工业现场，虽然说自动化专业来源于工业，但学生往往不会选择工业现场，一是因为环境差，二是因为待遇低，三是因为各种加班，比996有过之而无不及。\r\n\r\n但是由于各种原因，最后很多人还是去了工业现场，去了以后或者打算去的，可以记住这样一句话，越硬越穷，越软越富。什么意思呢，对于同一批进去的，比较工资待遇，一般算法岗或者管理岗要比纯硬件岗高。\r\n\r\n工业现场对于新招收的自动化学生有以下几种岗位：\r\n\r\n1、学徒工类\r\n\r\n第一年在车间锻炼，做一些装配工作，逐渐跟着厂里师傅学PLC,电气控制等活，这种一般是本科生。\r\n\r\n2、初级工程师\r\n\r\n如果PLC等相关器件掌握较好，有些企业会让新进的学生迅速参与设计与调试，常年出差，不过待遇比学徒工类要好一点。本科生居多。\r\n\r\n3、上位机类\r\n\r\n如果通信、上位机编程掌握较好，一般会负责一些现场的上位机软件设计，也可以去一些专门做这块的公司，同样需要常年蹲现场和出差。\r\n\r\n做了几年后，拥有了工作经验，才有资格参加许多公司的高级岗位招聘，拿最近比较热门的工业互联网来说，很多岗位都要求三年经验，这个行业非常看重经验。\r\n\r\n推荐标准：热爱这行、能沉下心锻炼自己、具有一定的不断学习能力的学生。\r\n\r\n五、军工\r\n【请咨询相关行业人士】\r\n\r\n六、纯软件\r\nJAVA 安卓都比较好，入行人工智能纯软件请做好神仙打架的准备。', 0, 0, 0, 1, '2021-05-17 16:38:54', 1, 1);
INSERT INTO `article` VALUES (60, '测试11111111111111111111', NULL, '实时测试11111111111111111111111', 0, 0, 0, 1, '2021-05-17 18:29:32', 3, 1);

-- ----------------------------
-- Table structure for category
-- ----------------------------
DROP TABLE IF EXISTS `category`;
CREATE TABLE `category`  (
  `category_id` int(11) NOT NULL AUTO_INCREMENT COMMENT '类别id',
  `category_name` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NULL DEFAULT NULL COMMENT '类别名',
  `category_photo` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NULL DEFAULT NULL COMMENT '分类图标',
  PRIMARY KEY (`category_id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 42 CHARACTER SET = utf8mb4 COLLATE = utf8mb4_0900_ai_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of category
-- ----------------------------
INSERT INTO `category` VALUES (0, '未分类', 'http://localhost:8080/category/image/%E6%9C%AA%E5%88%86%E7%B1%BB.png');
INSERT INTO `category` VALUES (1, '自动化', 'http://localhost:8080/image/%E8%87%AA%E5%8A%A8%E5%8C%96.png');
INSERT INTO `category` VALUES (2, '工业互联网', 'http://localhost:8080/image/%E5%B7%A5%E4%B8%9A%E4%BA%92%E8%81%94%E7%BD%91.png');
INSERT INTO `category` VALUES (3, '神经网络', 'http://localhost:8080/image/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C.png');
INSERT INTO `category` VALUES (4, '自动驾驶', 'http://localhost:8080/image/%E8%87%AA%E5%8A%A8%E9%A9%BEa');
INSERT INTO `category` VALUES (20, '智能算法', 'http://localhost:8080/category/image/智能算法.png');

-- ----------------------------
-- Table structure for comment
-- ----------------------------
DROP TABLE IF EXISTS `comment`;
CREATE TABLE `comment`  (
  `comment_id` int(11) NOT NULL AUTO_INCREMENT COMMENT '评论id',
  `comment_pid` int(11) NULL DEFAULT NULL COMMENT '评论父id',
  `article_id` int(11) NULL DEFAULT NULL COMMENT '文章id',
  `comment_person_name` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NULL DEFAULT NULL COMMENT '评论人名',
  `comment_person_email` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NULL DEFAULT NULL COMMENT '评论人邮箱',
  `comment_content` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NULL DEFAULT NULL COMMENT '评论内容',
  `respond_user` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NULL DEFAULT NULL COMMENT '回复评论人',
  `comment_creation_time` datetime(0) NULL DEFAULT NULL COMMENT '评论创建时间',
  PRIMARY KEY (`comment_id`) USING BTREE,
  INDEX `comment_person_name`(`comment_person_name`) USING BTREE,
  INDEX `comment_ibfk_1`(`comment_pid`) USING BTREE,
  INDEX `comment_ibfk_3`(`article_id`) USING BTREE,
  INDEX `comment_ibfk_4`(`respond_user`) USING BTREE,
  CONSTRAINT `comment_ibfk_1` FOREIGN KEY (`comment_pid`) REFERENCES `comment` (`comment_id`) ON DELETE CASCADE ON UPDATE CASCADE,
  CONSTRAINT `comment_ibfk_3` FOREIGN KEY (`article_id`) REFERENCES `article` (`article_id`) ON DELETE CASCADE ON UPDATE CASCADE,
  CONSTRAINT `comment_ibfk_4` FOREIGN KEY (`respond_user`) REFERENCES `comment` (`comment_person_name`) ON DELETE CASCADE ON UPDATE CASCADE
) ENGINE = InnoDB AUTO_INCREMENT = 45 CHARACTER SET = utf8mb4 COLLATE = utf8mb4_0900_ai_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of comment
-- ----------------------------
INSERT INTO `comment` VALUES (41, NULL, 1, 'zx', '', '测试评论', NULL, '2021-05-18 16:34:53');
INSERT INTO `comment` VALUES (42, NULL, 1, '测试人员1', '', '测试评论2', NULL, '2021-05-18 16:35:18');
INSERT INTO `comment` VALUES (43, NULL, 11, '测试3', '', '测试评论3', NULL, '2021-05-18 16:35:48');
INSERT INTO `comment` VALUES (44, 43, 11, '测试回复1', '', '测试回复1', '测试3', '2021-05-18 16:36:10');
INSERT INTO `comment` VALUES (45, NULL, 22, 'l', '', 'ww', NULL, '2021-05-31 11:43:53');

-- ----------------------------
-- Table structure for message
-- ----------------------------
DROP TABLE IF EXISTS `message`;
CREATE TABLE `message`  (
  `message_id` int(11) NOT NULL AUTO_INCREMENT,
  `message_user_name` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NULL DEFAULT NULL,
  `message_user_email` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NULL DEFAULT NULL,
  `message_content` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NULL DEFAULT NULL,
  `message_creation_time` datetime(0) NULL DEFAULT NULL,
  PRIMARY KEY (`message_id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 15 CHARACTER SET = utf8mb4 COLLATE = utf8mb4_0900_ai_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of message
-- ----------------------------
INSERT INTO `message` VALUES (14, '留言测试人员', '', '留言功能测试', '2021-05-11 14:36:29');
INSERT INTO `message` VALUES (15, '123', '', '233234', '2021-05-12 12:29:38');

-- ----------------------------
-- Table structure for role
-- ----------------------------
DROP TABLE IF EXISTS `role`;
CREATE TABLE `role`  (
  `role_id` int(11) NOT NULL,
  `role_name` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NULL DEFAULT NULL,
  PRIMARY KEY (`role_id`) USING BTREE
) ENGINE = InnoDB CHARACTER SET = utf8mb4 COLLATE = utf8mb4_0900_ai_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of role
-- ----------------------------

-- ----------------------------
-- Table structure for role_user
-- ----------------------------
DROP TABLE IF EXISTS `role_user`;
CREATE TABLE `role_user`  (
  `role_user_id` int(11) NOT NULL,
  `user_id` int(11) NULL DEFAULT NULL,
  `role_id` int(11) NULL DEFAULT NULL,
  PRIMARY KEY (`role_user_id`) USING BTREE
) ENGINE = InnoDB CHARACTER SET = utf8mb4 COLLATE = utf8mb4_0900_ai_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of role_user
-- ----------------------------

-- ----------------------------
-- Table structure for user
-- ----------------------------
DROP TABLE IF EXISTS `user`;
CREATE TABLE `user`  (
  `user_id` int(11) NOT NULL,
  `user_name` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NULL DEFAULT NULL,
  `user_password` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NULL DEFAULT NULL,
  PRIMARY KEY (`user_id`) USING BTREE
) ENGINE = InnoDB CHARACTER SET = utf8mb4 COLLATE = utf8mb4_0900_ai_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of user
-- ----------------------------

SET FOREIGN_KEY_CHECKS = 1;
